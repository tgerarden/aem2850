<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Code examples | R for Business Analytics</title><link>https://aem2850.toddgerarden.com/example/</link><atom:link href="https://aem2850.toddgerarden.com/example/index.xml" rel="self" type="application/rss+xml"/><description>Code examples</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Mon, 26 Jul 2021 00:00:00 +0000</lastBuildDate><image><url>https://aem2850.toddgerarden.com/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url><title>Code examples</title><link>https://aem2850.toddgerarden.com/example/</link></image><item><title>Sharing R output online</title><link>https://aem2850.toddgerarden.com/example/15-example/</link><pubDate>Mon, 26 Jul 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/15-example/</guid><description>&lt;h2 id="publishing-your-stuff-online">Publishing your stuff online&lt;/h2>
&lt;h3 id="quickest-and-easiest-way-rpubs">Quickest and easiest way: RPubs&lt;/h3>
&lt;p>The easiest way to get a knitted R Markdown onto the internet is to use &lt;a href="https://rpubs.com/" target="_blank" rel="noopener">RPubs&lt;/a>. We talked about this in &lt;a href="https://aem2850.toddgerarden.com/slides/10-slides.html#sharing-content">session 10&lt;/a>, and you used it to turn in &lt;a href="https://aem2850.toddgerarden.com/assignment/10-exercise/">exercise 10&lt;/a>. After knitting an HTML document in RStudio, click on the &amp;ldquo;Publish&amp;rdquo; button in the top right corner to upload the document to the RPubs server and get a URL that you can share with others:&lt;/p>
&lt;img src="https://aem2850.toddgerarden.com/slides/img/10/publish-document.png" width="30%" />
&lt;p>You don&amp;rsquo;t have to set up a web server or anythingâ€”it&amp;rsquo;s all pretty automatic and seamless.&lt;/p>
&lt;h3 id="great-for-standalone-projects-r-markdown-websites">Great for standalone projects: R Markdown websites&lt;/h3>
&lt;p>If you have something slightly more complex, like a collection of R Markdown files that do related things, it&amp;rsquo;s easy to stitch them all together in an &lt;a href="https://rmarkdown.rstudio.com/lesson-13.html" target="_blank" rel="noopener">R Markdown website&lt;/a>. RStudio supports these automaticallyâ€”after telling RStudio to consider an RStudio project to be a website, it will knit all the &lt;code>.Rmd&lt;/code> files in the root of your project directory every time you click on the &amp;ldquo;Build Website&amp;rdquo; button.&lt;/p>
&lt;p>RStudio generates a standalone folder named &lt;code>public&lt;/code> with static HTML pages of all your knitted documents. You then have to put that folder on the internet somewhere, either on a web server you have access to, or a free service like &lt;a href="https://www.netlify.com/" target="_blank" rel="noopener">Netlify&lt;/a>.&lt;/p>
&lt;p>See &lt;a href="https://bookdown.org/yihui/rmarkdown/rmarkdown-site.html" target="_blank" rel="noopener">this page for complete documentation&lt;/a>, or follow these tutorials by &lt;a href="https://livefreeordichotomize.com/2017/08/08/how-to-make-an-rmarkdown-website/" target="_blank" rel="noopener">Lucy D&amp;rsquo;Agostino McGowan&lt;/a> and &lt;a href="https://www.emilyzabor.com/tutorials/rmarkdown_websites_tutorial.html" target="_blank" rel="noopener">Emily Zabor&lt;/a>.&lt;/p>
&lt;p>These websites are especially helpful for standalone projects like research papers and reports. I&amp;rsquo;ve had students do their master&amp;rsquo;s capstone projects with these, with specific pages for their introduction, literature review, data cleaning, exploratory data analysis, modeling, and results.&lt;/p>
&lt;p>I typically make a website for each of my research projects and will include pages with IRB details, copies of survey experiments, data cleaning, results, and so on. Here are some examples:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://stats.andrewheiss.com/ngo-crackdowns-philanthropy/" target="_blank" rel="noopener">NGO Crackdowns and Philanthropy&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://stats.andrewheiss.com/donors-ngo-restrictions/" target="_blank" rel="noopener">Are Donors Really Responding?&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://stats.andrewheiss.com/edb-social-pressure/" target="_blank" rel="noopener">The Power of Ranking&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://stats.andrewheiss.com/constraint-closure/" target="_blank" rel="noopener">Constraint Closure&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>You can also make really neat small websites like &lt;a href="https://tinystats.github.io/teacups-giraffes-and-statistics/index.html" target="_blank" rel="noopener">DesirÃ©e De Leon&amp;rsquo;s Teacup Giraffes&lt;/a> for teaching basic statistics.&lt;/p>
&lt;h3 id="more-complex-blogs-and-websites-blogdown">More complex blogs and websites: blogdown&lt;/h3>
&lt;p>If you want more control (i.e. total control) over the HTML output and the structure of a website, you can use a package named &lt;a href="https://bookdown.org/yihui/blogdown/structure-of-the-book.html" target="_blank" rel="noopener">&lt;strong>blogdown&lt;/strong>&lt;/a> to convert R Markdown files into an entire website. This course website is built with &lt;strong>blogdown&lt;/strong>: you can see &lt;a href="https://github.com/andrewheiss/datavizm20.classes.andrewheiss.com" target="_blank" rel="noopener">all the underlying R Markdown files at GitHub&lt;/a>.&lt;/p>
&lt;p>Like R Markdown websites, blogdown generates a complete static version of the knitted website and puts it in a folder named &lt;code>public&lt;/code>. You&amp;rsquo;re then responsible for putting that somewhere on the internet, either on your own server or by using a free hosting service like &lt;a href="https://www.netlify.com/" target="_blank" rel="noopener">Netlify&lt;/a>.&lt;/p>
&lt;p>Blogdown is &lt;a href="https://bookdown.org/yihui/blogdown/" target="_blank" rel="noopener">incredibly well documented&lt;/a>, and there are lots of tutorials for how to get started. &lt;a href="https://alison.rbind.io/post/2017-06-12-up-and-running-with-blogdown/" target="_blank" rel="noopener">Alison Hill&amp;rsquo;s tutorial here is the best place to get started&lt;/a>â€”follow it and you&amp;rsquo;ll have a basic blog completely free.&lt;/p>
&lt;h3 id="books-dissertations-and-theses-bookdown">Books, dissertations, and theses: bookdown&lt;/h3>
&lt;p>If you don&amp;rsquo;t want to create a website, you can use a package named &lt;a href="https://bookdown.org/" target="_blank" rel="noopener">&lt;strong>bookdown&lt;/strong>&lt;/a> to stitch a collection of R Markdown files into a PDF, Word, or HTML book. (You could even put all your exercises from this class into a single book!). &lt;strong>bookdown&lt;/strong> is &lt;a href="https://bookdown.org/yihui/bookdown/" target="_blank" rel="noopener">incredibly well documented&lt;/a> too (as a &lt;strong>bookdown&lt;/strong> book), and you can get familiar with it fairly quickly.&lt;/p>
&lt;p>&lt;a href="https://bookdown.org/home/archive/" target="_blank" rel="noopener">Dozens of real-world books&lt;/a>, dissertations, and theses have been written with &lt;strong>bookdown&lt;/strong>, including both &lt;a href="https://clauswilke.com/dataviz/" target="_blank" rel="noopener">Claus Wilke&amp;rsquo;s&lt;/a> and &lt;a href="https://socviz.co/" target="_blank" rel="noopener">Kieran Healy&amp;rsquo;s&lt;/a> books from this course. Because of the magic of Markdown, you can create parallel HTML and PDF versions of your book and post one type of output on the internet and print and bind the other one.&lt;/p>
&lt;h3 id="slides-xaringan">Slides: xaringan&lt;/h3>
&lt;p>R Markdown isn&amp;rsquo;t just for PDF, Word, and HTML documents. You can also make slides! All the slides for this course were made in R Markdown with a package named &lt;strong>xaringan&lt;/strong>. You can see &lt;a href="https://bookdown.org/yihui/rmarkdown/xaringan.html" target="_blank" rel="noopener">the documentation here&lt;/a>, and see &lt;a href="https://slides.yihui.org/xaringan/" target="_blank" rel="noopener">the main example presentation here&lt;/a>. You can also &lt;a href="https://github.com/andrewheiss/datavizs21.classes.andrewheiss.com/tree/main/static/slides" target="_blank" rel="noopener">see all the R Markdown files I wrote to create the slides for this class here&lt;/a>.&lt;/p>
&lt;h3 id="code-github-and-github-gists">Code: GitHub and GitHub gists&lt;/h3>
&lt;p>And finally, if you want to share code (and keep track of versions of your code), &lt;a href="https://github.com/" target="_blank" rel="noopener">GitHub&lt;/a> is one of the best places for that. Posting your code at places like GitHub lets other people see and borrow and adapt and make suggestions to your code. You can see &lt;a href="https://github.com/andrewheiss/" target="_blank" rel="noopener">all my different repositories and projects here&lt;/a>, for example.&lt;/p>
&lt;p>&lt;a href="https://happygitwithr.com/" target="_blank" rel="noopener">Jenny Bryan has a useful &lt;strong>bookdown&lt;/strong> website&lt;/a> explaining how to get started, and GitHub itself &lt;a href="https://guides.github.com/activities/hello-world/" target="_blank" rel="noopener">has excellent materials for learning how to use git&lt;/a>.&lt;/p>
&lt;p>If you don&amp;rsquo;t want to go through the process of creating a full-blown git repository, GitHub also lets you make &amp;ldquo;gists&amp;rdquo;, which are single shareable files of code. (&lt;a href="https://gist.github.com/andrewheiss" target="_blank" rel="noopener">See all mine here for examples&lt;/a>). Gists are excellent ways to share reproducible examples (or &lt;a href="https://www.jessemaegan.com/post/so-you-ve-been-asked-to-make-a-reprex/" target="_blank" rel="noopener">reprexes&lt;/a>), and the &lt;a href="https://reprex.tidyverse.org/" target="_blank" rel="noopener">&lt;strong>reprex&lt;/strong> package&lt;/a> in R generates output that you can paste directly into a new gist for sharing (see &lt;a href="https://gist.github.com/andrewheiss/5ea439fae38e61419858ce9b5c2027cd" target="_blank" rel="noopener">this one, for instance, which I used to show someone how to run and plot logistic regression with R&lt;/a>).&lt;/p>
&lt;h2 id="telling-stories-with-data">Telling stories with data&lt;/h2>
&lt;p>If you&amp;rsquo;re interested in learning more about data storytelling and science communication, check out these resources:&lt;/p>
&lt;ul>
&lt;li>&lt;i class="fas fa-university">&lt;/i> &lt;a href="https://www.jessemaegan.com/post/so-you-ve-been-asked-to-make-a-reprex/" target="_blank" rel="noopener">BUSM 491R: Telling Stories with Data&lt;/a> (BYU, Fall 2017)&lt;/li>
&lt;li>&lt;i class="fas fa-book">&lt;/i> Cole Nussbaumer Knaflic, &lt;a href="https://www.amazon.com/Storytelling-Data-Visualization-Business-Professionals/dp/1119002257" target="_blank" rel="noopener">&lt;em>Storytelling with Data: A Data Visualization Guide for Business Professionals&lt;/em>&lt;/a> (Hoboken, New Jersey: John Wiley &amp;amp; Sons, Inc., 2015).&lt;/li>
&lt;li>&lt;i class="fas fa-book">&lt;/i> Alan Alda, &lt;a href="https://www.amazon.com/Understood-Would-Have-This-Look/dp/0812989147" target="_blank" rel="noopener">&lt;em>If I Understood You, Would I Have This Look on My Face? My Adventures in the Art and Science of Relating and Communicating&lt;/em>&lt;/a> (New York: Random House, 2017).&lt;/li>
&lt;li>&lt;i class="fas fa-book">&lt;/i> Nancy Duarte, &lt;a href="https://www.amazon.com/Resonate-Present-Stories-Transform-Audiences/dp/0470632011" target="_blank" rel="noopener">&lt;em>Resonate: Present Visual Stories That Transform Audiences&lt;/em>&lt;/a> (Hoboken, New Jersey: John Wiley &amp;amp; Sons, Inc., 2010).&lt;/li>
&lt;li>&lt;i class="fab fa-youtube">&lt;/i> &lt;a href="http://www.msnbc.com/morning-joe/watch/understanding-the-way-scientists-speak-27745859874" target="_blank" rel="noopener">&amp;ldquo;Understanding the way scientists speak,&amp;quot;&lt;/a> MSNBC Morning Joe, 2013-04-24&lt;/li>
&lt;li>&lt;i class="fab fa-youtube">&lt;/i> &lt;a href="https://www.youtube.com/watch?v=JtdyA7SibG8" target="_blank" rel="noopener">&amp;ldquo;Improvisation for Scientists: Workshops by Alan Alda and the Center for Communicating Science,&amp;quot;&lt;/a> Stony Brook Journalism, 2010-03-23&lt;/li>
&lt;/ul></description></item><item><title>Text</title><link>https://aem2850.toddgerarden.com/example/13-example/</link><pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/13-example/</guid><description>&lt;p>For this example, we&amp;rsquo;re going to use the text of &lt;em>Little Women&lt;/em> by Louisa May Alcott and four Shakespearean tragedies (&lt;em>Romeo and Juliet&lt;/em>, &lt;em>King Lear&lt;/em>, &lt;em>Macbeth&lt;/em>, and &lt;em>Hamlet&lt;/em>) to explore how to do some basic text visualization.&lt;/p>
&lt;p>You can follow along if you want, but &lt;strong>don&amp;rsquo;t feel like you have too&lt;/strong>. This is mostly just to give you a taste of different methods for visualizing text. It&amp;rsquo;s by no means comprehensive, but it is well annotated and commented and should (hopefully) be easy to follow.&lt;/p>
&lt;p>If you want to play with part-of-speech tagging, you can download an already-tagged version of &lt;em>Little Women&lt;/em> here (you&amp;rsquo;ll likely need to right click and choose &amp;ldquo;Save Link Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/little_women_tagged.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>little_women_tagged.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>If you want to see other examples of text visualizations with the &lt;strong>tidytext&lt;/strong> package, check out some of these:&lt;/p>
&lt;ul>
&lt;li>&lt;i class="fas fa-external-link-square-alt">&lt;/i> &lt;a href="https://rstudio-pubs-static.s3.amazonaws.com/300624_8260952d1f0346969e65f41a97006bf5.html" target="_blank" rel="noopener">Harry Potter Sentiment Analysis for Beginners&lt;/a> (this uses &lt;a href="https://github.com/bradleyboehmke/harrypotter" target="_blank" rel="noopener">the &lt;strong>harrypotter&lt;/strong> package&lt;/a>, which you can install from GitHub (not from CRAN))&lt;/li>
&lt;li>&lt;i class="fas fa-external-link-square-alt">&lt;/i> Peer Christensen &lt;a href="https://peerchristensen.netlify.app/post/fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies/" target="_blank" rel="noopener">&amp;ldquo;Fair is foul, and foul is fair: a tidytext sentiment analysis of Shakespeareâ€™s tragedies&amp;rdquo;&lt;/a>&lt;/li>
&lt;li>&lt;i class="fas fa-external-link-square-alt">&lt;/i> &lt;a href="https://www.andrewheiss.com/blog/2018/12/26/tidytext-pos-john/" target="_blank" rel="noopener">&amp;ldquo;Tidy text, parts of speech, and unique words in the Bible&amp;rdquo;&lt;/a>&lt;/li>
&lt;li>&lt;i class="fas fa-external-link-square-alt">&lt;/i> &lt;a href="https://www.andrewheiss.com/blog/2018/12/28/tidytext-pos-arabic/" target="_blank" rel="noopener">&amp;ldquo;Tidy text, parts of speech, and unique words in the Qur&amp;rsquo;an&amp;rdquo;&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/YeyZp8Dw55g" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a highly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="get-data">Get data&lt;/h3>
&lt;p>First, as always, we&amp;rsquo;ll load the libraries we&amp;rsquo;ll be using:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse) # For ggplot, dplyr, etc.
library(tidytext) # For neat text things
library(gutenbergr) # For downloading books from Project Gutenberg
&lt;/code>&lt;/pre>
&lt;p>We&amp;rsquo;re going to use the &lt;strong>gutenbergr&lt;/strong> package to download some books directly from Project Gutenberg. The IDs for these books come from the URLs at their website. For instance, &lt;a href="https://www.gutenberg.org/ebooks/514" target="_blank" rel="noopener">&lt;em>Little Women&lt;/em> is book #514&lt;/a>. We&amp;rsquo;ll store these books as &lt;code>*_raw&lt;/code> and then clean them up later.&lt;/p>
&lt;pre>&lt;code class="language-r"># 514 Little Women
little_women_raw &amp;lt;- gutenberg_download(514, meta_fields = &amp;quot;title&amp;quot;)
# 1524 - Hamlet
# 1532 - King Lear
# 1533 - Macbeth
# 1513 - Romeo and Juliet
tragedies_raw &amp;lt;- gutenberg_download(c(1524, 1532, 1533, 1513),
meta_fields = &amp;quot;title&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>If you won&amp;rsquo;t want to redownload the books every time you knit (you don&amp;rsquo;t), you can do the same trick we&amp;rsquo;ve used for &lt;a href="https://aem2850.toddgerarden.com/example/08-example/">WDI&lt;/a> and &lt;a href="https://aem2850.toddgerarden.com/example/11-example/">FRED data&lt;/a>. Put the actual code for getting the books in a chunk with &lt;code>eval=FALSE&lt;/code> on it and run it manually in RStudio when you want to get the data. Then you can write the downloaded data as a CSV file, and then load it invisibly from the CSV file when you knit:&lt;/p>
&lt;pre>&lt;code class="language-text">I first download data from Project Gutenberg:
```{r get-book, eval=FALSE}
books_raw &amp;lt;- gutenberg_download(...)
write_csv(books_raw, &amp;quot;data/books_raw.csv&amp;quot;)
```
```{r load-book-data-real, include=FALSE}
books_raw &amp;lt;- read_csv(&amp;quot;data/books_raw.csv&amp;quot;)
```
&lt;/code>&lt;/pre>
&lt;h3 id="clean-data">Clean data&lt;/h3>
&lt;p>The data you get from Project Gutenberg comes in a tidy format, with a column for the book id, a column for the title, and a column for text. Sometimes this text column will be divided by lines in the book; sometimes it might be an entire page or paragraph or chapter. It all depends on how the book is formatted at Project Gutenberg.&lt;/p>
&lt;p>Here&amp;rsquo;s what the start of our &lt;code>little_women_raw&lt;/code> data looks like:&lt;/p>
&lt;pre>&lt;code class="language-r">head(little_women_raw)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 3
## gutenberg_id text title
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 514 LITTLE WOMEN Little Women
## 2 514 &amp;lt;NA&amp;gt; Little Women
## 3 514 &amp;lt;NA&amp;gt; Little Women
## 4 514 by Little Women
## 5 514 &amp;lt;NA&amp;gt; Little Women
## 6 514 Louisa May Alcott Little Women
&lt;/code>&lt;/pre>
&lt;p>If we look at the data in RStudio, we can see that the actual book doesn&amp;rsquo;t start until row 70 (the first 69 rows are the table of contents and other parts of the front matter).&lt;/p>
&lt;p>It would be nice if we had a column that indicated what chapter each line is in, since we could then group by chapter and look at patterns within chapters. Since the data doesn&amp;rsquo;t come with a chapter column, we have to make one ourselves using a fun little trick. Each chapter in the book starts with &amp;ldquo;CHAPTER ONE&amp;rdquo; or &amp;ldquo;CHAPTER TWO&amp;rdquo;, with &amp;ldquo;chapter&amp;rdquo; in ALL CAPS. We can make a variable named &lt;code>chapter_start&lt;/code> that will be true if a line starts with &amp;ldquo;CHAPTER&amp;rdquo; and false if not. Then we can use the &lt;code>cumsum()&lt;/code> function to take the cumulative sum of this column, which will increment up one number ever time there&amp;rsquo;s a new chapter, thus creating a helpful chapter column.&lt;/p>
&lt;pre>&lt;code class="language-r"># Clean up Little Women
little_women &amp;lt;- little_women_raw %&amp;gt;%
# The actual book doesn't start until line 70
slice(70:n()) %&amp;gt;%
# Get rid of rows where text is missing
drop_na(text) %&amp;gt;%
# Chapters start with CHAPTER X, so mark if each row is a chapter start
# cumsum() calculates the cumulative sum, so it'll increase every time there's
# a new chapter and automatically make chapter numbers
mutate(chapter_start = str_detect(text, &amp;quot;^CHAPTER&amp;quot;),
chapter_number = cumsum(chapter_start)) %&amp;gt;%
# Get rid of these columns
select(-gutenberg_id, -title, -chapter_start)
head(little_women)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 2
## text chapter_number
## &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt;
## 1 &amp;quot;CHAPTER ONE&amp;quot; 1
## 2 &amp;quot;PLAYING PILGRIMS&amp;quot; 1
## 3 &amp;quot;\&amp;quot;Christmas won't be Christmas without any presents,\&amp;quot; grumbled Jo, lying&amp;quot; 1
## 4 &amp;quot;on the rug.&amp;quot; 1
## 5 &amp;quot;\&amp;quot;It's so dreadful to be poor!\&amp;quot; sighed Meg, looking down at her old&amp;quot; 1
## 6 &amp;quot;dress.&amp;quot; 1
&lt;/code>&lt;/pre>
&lt;p>The data from Shakespeare is similarly messy, with just three columns:&lt;/p>
&lt;pre>&lt;code class="language-r">head(tragedies_raw)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 3
## gutenberg_id text title
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 1513 ROMEO AND JULIET Romeo and Juliet
## 2 1513 &amp;lt;NA&amp;gt; Romeo and Juliet
## 3 1513 by William Shakespeare Romeo and Juliet
## 4 1513 &amp;lt;NA&amp;gt; Romeo and Juliet
## 5 1513 &amp;lt;NA&amp;gt; Romeo and Juliet
## 6 1513 &amp;lt;NA&amp;gt; Romeo and Juliet
&lt;/code>&lt;/pre>
&lt;p>The initial text sometimes isn&amp;rsquo;t the actual text of the book. If you look at the beginning of &lt;em>Hamlet&lt;/em>, for instance, there&amp;rsquo;s a bunch of introductory stuff from editors and transcribers. In real life, we&amp;rsquo;d want to find a systematic way to get rid of that (perhaps by looking at how many introductory rows there are in each of the four plays and removing those rows), but for now, we&amp;rsquo;ll just live with it and pretend Shakespeare wrote these notes. ðŸ¤·&lt;/p>
&lt;p>We could also figure out a systematic way to indicate acts and scenes, but that&amp;rsquo;s tricky, so we won&amp;rsquo;t for this example. (&lt;a href="https://peerchristensen.netlify.app/post/fair-is-foul-and-foul-is-fair-a-tidytext-entiment-analysis-of-shakespeare-s-tragedies/" target="_blank" rel="noopener">This guy did though!&lt;/a>)&lt;/p>
&lt;p>Now that we have tidy text data, let&amp;rsquo;s do stuff with it!&lt;/p>
&lt;h3 id="tokens-and-word-counts">Tokens and word counts&lt;/h3>
&lt;h4 id="single-words">Single words&lt;/h4>
&lt;p>One way we can visualize text is to look at word frequencies and find the most common words. This is even more important when looking across documents.&lt;/p>
&lt;p>Right now the text we have is tidy, but it is based on lines of text, not words. In order to count words correctly, we need each token (or text element, whether it be a word or bigram or paragraph or whatever) to be in its own row. The &lt;code>unnest_tokens()&lt;/code> functions from &lt;strong>tidytext&lt;/strong> does this for us. The first argument is the name of the column we want to create; the second argument is the name of the column we want to split into tokens.&lt;/p>
&lt;p>Let&amp;rsquo;s just work with the Shakespeare tragedies:&lt;/p>
&lt;pre>&lt;code class="language-r">tragedies_words &amp;lt;- tragedies_raw %&amp;gt;%
drop_na(text) %&amp;gt;%
unnest_tokens(word, text)
head(tragedies_words)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 3
## gutenberg_id title word
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 1513 Romeo and Juliet romeo
## 2 1513 Romeo and Juliet and
## 3 1513 Romeo and Juliet juliet
## 4 1513 Romeo and Juliet by
## 5 1513 Romeo and Juliet william
## 6 1513 Romeo and Juliet shakespeare
&lt;/code>&lt;/pre>
&lt;p>Now that we have words, we can filter and count the words. Here&amp;rsquo;s what&amp;rsquo;s happening in this next chunk:&lt;/p>
&lt;ul>
&lt;li>We use &lt;code>anti_join()&lt;/code> to remove all common stop words like &amp;ldquo;a&amp;rdquo; and &amp;ldquo;the&amp;rdquo; that are listed in the &lt;code>stop_words&lt;/code> dataset that is loaded when you load &lt;strong>tidytext&lt;/strong>&lt;/li>
&lt;li>We count how many times each word appears in each title/play&lt;/li>
&lt;li>We only keep the top 15 words&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">top_words_tragedies &amp;lt;- tragedies_words %&amp;gt;%
# Remove stop words
anti_join(stop_words) %&amp;gt;%
# Get rid of old timey words and stage directions
filter(!(word %in% c(&amp;quot;thou&amp;quot;, &amp;quot;thy&amp;quot;, &amp;quot;haue&amp;quot;, &amp;quot;thee&amp;quot;,
&amp;quot;thine&amp;quot;, &amp;quot;enter&amp;quot;, &amp;quot;exeunt&amp;quot;, &amp;quot;exit&amp;quot;))) %&amp;gt;%
# Count all the words in each play
count(title, word, sort = TRUE) %&amp;gt;%
# Keep top 15 in each play
group_by(title) %&amp;gt;%
top_n(15) %&amp;gt;%
ungroup() %&amp;gt;%
# Make the words an ordered factor so they plot in order
mutate(word = fct_inorder(word))
top_words_tragedies
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 63 x 3
## title word n
## &amp;lt;chr&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;int&amp;gt;
## 1 Hamlet, Prince of Denmark ham 358
## 2 Romeo and Juliet romeo 296
## 3 Macbeth macbeth 282
## 4 The Tragedy of King Lear lear 230
## 5 Hamlet, Prince of Denmark lord 223
## 6 Hamlet, Prince of Denmark king 197
## 7 Romeo and Juliet juliet 178
## 8 The Tragedy of King Lear kent 174
## 9 Romeo and Juliet nurse 149
## 10 Romeo and Juliet capulet 145
## # â€¦ with 53 more rows
&lt;/code>&lt;/pre>
&lt;p>Now we can plot these results, facetting and filling by title:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(top_words_tragedies, aes(y = fct_rev(word), x = n, fill = title)) +
geom_col() +
guides(fill = &amp;quot;none&amp;quot;) +
labs(y = &amp;quot;Count&amp;quot;, x = NULL,
title = &amp;quot;15 most frequent words in four Shakespearean tragedies&amp;quot;) +
facet_wrap(vars(title), scales = &amp;quot;free_y&amp;quot;) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/13-example_files/figure-html/plot-top-words-tragedies-1.png" width="672" style="display: block; margin: auto;" />
&lt;p>These results aren&amp;rsquo;t terribly surprising. &amp;ldquo;lear&amp;rdquo; is the most common word in &lt;em>King Lear&lt;/em>, &amp;ldquo;macbeth&amp;rdquo; is the most common word in &lt;em>Macbeth&lt;/em>, and so on. But the results are still really neat! This is a wordcloud for grownups!&lt;/p>
&lt;p>(Sharp-eyed readers will notice that the words aren&amp;rsquo;t actually in perfect order! That&amp;rsquo;s because some common words are repeated across the plays, like &amp;ldquo;lord&amp;rdquo; and &amp;ldquo;sir&amp;rdquo;. However, each category in a factor can only have one possible position in the orer, so because &amp;ldquo;lord&amp;rdquo; is the second most common word in &lt;em>Hamlet&lt;/em> it also appears as #2 in &lt;em>Macbeth&lt;/em> and &lt;em>King Lear&lt;/em>. You can fix this with the &lt;code>reorder_within()&lt;/code> function in &lt;strong>tidytext&lt;/strong>â€”see &lt;a href="https://juliasilge.com/blog/reorder-within/" target="_blank" rel="noopener">Julia Silge&amp;rsquo;s tutorial here&lt;/a> for how to use it.)&lt;/p>
&lt;h4 id="bigrams">Bigrams&lt;/h4>
&lt;p>We can also look at pairs of words instead of single words. To do this, we need to change a couple arguments in &lt;code>unnest_tokens()&lt;/code>, but otherwise everything else stays the same. In order to remove stopwords, we need to split the bigram column into two columns (&lt;code>word1&lt;/code> and &lt;code>word2&lt;/code>) with &lt;code>separate()&lt;/code>, filter each of those columns, and then combine the word columns back together as &lt;code>bigram&lt;/code> with &lt;code>unite()&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-r">tragedies_bigrams &amp;lt;- tragedies_raw %&amp;gt;%
drop_na(text) %&amp;gt;%
# n = 2 here means bigrams. We could also make trigrams (n = 3) or any type of n-gram
unnest_tokens(bigram, text, token = &amp;quot;ngrams&amp;quot;, n = 2) %&amp;gt;%
# Get rid of NAs in the new bigram column
drop_na(bigram) %&amp;gt;%
# Split the bigrams into two words so we can remove stopwords
separate(bigram, c(&amp;quot;word1&amp;quot;, &amp;quot;word2&amp;quot;), sep = &amp;quot; &amp;quot;) %&amp;gt;%
filter(!word1 %in% stop_words$word,
!word2 %in% stop_words$word) %&amp;gt;%
filter(!word1 %in% c(&amp;quot;thou&amp;quot;, &amp;quot;thy&amp;quot;, &amp;quot;thine&amp;quot;, &amp;quot;enter&amp;quot;, &amp;quot;exeunt&amp;quot;, &amp;quot;exit&amp;quot;),
!word2 %in% c(&amp;quot;thou&amp;quot;, &amp;quot;thy&amp;quot;, &amp;quot;thine&amp;quot;, &amp;quot;enter&amp;quot;, &amp;quot;exeunt&amp;quot;, &amp;quot;exit&amp;quot;)) %&amp;gt;%
# Put the two word columns back together
unite(bigram, word1, word2, sep = &amp;quot; &amp;quot;)
tragedies_bigrams
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 9,579 x 3
## gutenberg_id title bigram
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 1513 Romeo and Juliet william shakespeare
## 2 1513 Romeo and Juliet persons represented
## 3 1513 Romeo and Juliet escalus prince
## 4 1513 Romeo and Juliet nobleman kinsman
## 5 1513 Romeo and Juliet montague heads
## 6 1513 Romeo and Juliet romeo son
## 7 1513 Romeo and Juliet mercutio kinsman
## 8 1513 Romeo and Juliet benvolio nephew
## 9 1513 Romeo and Juliet tybalt nephew
## 10 1513 Romeo and Juliet lady capulet
## # â€¦ with 9,569 more rows
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">top_bigrams &amp;lt;- tragedies_bigrams %&amp;gt;%
# Count all the bigrams in each play
count(title, bigram, sort = TRUE) %&amp;gt;%
# Keep top 15 in each play
group_by(title) %&amp;gt;%
top_n(15) %&amp;gt;%
ungroup() %&amp;gt;%
# Make the bigrams an ordered factor so they plot in order
mutate(bigram = fct_inorder(bigram))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Selecting by n
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">ggplot(top_bigrams, aes(y = fct_rev(bigram), x = n, fill = title)) +
geom_col() +
guides(fill = &amp;quot;none&amp;quot;) +
labs(y = &amp;quot;Count&amp;quot;, x = NULL,
title = &amp;quot;15 most frequent bigrams in four Shakespearean tragedies&amp;quot;) +
facet_wrap(vars(title), scales = &amp;quot;free&amp;quot;) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/13-example_files/figure-html/top-bigrams-1.png" width="672" style="display: block; margin: auto;" />
&lt;p>There are some neat trends here. &amp;ldquo;Lord Hamlet&amp;rdquo; is the most common pair of words in &lt;em>Hamlet&lt;/em> (not surprisingly), but in Macbeth the repeated &amp;ldquo;knock knock&amp;rdquo; (the first non-name repeated pair) is a well-known plot point and reoccurring symbolic theme throughout the play.&lt;/p>
&lt;h3 id="bigrams-and-probability">Bigrams and probability&lt;/h3>
&lt;p>We can replicate the &lt;a href="https://pudding.cool/2017/08/screen-direction/" target="_blank" rel="noopener">&amp;ldquo;She Giggles, He Gallops&amp;rdquo;&lt;/a> idea by counting the bigrams that match &amp;ldquo;he X&amp;rdquo; and &amp;ldquo;she X&amp;rdquo;.&lt;/p>
&lt;p>The log ratio idea shows how much more likely a word is compared to its counterpart (so &amp;ldquo;he that&amp;rdquo; is about 5 more likely to appear than &amp;ldquo;she that&amp;rdquo;. In this graph, I replaced the x-axis labels with &amp;ldquo;2x&amp;rdquo; and &amp;ldquo;4x&amp;rdquo;, but without those, you get numbers like 1, 2, and 3 (or -1, -2, -3)). To convert those logged ratio numbers into the multiplicative version (i.e. 2x instead of 1), raise 2 to the power of the log ratio. If the log ratio is 3, the human-readable version is &lt;code>\(2^3\)&lt;/code>, or 8 times.&lt;/p>
&lt;pre>&lt;code class="language-r"># Take the log of 8:
log2(8)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 3
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># Reverse log of 3:
2^3
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## [1] 8
&lt;/code>&lt;/pre>
&lt;p>The only text wizardry here is tokenizing the words. Pretty much the rest of all this code is just &lt;strong>dplyr&lt;/strong> mutating, filtering, and counting:&lt;/p>
&lt;pre>&lt;code class="language-r">pronouns &amp;lt;- c(&amp;quot;he&amp;quot;, &amp;quot;she&amp;quot;)
bigram_he_she_counts &amp;lt;- tragedies_raw %&amp;gt;%
drop_na(text) %&amp;gt;%
# Split into bigrams
unnest_tokens(bigram, text, token = &amp;quot;ngrams&amp;quot;, n = 2) %&amp;gt;%
# Find counts of bigrams
count(bigram, sort = TRUE) %&amp;gt;%
# Split the bigram column into two columns
separate(bigram, c(&amp;quot;word1&amp;quot;, &amp;quot;word2&amp;quot;), sep = &amp;quot; &amp;quot;) %&amp;gt;%
# Only choose rows where the first word is he or she
filter(word1 %in% pronouns) %&amp;gt;%
count(word1, word2, wt = n, sort = TRUE) %&amp;gt;%
rename(total = n)
word_ratios &amp;lt;- bigram_he_she_counts %&amp;gt;%
# Look at each of the second words
group_by(word2) %&amp;gt;%
# Only choose rows where the second word appears more than 10 times
filter(sum(total) &amp;gt; 10) %&amp;gt;%
ungroup() %&amp;gt;%
# Spread out the word1 column so that there's a column named &amp;quot;he&amp;quot; and one named &amp;quot;she&amp;quot;
spread(word1, total, fill = 0) %&amp;gt;%
# Add 1 to each number so that logs work (just in case any are zero)
mutate_if(is.numeric, ~(. + 1) / sum(. + 1)) %&amp;gt;%
# Create a new column that is the logged ratio of the she counts to he counts
mutate(logratio = log2(she / he)) %&amp;gt;%
# Sort by that ratio
arrange(desc(logratio))
# Rearrange this data so it's plottable
plot_word_ratios &amp;lt;- word_ratios %&amp;gt;%
# This gets the words in the right order---we take the absolute value, select
# only rows where the log ratio is bigger than 0, and then take the top 15 words
mutate(abslogratio = abs(logratio)) %&amp;gt;%
group_by(logratio &amp;lt; 0) %&amp;gt;%
top_n(15, abslogratio) %&amp;gt;%
ungroup() %&amp;gt;%
mutate(word = reorder(word2, logratio))
# Finally we plot this
ggplot(plot_word_ratios, aes(y = word, x = logratio, color = logratio &amp;lt; 0)) +
geom_segment(aes(y = word, yend = word,
x = 0, xend = logratio),
size = 1.1, alpha = 0.6) +
geom_point(size = 3.5) +
labs(x = &amp;quot;How much more/less likely&amp;quot;, y = NULL) +
scale_color_discrete(name = &amp;quot;&amp;quot;, labels = c(&amp;quot;More 'she'&amp;quot;, &amp;quot;More 'he'&amp;quot;)) +
scale_x_continuous(breaks = seq(-3, 3),
labels = c(&amp;quot;8x&amp;quot;, &amp;quot;4x&amp;quot;, &amp;quot;2x&amp;quot;,
&amp;quot;Same&amp;quot;, &amp;quot;2x&amp;quot;, &amp;quot;4x&amp;quot;, &amp;quot;8x&amp;quot;)) +
theme_bw() +
theme(legend.position = &amp;quot;bottom&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/13-example_files/figure-html/bigrams-he-she-1.png" width="672" style="display: block; margin: auto;" />
&lt;p>Shakespeare doesn&amp;rsquo;t use a lot of fancy verbs in his plays, so we&amp;rsquo;re left with incredibly common verbs like &amp;ldquo;should&amp;rdquo; and &amp;ldquo;comes&amp;rdquo; and &amp;ldquo;was&amp;rdquo;. Oh well.&lt;/p>
&lt;h3 id="term-frequency-inverse-document-frequency-tf-idf">Term frequency-inverse document frequency (tf-idf)&lt;/h3>
&lt;p>We can determine which words are the most unique for each book/document in our corpus using by calculating the tf-idf (term frequency-inverse document frequency) score for each term. The tf-idf is the product of the term frequency and the inverse document frequency:&lt;/p>
&lt;p>$$
&lt;code>\begin{aligned} tf(\text{term}) &amp;amp;= \frac{n_{\text{term}}}{n_{\text{terms in document}}} \\ idf(\text{term}) &amp;amp;= \ln{\left(\frac{n_{\text{documents}}}{n_{\text{documents containing term}}}\right)} \\ tf\text{-}idf(\text{term}) &amp;amp;= tf(\text{term}) \times idf(\text{term}) \end{aligned}&lt;/code>
$$&lt;/p>
&lt;p>Fortunately you don&amp;rsquo;t need to remember that formula. The &lt;code>bind_tf_idf()&lt;/code> function will calculate this for you. Remember, the higher the tf-idf number, the more unique the term is in the document, but these numbers are meaningless and unitlessâ€”you can&amp;rsquo;t convert them to a percentage or anything.&lt;/p>
&lt;p>Here are the most unique words in these four tragedies, compared to all the tragedies:&lt;/p>
&lt;pre>&lt;code class="language-r">tragedy_words &amp;lt;- tragedies_raw %&amp;gt;%
drop_na() %&amp;gt;%
# Split into word tokens
unnest_tokens(word, text) %&amp;gt;%
# Remove stop words and old timey words
anti_join(stop_words) %&amp;gt;%
filter(!word %in% c(&amp;quot;thou&amp;quot;, &amp;quot;thy&amp;quot;, &amp;quot;haue&amp;quot;, &amp;quot;thee&amp;quot;,
&amp;quot;thine&amp;quot;, &amp;quot;enter&amp;quot;, &amp;quot;exeunt&amp;quot;, &amp;quot;exit&amp;quot;)) %&amp;gt;%
count(title, word, sort = TRUE)
# Add the tf-idf values to the counts
tragedy_tf_idf &amp;lt;- tragedy_words %&amp;gt;%
bind_tf_idf(word, title, n)
# Get the top 10 uniquest words
tragedy_tf_idf_plot &amp;lt;- tragedy_tf_idf %&amp;gt;%
arrange(desc(tf_idf)) %&amp;gt;%
group_by(title) %&amp;gt;%
top_n(10) %&amp;gt;%
ungroup() %&amp;gt;%
mutate(word = fct_inorder(word))
ggplot(tragedy_tf_idf_plot,
aes(y = fct_rev(word), x = tf_idf, fill = title)) +
geom_col() +
guides(fill = &amp;quot;none&amp;quot;) +
labs(x = &amp;quot;tf-idf&amp;quot;, y = NULL) +
facet_wrap(~ title, scales = &amp;quot;free&amp;quot;) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/13-example_files/figure-html/tf-idf-tragedies-1.png" width="672" style="display: block; margin: auto;" />
&lt;p>Not surprisingly, the most unique words for each play happen to be the names of the characters in those plays.&lt;/p>
&lt;h3 id="sentiment-analysis">Sentiment analysis&lt;/h3>
&lt;p>In the video, I plotted the sentiment of &lt;em>Little Women&lt;/em> across the book, but it wasn&amp;rsquo;t a very interesting plot. We&amp;rsquo;ll try with Shakespeare here instead.&lt;/p>
&lt;p>At its core, sentiment analysis involves looking at a big list of words for how negative or positive they are. Some sentiment dictionaries mark if a word is &amp;ldquo;negative&amp;rdquo; or &amp;ldquo;positive&amp;rdquo;; some give words a score from -3 to 3; some give different emotions like &amp;ldquo;sadness&amp;rdquo; or &amp;ldquo;anger&amp;rdquo;. You can see what the different dictionaries look like with &lt;code>get_sentiments()&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-r">get_sentiments(&amp;quot;afinn&amp;quot;) # Scoring system
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 2,477 x 2
## word value
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt;
## 1 abandon -2
## 2 abandoned -2
## 3 abandons -2
## 4 abducted -2
## 5 abduction -2
## 6 abductions -2
## 7 abhor -3
## 8 abhorred -3
## 9 abhorrent -3
## 10 abhors -3
## # â€¦ with 2,467 more rows
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r"># get_sentiments(&amp;quot;bing&amp;quot;) # Negative/positive
# get_sentiments(&amp;quot;nrc&amp;quot;) # Specific emotions
# get_sentiments(&amp;quot;loughran&amp;quot;) # Designed for financial statements; positive/negative
&lt;/code>&lt;/pre>
&lt;p>Here we split the Shakespearean tragedies into words, join a sentiment dictionary to it, and use &lt;strong>dplyr&lt;/strong> data wrangling to calculate the net number positive words in each chapter. Had we used the AFINN library, we could calculate the average sentiment per chapter, since AFINN uses a scoring system instead of negative/positive labels. Or we could&amp;rsquo;ve used the NRC library, which has specific emotions like trust and fear.&lt;/p>
&lt;pre>&lt;code class="language-r">tragedy_words &amp;lt;- tragedies_raw %&amp;gt;%
drop_na() %&amp;gt;%
# Split into word tokens
unnest_tokens(word, text) %&amp;gt;%
# Remove stop words and old timey words
anti_join(stop_words) %&amp;gt;%
filter(!word %in% c(&amp;quot;thou&amp;quot;, &amp;quot;thy&amp;quot;, &amp;quot;haue&amp;quot;, &amp;quot;thee&amp;quot;,
&amp;quot;thine&amp;quot;, &amp;quot;enter&amp;quot;, &amp;quot;exeunt&amp;quot;, &amp;quot;exit&amp;quot;))
# Join the sentiment dictionary
tragedy_sentiment &amp;lt;- tragedy_words %&amp;gt;%
inner_join(get_sentiments(&amp;quot;bing&amp;quot;))
tragedy_sentiment
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 7,736 x 4
## gutenberg_id title word sentiment
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 1513 Romeo and Juliet dignity positive
## 2 1513 Romeo and Juliet fair positive
## 3 1513 Romeo and Juliet grudge negative
## 4 1513 Romeo and Juliet break negative
## 5 1513 Romeo and Juliet unclean negative
## 6 1513 Romeo and Juliet fatal negative
## 7 1513 Romeo and Juliet overthrows negative
## 8 1513 Romeo and Juliet death negative
## 9 1513 Romeo and Juliet strife negative
## 10 1513 Romeo and Juliet fearful negative
## # â€¦ with 7,726 more rows
&lt;/code>&lt;/pre>
&lt;p>We can look at these sentiments a few different ways. First we can get a count of total positive and negative words in the four books. We can see that in all four, there are more negative words than positive ones (they&amp;rsquo;re tragdies, after all):&lt;/p>
&lt;pre>&lt;code class="language-r">tragedy_sentiment_plot &amp;lt;- tragedy_sentiment %&amp;gt;%
count(title, sentiment)
ggplot(tragedy_sentiment_plot, aes(x = sentiment, y = n, fill = title, alpha = sentiment)) +
geom_col(position = position_dodge()) +
scale_alpha_manual(values = c(0.5, 1)) +
facet_wrap(vars(title)) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/13-example_files/figure-html/shakespeare-sentiment-plot-bars-1.png" width="672" style="display: block; margin: auto;" />
&lt;p>Perhaps more usefully, we can divide each of the plays into groups of 100 lines, and then get the net sentiment of each group (number of positive words âˆ’ number of negative words). By splitting the data into groups of lines, we can show a more granular view of the progression of the plot. To do this we make a column that indicates the row number, and then we use the special &lt;code>%/%&lt;/code> operator to perform integer division, which essentially lops off the decimal point when dividing numbers: 150/100 normally is 1.5, but in integer divison, it is 1. This is a helpful trick for putting rows 1-99 in one group, then rows 100-199 in another group, etc.&lt;/p>
&lt;pre>&lt;code class="language-r">tragedies_split_into_lines &amp;lt;- tragedy_sentiment %&amp;gt;%
# Divide lines into groups of 100
mutate(line = row_number(),
line_chunk = line %/% 100) %&amp;gt;%
# Get a count of postiive and negative words in each 100-line chunk in each play
count(title, line_chunk, sentiment) %&amp;gt;%
# Convert the sentiment column into two columns named &amp;quot;positive&amp;quot; and &amp;quot;negative&amp;quot;
pivot_wider(names_from = sentiment, values_from = n) %&amp;gt;%
# Calculate net sentiment
mutate(sentiment = positive - negative)
ggplot(tragedies_split_into_lines,
aes(x = line_chunk, y = sentiment, fill = sentiment)) +
geom_col() +
scale_fill_viridis_c(option = &amp;quot;magma&amp;quot;, end = 0.9) +
facet_wrap(vars(title), scales = &amp;quot;free_x&amp;quot;) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/13-example_files/figure-html/shakespeare-sentiment-plot-lines-1.png" width="672" style="display: block; margin: auto;" />
&lt;p>Neat. They&amp;rsquo;re all really sad and negative, except for the beginning of Romeo and Juliet where the two lovers meet and fall in love. Then everyone dies later.&lt;/p>
&lt;h3 id="neat-extra-stuff">Neat extra stuff&lt;/h3>
&lt;p>None of this stuff was in the video, but it&amp;rsquo;s useful to know and see how to do it. It all generally comes from the &lt;a href="https://www.tidytextmining.com/" target="_blank" rel="noopener">&lt;em>Tidy Text Mining&lt;/em> book&lt;/a> by Julia Silge and David Robinson&lt;/p>
&lt;h4 id="part-of-speech-tagging">Part of speech tagging&lt;/h4>
&lt;p>R has no way of knowing if words are nouns, verbs, or adjectives. You can algorithmically predict what part of speech each word is using a part-of-speech tagger, like &lt;a href="https://spacy.io/" target="_blank" rel="noopener">&lt;strong>spaCy&lt;/strong>&lt;/a> or &lt;a href="https://nlp.stanford.edu/" target="_blank" rel="noopener">Stanford&amp;rsquo;s Natural Langauge Processing (NLP) library&lt;/a>.&lt;/p>
&lt;p>These are external programs that are not written in R and don&amp;rsquo;t naturally communicate with R (spaCy is written in Python; Stanford&amp;rsquo;s CoreNLP is written in Java). There is a helpful R package named &lt;strong>cleanNLP&lt;/strong> that helps you interact with these programs from within R, whis is super helpful. &lt;strong>cleanNLP&lt;/strong> also comes with its own R-only tagger so you don&amp;rsquo;t need to install anything with Python or Java (however, it&amp;rsquo;s not as powerful as either spaCy, which is faster, and doesn&amp;rsquo;t deal with foreign languages like Arabic and Chinese like Stanford&amp;rsquo;s NLP library).&lt;/p>
&lt;p>You can see other examples of part-of-speech tagging (along with instructions for how to install spaCy and coreNLP) here:&lt;/p>
&lt;ul>
&lt;li>&lt;i class="fas fa-external-link-square-alt">&lt;/i> &lt;a href="https://www.andrewheiss.com/blog/2018/12/26/tidytext-pos-john/" target="_blank" rel="noopener">&amp;ldquo;Tidy text, parts of speech, and unique words in the Bible&amp;rdquo;&lt;/a>&lt;/li>
&lt;li>&lt;i class="fas fa-external-link-square-alt">&lt;/i> &lt;a href="https://www.andrewheiss.com/blog/2018/12/28/tidytext-pos-arabic/" target="_blank" rel="noopener">&amp;ldquo;Tidy text, parts of speech, and unique words in the Qur&amp;rsquo;an&amp;rdquo;&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Here&amp;rsquo;s the general process for tagging (or &amp;ldquo;annotating&amp;rdquo;) text with the &lt;strong>cleanNLP&lt;/strong> package:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Make a dataset where one column is the id (line number, chapter number, book+chapter, etc.), and another column is the text itself.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Initialize the NLP tagger. You can use any of these:&lt;/p>
&lt;ul>
&lt;li>&lt;code>cnlp_init_udpipe()&lt;/code>: Use an R-only tagger that should work without installing anything extra (a little slower than the others, but requires no extra steps!)&lt;/li>
&lt;li>&lt;code>cnlp_init_spacy()&lt;/code>: Use spaCy (if you&amp;rsquo;ve installed it on your computer with Python)&lt;/li>
&lt;li>&lt;code>cnlp_init_corenlp()&lt;/code>: Use Stanford&amp;rsquo;s NLP library (if you&amp;rsquo;ve installed it on your computer with Java)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Feed the data frame from step 1 into the &lt;code>cnlp_annotate()&lt;/code> function and wait.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Save the tagged data on your computer so you don&amp;rsquo;t have to re-tag it every time.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>Here&amp;rsquo;s an example using the &lt;em>Little Women&lt;/em> data:&lt;/p>
&lt;pre>&lt;code class="language-r"># For the tagger to work, each row needs to be unique, which means we need to
# combine all the text into individual chapter-based rows. This takes a little
# bit of text-wrangling with dplyr:
little_women_to_tag &amp;lt;- little_women %&amp;gt;%
# Group by chapter number
group_by(chapter_number) %&amp;gt;%
# Take all the rows in each chapter and collapse them into a single cell
nest(data = c(text)) %&amp;gt;%
ungroup() %&amp;gt;%
# Look at each individual cell full of text lines and paste them together into
# one really long string of text per chapter
mutate(text = map_chr(data, ~paste(.$text, collapse = &amp;quot; &amp;quot;))) %&amp;gt;%
# Get rid of this column
select(-data)
little_women_to_tag
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 47 x 2
## chapter_number text
## &amp;lt;int&amp;gt; &amp;lt;chr&amp;gt;
## 1 1 &amp;quot;CHAPTER ONE PLAYING PILGRIMS \&amp;quot;Christmas won't be Christmas without any presents,\&amp;quot; grumbled Jo, lying on the rug. \&amp;quot;It's so dreadâ€¦
## 2 2 &amp;quot;CHAPTER TWO A MERRY CHRISTMAS Jo was the first to wake in the gray dawn of Christmas morning. No stockings hung at the fireplace, â€¦
## 3 3 &amp;quot;CHAPTER THREE THE LAURENCE BOY \&amp;quot;Jo! Jo! Where are you?\&amp;quot; cried Meg at the foot of the garret stairs. \&amp;quot;Here!\&amp;quot; answered a huskyâ€¦
## 4 4 &amp;quot;CHAPTER FOUR BURDENS \&amp;quot;Oh, dear, how hard it does seem to take up our packs and go on,\&amp;quot; sighed Meg the morning after the party, fâ€¦
## 5 5 &amp;quot;CHAPTER FIVE BEING NEIGHBORLY \&amp;quot;What in the world are you going to do now, Jo?\&amp;quot; asked Meg one snowy afternoon, as her sister cameâ€¦
## 6 6 &amp;quot;CHAPTER SIX BETH FINDS THE PALACE BEAUTIFUL The big house did prove a Palace Beautiful, though it took some time for all to get inâ€¦
## 7 7 &amp;quot;CHAPTER SEVEN AMY'S VALLEY OF HUMILIATION \&amp;quot;That boy is a perfect cyclops, isn't he?\&amp;quot; said Amy one day, as Laurie clattered by onâ€¦
## 8 8 &amp;quot;CHAPTER EIGHT JO MEETS APOLLYON \&amp;quot;Girls, where are you going?\&amp;quot; asked Amy, coming into their room one Saturday afternoon, and findâ€¦
## 9 9 &amp;quot;CHAPTER NINE MEG GOES TO VANITY FAIR \&amp;quot;I do think it was the most fortunate thing in the world that those children should have theâ€¦
## 10 10 &amp;quot;CHAPTER TEN THE P.C. AND P.O. As spring came on, a new set of amusements became the fashion, and the lengthening days gave long afâ€¦
## # â€¦ with 37 more rows
&lt;/code>&lt;/pre>
&lt;p>Notice how there&amp;rsquo;s now a row for each chapter, and the whole chapter is contained in the &lt;code>text&lt;/code> column. With the data in this format, we can annotate it. It takes about 3 minutes to run this on my 2016 MacBook Pro with the R-only udpipe tagger (and only 30 seconds if I use the spaCy tagger). Notice how I immediately save the tagged tokens as a CSV file after so I don&amp;rsquo;t have to do it again.&lt;/p>
&lt;pre>&lt;code class="language-r">library(cleanNLP)
# Use the built-in R-based tagger
cnlp_init_udpipe()
little_women_tagged &amp;lt;- cnlp_annotate(little_women_to_tag,
text_name = &amp;quot;text&amp;quot;,
doc_name = &amp;quot;chapter_number&amp;quot;)
write_csv(little_women_tagged$token, &amp;quot;little_women_tagged.csv&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Here&amp;rsquo;s what the tagged text looks like:&lt;/p>
&lt;pre>&lt;code class="language-r">little_women_tagged
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 232,093 x 10
## doc_id sid tid token token_with_ws lemma upos xpos tid_source relation
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
## 1 1 1 1 &amp;quot;CHAPTER&amp;quot; &amp;quot;CHAPTER&amp;quot; &amp;quot;chapter&amp;quot; NOUN NN 4 nmod
## 2 1 1 2 &amp;quot;ONE&amp;quot; &amp;quot;ONE&amp;quot; &amp;quot;one&amp;quot; NUM CD 1 nummod
## 3 1 1 3 &amp;quot;PLAYING&amp;quot; &amp;quot;PLAYING&amp;quot; &amp;quot;playing&amp;quot; NOUN NN 4 compound
## 4 1 1 4 &amp;quot;PILGRIMS&amp;quot; &amp;quot;PILGRIMS&amp;quot; &amp;quot;pilgrims&amp;quot; NOUN NN 0 root
## 5 1 1 5 &amp;quot;\&amp;quot;&amp;quot; &amp;quot;\&amp;quot;&amp;quot; &amp;quot;\&amp;quot;&amp;quot; PUNCT `` 4 punct
## 6 1 2 1 &amp;quot;Christmas&amp;quot; &amp;quot;Christmas&amp;quot; &amp;quot;Christmas&amp;quot; PROPN NNP 4 nsubj
## 7 1 2 2 &amp;quot;wo&amp;quot; &amp;quot;wo&amp;quot; &amp;quot;will&amp;quot; VERB MD 4 aux
## 8 1 2 3 &amp;quot;n't&amp;quot; &amp;quot;n't&amp;quot; &amp;quot;not&amp;quot; PART RB 4 neg
## 9 1 2 4 &amp;quot;be&amp;quot; &amp;quot;be&amp;quot; &amp;quot;be&amp;quot; AUX VB 0 root
## 10 1 2 5 &amp;quot;Christmas&amp;quot; &amp;quot;Christmas&amp;quot; &amp;quot;Christmas&amp;quot; PROPN NNP 4 attr
## # â€¦ with 232,083 more rows
&lt;/code>&lt;/pre>
&lt;p>There are a bunch of new columns like &lt;code>lemma&lt;/code> (or the base stemmed word), and &lt;code>upos&lt;/code> and &lt;code>pos&lt;/code> for the different parts of speech. These use the &lt;a href="https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html" target="_blank" rel="noopener">Penn Treebank codes&lt;/a>.&lt;/p>
&lt;p>Now that everything is tagged, we can do any grouping and summarizing and filtering we want. We could find the most common verbs, or the most common nouns or proper names, for instance. Here&amp;rsquo;s a fun plot that shows the proportion of mentions of the four main characters (Meg, Jo, Beth, and Amy) in each chapter.&lt;/p>
&lt;pre>&lt;code class="language-r"># Find all proper nouns
proper_nouns &amp;lt;- little_women_tagged %&amp;gt;%
filter(upos == &amp;quot;PROPN&amp;quot;)
main_characters_by_chapter &amp;lt;- proper_nouns %&amp;gt;%
# Find only Meg, Jo, Beth, and Amy
filter(lemma %in% c(&amp;quot;Meg&amp;quot;, &amp;quot;Jo&amp;quot;, &amp;quot;Beth&amp;quot;, &amp;quot;Amy&amp;quot;)) %&amp;gt;%
# Group by chapter and character name
group_by(doc_id, lemma) %&amp;gt;%
# Get the count of mentions
summarize(n = n()) %&amp;gt;%
# Make a new column named &amp;quot;name&amp;quot; that is an ordered factor of the girls' names
mutate(name = factor(lemma, levels = c(&amp;quot;Meg&amp;quot;, &amp;quot;Jo&amp;quot;, &amp;quot;Beth&amp;quot;, &amp;quot;Amy&amp;quot;), ordered = TRUE)) %&amp;gt;%
# Rename this so it's called chapter
rename(chapter = doc_id) %&amp;gt;%
# Group by chapter
group_by(chapter) %&amp;gt;%
# Calculate the proportion of each girl's mentions in each chapter
mutate(prop = n / sum(n)) %&amp;gt;%
ungroup() %&amp;gt;%
# Make a cleaner chapter name column
mutate(chapter_name = paste(&amp;quot;Chapter&amp;quot;, chapter)) %&amp;gt;%
mutate(chapter_name = fct_inorder(chapter_name))
main_characters_by_chapter
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 177 x 6
## chapter lemma n name prop chapter_name
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;int&amp;gt; &amp;lt;ord&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt;
## 1 1 Amy 23 Amy 0.195 Chapter 1
## 2 1 Beth 26 Beth 0.220 Chapter 1
## 3 1 Jo 43 Jo 0.364 Chapter 1
## 4 1 Meg 26 Meg 0.220 Chapter 1
## 5 2 Amy 13 Amy 0.197 Chapter 2
## 6 2 Beth 12 Beth 0.182 Chapter 2
## 7 2 Jo 21 Jo 0.318 Chapter 2
## 8 2 Meg 20 Meg 0.303 Chapter 2
## 9 3 Amy 2 Amy 0.0202 Chapter 3
## 10 3 Beth 2 Beth 0.0202 Chapter 3
## # â€¦ with 167 more rows
&lt;/code>&lt;/pre>
&lt;p>And here&amp;rsquo;s the polished plot:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(main_characters_by_chapter, aes(x = prop, y = &amp;quot;1&amp;quot;, fill = fct_rev(name))) +
geom_col(position = position_stack()) +
scale_x_continuous(expand = c(0, 0)) +
scale_y_discrete(expand = c(0, 0)) +
scale_fill_viridis_d(option = &amp;quot;plasma&amp;quot;, end = 0.9, name = NULL) +
guides(fill = guide_legend(reverse = TRUE)) +
labs(x = NULL, y = NULL,
title = &amp;quot;Proportion of mentions of each\nLittle Woman per chapter&amp;quot;,
subtitle = &amp;quot;Jo basically dominates the last third of the book&amp;quot;) +
facet_wrap(vars(chapter_name), nrow = 6) +
theme_bw(base_family = &amp;quot;Roboto Condensed&amp;quot;) +
theme(legend.position = &amp;quot;top&amp;quot;,
axis.text = element_blank(),
axis.ticks = element_blank(),
strip.background = element_rect(fill = &amp;quot;white&amp;quot;),
legend.text = element_text(face = &amp;quot;bold&amp;quot;, size = rel(1)),
plot.title = element_text(face = &amp;quot;bold&amp;quot;, hjust = 0.5, size = rel(1.7)),
plot.subtitle = element_text(hjust = 0.5, size = rel(1.1)))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/13-example_files/figure-html/lw-props-plot-1.png" width="768" style="display: block; margin: auto;" />
&lt;h4 id="topic-modeling-and-fingerprinting">Topic modeling and fingerprinting&lt;/h4>
&lt;p>If you want to see some examples of topic modeling with Latent Dirichlet Allocation (LDA) or text fingerprinting based on sentence length and counts of hapax legomena (&lt;a href="https://kops.uni-konstanz.de/bitstream/handle/123456789/5492/Literature_Fingerprinting.pdf" target="_blank" rel="noopener">based on this article&lt;/a>), see these examples from a previous version of this class: &lt;a href="https://datavizf18.classes.andrewheiss.com/class/11-class/#topic-modeling" target="_blank" rel="noopener">topic modeling&lt;/a> and &lt;a href="https://datavizf18.classes.andrewheiss.com/class/11-class/#fingerprinting" target="_blank" rel="noopener">fingerprinting&lt;/a>&lt;/p>
&lt;h4 id="text-features">Text features&lt;/h4>
&lt;p>Finally, you can use &lt;a href="https://github.com/mkearney/textfeatures" target="_blank" rel="noopener">the &lt;strong>textfeatures&lt;/strong> package&lt;/a> to find all sorts of interesting numeric statistics about text, like the number of exclamation points, commas, digits, characters per word, uppercase letters, lowercase letters, and more!&lt;/p></description></item><item><title>Enhancing graphics</title><link>https://aem2850.toddgerarden.com/example/14-example/</link><pubDate>Mon, 19 Jul 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/14-example/</guid><description>&lt;h2 id="why-enhance-graphics">Why enhance graphics?&lt;/h2>
&lt;p>The content from today isn&amp;rsquo;t really code-based at all. Instead, you&amp;rsquo;re learning about how to take a plot from R and make it &lt;em>fancy&lt;/em> in a vector editing program like Illustrator, Gravit Designer, or Inkscape.&lt;/p>
&lt;p>This concept comes from a common workflow in the real world, where organizations like news outlets, think tanks, research centers, or nonprofits will publish highly polished plots in annual reports, magazines, and other types of publications. These graphics often have to follow specific in-house style guidelines and use specific colors and fonts and other design elements. Even if you don&amp;rsquo;t work for a place with in-house style guides, you&amp;rsquo;ll often want to make some edits to your plots by hand after you create them.&lt;/p>
&lt;p>The general workflow goes like this:&lt;/p>
&lt;ol>
&lt;li>Create a plot in R and ggplot&lt;/li>
&lt;li>Export that plot as a vector image (either a PDF or an SVG)&lt;/li>
&lt;li>Edit and enhance the vector image in a vector editor, like Adobe Illustrator&lt;/li>
&lt;li>Export the polished version from Illustrator as either a PDF or PNG (or both)&lt;/li>
&lt;/ol>
&lt;p>Big data-focused organizations have been using a process like this for years. Nathan Yau describes this whole process in his 2011 book &lt;a href="http://book.flowingdata.com/" target="_blank" rel="noopener">&lt;em>Visualize This&lt;/em>&lt;/a> and the book contains a bunch of tutorials to help you learn how create something in R, export it, and edit it in Illustrator.&lt;/p>
&lt;p>For instance, in his first chapter, he guides you through the process of creating the skeleton of this chart in R, exporting it as a PDF, and adding all the titles and annotations and arrows and extra lines in Illustrator (&lt;a href="https://flowingdata.com/2008/07/03/nathans-annual-hot-dog-eating-contest-kobayashi-vs-chestnut/" target="_blank" rel="noopener">original post from 2008&lt;/a>):&lt;/p>
&lt;img src="https://aem2850.toddgerarden.com/img/assignments/hot-dogs.gif" width="100%" />
&lt;h2 id="enhancing-graphics-in-2021">Enhancing graphics in 2021&lt;/h2>
&lt;p>In 2011, that was the best possible workflow because ggplot couldn&amp;rsquo;t deal with subtitles, captions, repelled labels, embedded fonts, and differently-styled text (like &lt;strong>bold&lt;/strong> in the middle of a title). Illustrator was the only way to do this stuff.&lt;/p>
&lt;p>Nowadays in 2021, though, you can do nearly all of this annotating and enhancing with packages like &lt;strong>ggtext&lt;/strong> and &lt;strong>patchwork&lt;/strong> and &lt;strong>ggrepel&lt;/strong>. You can almost perfectly replicate in-house style guides with the &lt;code>theme()&lt;/code> function and put text and arrows and labels and text boxes wherever you want with &lt;code>annotate()&lt;/code>. It&amp;rsquo;s a brave exciting new world.&lt;/p>
&lt;p>You still can&amp;rsquo;t do everything with R. ggplot can&amp;rsquo;t create fancy font ligatures like &amp;ldquo;ï¬&amp;rdquo; in words that have an &amp;ldquo;f&amp;rdquo; followed by an &amp;ldquo;i&amp;rdquo;, and it can&amp;rsquo;t handle automatic hyphenation and full text justification, among other limitations. But these are the minorest of graphic design issues (and &lt;a href="https://www.tidyverse.org/blog/2020/05/updates-to-ragg-and-systemfonts/" target="_blank" rel="noopener">the ggplot team is working on them&lt;/a>!).&lt;/p>
&lt;p>&lt;em>That all said&lt;/em>, it&amp;rsquo;s still often faster and easier to make edits to your graphs in Illustrator rather than fight with a reluctant &lt;code>annotate()&lt;/code> layer that just won&amp;rsquo;t put an arrow exactly where you want. And &lt;strong>ggtext&lt;/strong> is so new that lots of people haven&amp;rsquo;t heard of it yet. This is all cutting edge stuff.&lt;/p>
&lt;p>So it&amp;rsquo;s still a good idea to understand how to follow the standard workflow of exporting from R and enhancing in Illustrator.&lt;/p>
&lt;h2 id="abbreviated-example">Abbreviated example&lt;/h2>
&lt;p>In this video I use the code for the hot dog plot that I provide in today&amp;rsquo;s assignment to create a plot, export it, and make edits to it both in Illustrator and &lt;a href="https://www.designer.io/en/" target="_blank" rel="noopener">Gravit Designer&lt;/a>. It&amp;rsquo;s not a complete example at all, but I show you the general process for adding text and lines and editing plot elements.&lt;/p>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/L-tUSEMWrgE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div></description></item><item><title>Time</title><link>https://aem2850.toddgerarden.com/example/11-example/</link><pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/11-example/</guid><description>&lt;p>For this example, we&amp;rsquo;re going to use economic data from the US Federal Reserve (the Fed). The St. Louis Fed is in charge of publishing Fed economic data, and they host it all at an online portal named &lt;a href="https://fred.stlouisfed.org/" target="_blank" rel="noopener">FRED&lt;/a>. Instead of downloading individual time series data from the FRED website, we&amp;rsquo;ll do what with did with the World Bank WDI data and download it directly from the internet with the &lt;a href="https://business-science.github.io/tidyquant/" target="_blank" rel="noopener">&lt;strong>tidyquant&lt;/strong> package&lt;/a>, which includes a function for working with the FRED API/website.&lt;/p>
&lt;p>If you want to skip the data downloading, you can download the data below (you&amp;rsquo;ll likely need to right click and choose &amp;ldquo;Save Link Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/fred_raw.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>fred_raw.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/ObnRqO4zTY8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a slightly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="get-data">Get data&lt;/h3>
&lt;p>First, we load the libraries we&amp;rsquo;ll be using:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse) # For ggplot, dplyr, and friends
library(tidyquant) # For accessing FRED data
library(scales) # For nicer labels
&lt;/code>&lt;/pre>
&lt;p>The US Federal Reserve provides thousands of economic datasets at &lt;a href="https://fred.stlouisfed.org/" target="_blank" rel="noopener">FRED&lt;/a>. We can use the &lt;a href="https://business-science.github.io/tidyquant/" target="_blank" rel="noopener">&lt;strong>tidyquant&lt;/strong> R package&lt;/a> to access their servers and download the data directly into R.&lt;/p>
&lt;p>Like we did with the &lt;a href="https://aem2850.toddgerarden.com/example/08-example/">WDI indicators in session 8&lt;/a>, we need to find the special internal code for the variables we want to get. We need to pay close attention to the details of each variable, since the same measure can be offered with different combinations of real (adjusted for inflation) or nominal (not adjusted for inflation); monthly, quarterly, or annually; and seasonally adjusted or not seasonally adjusted. For instance, if you want to see US GDP, here are some possibilities (all the possible GDP measures are &lt;a href="https://fred.stlouisfed.org/categories/106" target="_blank" rel="noopener">listed here&lt;/a>):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://fred.stlouisfed.org/series/GDPC1" target="_blank" rel="noopener">&lt;code>GDPC1&lt;/code>: Real (2012 dollars), quarterly, seasonally adjusted&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://fred.stlouisfed.org/series/ND000334Q" target="_blank" rel="noopener">&lt;code>ND000334Q&lt;/code>: Real (2012 dollars), quarterly, not seasonally adjusted&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://fred.stlouisfed.org/series/GDPCA" target="_blank" rel="noopener">&lt;code>GDPCA&lt;/code>: Real (2012 dollars), annual, not seasonally adjusted&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://fred.stlouisfed.org/series/GDP" target="_blank" rel="noopener">&lt;code>GDP&lt;/code>: Nominal, quarterly, seasonally adjusted&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://fred.stlouisfed.org/series/GDPA" target="_blank" rel="noopener">&lt;code>GDPA&lt;/code>: Nominal, annual, not seasonally adjusted&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The code for getting data from FRED works a little differently than &lt;code>WDI()&lt;/code>, and the output is a little different too, but it&amp;rsquo;s hopefully not too complicated. We need to feed the &lt;code>tq_get()&lt;/code> function (1) a list of indicators we want, (2) a source for those indicators, and (3) a starting and/or ending date.&lt;/p>
&lt;p>&lt;code>tq_get()&lt;/code> can actually get data from a ton of different sources like stocks from Yahoo Finance and general financial data from &lt;a href="https://www.bloomberg.com/professional/solution/bloomberg-terminal" target="_blank" rel="noopener">Bloomberg&lt;/a>, &lt;a href="https://www.quandl.com/" target="_blank" rel="noopener">Quandl&lt;/a>, and &lt;a href="https://api.tiingo.com/" target="_blank" rel="noopener">Tiingo&lt;/a>. Most of those other sources require a subscription and a fancy API key that logs you into their servers when getting data, but FRED is free (yay public goods!).&lt;/p>
&lt;p>We&amp;rsquo;ll first make a new dataset named &lt;code>fred_raw&lt;/code> that gets a bunch of interesting variables from FRED from January 1, 1990 until today.&lt;/p>
&lt;pre>&lt;code class="language-r">fred_raw &amp;lt;- tq_get(c(&amp;quot;RSXFSN&amp;quot;, # Advance retail sales
&amp;quot;GDPC1&amp;quot;, # GDP
&amp;quot;ICSA&amp;quot;, # Initial unemployment claims
&amp;quot;FPCPITOTLZGUSA&amp;quot;, # Inflation
&amp;quot;UNRATE&amp;quot;, # Unemployment rate
&amp;quot;USREC&amp;quot;), # Recessions
get = &amp;quot;economic.data&amp;quot;, # Use FRED
from = &amp;quot;1990-01-01&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Downloading data from FRED every time you knit will get tedious and take a long time (plus if their servers are temporarily down, you won&amp;rsquo;t be able to get the data). As with the World Bank data we used, it&amp;rsquo;s good practice to save this raw data as a CSV file and then work with that.&lt;/p>
&lt;pre>&lt;code class="language-r">write_csv(fred_raw, &amp;quot;data/fred_raw.csv&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Since we care about reproducibility, we still want to include the code we used to get data from FRED, we just don&amp;rsquo;t want it to actually run. You can include chunks but not run them by setting &lt;code>eval=FALSE&lt;/code> in the chunk options. In this little example, we show the code for downloading the data, but we don&amp;rsquo;t evaluate the chunk. We then include a chunk that loads the data from a CSV file with &lt;code>read_csv()&lt;/code>, but we don&amp;rsquo;t include it (&lt;code>include=FALSE&lt;/code>). That way, in the knitted file we see the &lt;code>WDI()&lt;/code> code, but in reality it&amp;rsquo;s loading the data from CSV. Super tricky.&lt;/p>
&lt;pre>&lt;code class="language-text">I first download data from FRED:
```{r get-fred-data, eval=FALSE}
fred_raw &amp;lt;- tq_get(...)
write_csv(fred_raw, &amp;quot;data/fred_raw.csv&amp;quot;)
```
```{r load-fred-data-real, include=FALSE}
fred_raw &amp;lt;- read_csv(&amp;quot;data/fred_raw.csv&amp;quot;)
```
&lt;/code>&lt;/pre>
&lt;h3 id="look-at-and-clean-data">Look at and clean data&lt;/h3>
&lt;p>The data we get from FRED is in a slightly different format than we&amp;rsquo;re used to with &lt;code>WDI()&lt;/code>, but with good reason. With World Bank data, you get data for every country and every year, so there are rows for Afghanistan 2000, Afghanistan 2001, etc. You then get a column for each of the variables you want (population, life expectancy, GDP/capita, etc.)&lt;/p>
&lt;p>With FRED data, that kind of format doesn&amp;rsquo;t work for every possible time series variable because time is spaced differently. If you want to work with annual GDP, you should have a row for each year. If you want quarterly GDP, you should have a row for every quarter. If you put these in the same dataset, you&amp;rsquo;ll end up with all sorts of missing data issues:&lt;/p>
&lt;table>
&lt;thead>
&lt;tr>
&lt;th>&lt;code>time&lt;/code>&lt;/th>
&lt;th style="text-align:center">&lt;code>annual_gdp&lt;/code>&lt;/th>
&lt;th style="text-align:center">&lt;code>quarterly_gdp&lt;/code>&lt;/th>
&lt;/tr>
&lt;/thead>
&lt;tbody>
&lt;tr>
&lt;td>2019, Q1&lt;/td>
&lt;td style="text-align:center">X&lt;/td>
&lt;td style="text-align:center">X&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2019, Q2&lt;/td>
&lt;td style="text-align:center">&lt;/td>
&lt;td style="text-align:center">X&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2019, Q3&lt;/td>
&lt;td style="text-align:center">&lt;/td>
&lt;td style="text-align:center">X&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2019, Q4&lt;/td>
&lt;td style="text-align:center">&lt;/td>
&lt;td style="text-align:center">X&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2020, Q1&lt;/td>
&lt;td style="text-align:center">X&lt;/td>
&lt;td style="text-align:center">X&lt;/td>
&lt;/tr>
&lt;tr>
&lt;td>2020, Q2&lt;/td>
&lt;td style="text-align:center">&lt;/td>
&lt;td style="text-align:center">X&lt;/td>
&lt;/tr>
&lt;/tbody>
&lt;/table>
&lt;p>To fix this, the &lt;strong>tidyquant&lt;/strong> package gives you data in tidy (or long) form and only provides three columns:&lt;/p>
&lt;pre>&lt;code class="language-r">head(fred_raw)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 3
## symbol date price
## &amp;lt;chr&amp;gt; &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt;
## 1 RSXFSN 1992-01-01 130683
## 2 RSXFSN 1992-02-01 131244
## 3 RSXFSN 1992-03-01 142488
## 4 RSXFSN 1992-04-01 147175
## 5 RSXFSN 1992-05-01 152420
## 6 RSXFSN 1992-06-01 151849
&lt;/code>&lt;/pre>
&lt;p>The &lt;code>symbol&lt;/code> column is the ID of the variable from FRED , &lt;code>date&lt;/code> isâ€¦ the date, and &lt;code>price&lt;/code> is the value. These columns are called symbol and price because the &lt;strong>tidyquant&lt;/strong> package was designed to get and process stock data, so you&amp;rsquo;d typically see stock symbols (like AAPL or MSFT) and stock prices. When working with FRED data, the &lt;code>price&lt;/code> column shows the value of whatever you&amp;rsquo;re interested inâ€”it&amp;rsquo;s not technically a price (so unemployment claims, inflation rates, and GDP values are still called &lt;code>price&lt;/code>).&lt;/p>
&lt;p>Right now, our &lt;code>fred_raw&lt;/code> dataset has only 3 columns, but nearly 3,000 rows since the six indicators we got from the server are all stacked on top of each other. To actually work with these, we need to filter the raw data so that it only includes the indicators we&amp;rsquo;re interested in. For instance, if we want to plot retail sales, we need to select only the rows where the symbol is &lt;code>RSXFSN&lt;/code>. Make a smaller dataset with &lt;code>filter()&lt;/code> to do that:&lt;/p>
&lt;pre>&lt;code class="language-r">retail_sales &amp;lt;- fred_raw %&amp;gt;%
filter(symbol == &amp;quot;RSXFSN&amp;quot;)
retail_sales
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 351 x 3
## symbol date price
## &amp;lt;chr&amp;gt; &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt;
## 1 RSXFSN 1992-01-01 130683
## 2 RSXFSN 1992-02-01 131244
## 3 RSXFSN 1992-03-01 142488
## 4 RSXFSN 1992-04-01 147175
## 5 RSXFSN 1992-05-01 152420
## 6 RSXFSN 1992-06-01 151849
## 7 RSXFSN 1992-07-01 152586
## 8 RSXFSN 1992-08-01 152476
## 9 RSXFSN 1992-09-01 148158
## 10 RSXFSN 1992-10-01 155987
## # â€¦ with 341 more rows
&lt;/code>&lt;/pre>
&lt;p>If multiple variables have the same spacing (annual, quarterly, monthly, weekly), you can use filter to select all of them and then the use &lt;code>pivot_wider()&lt;/code> or &lt;code>spread()&lt;/code> to make separate columns for each. Inflation, unemployment, and retail sales are all monthly, so we can make a dataset for just those:&lt;/p>
&lt;pre>&lt;code class="language-r">fred_monthly_things &amp;lt;- fred_raw %&amp;gt;%
filter(symbol %in% c(&amp;quot;FPCPITOTLZGUSA&amp;quot;, &amp;quot;UNRATE&amp;quot;, &amp;quot;RSXFSN&amp;quot;)) %&amp;gt;%
# Convert the symbol column into multiple columns, using the &amp;quot;prices&amp;quot; for values
pivot_wider(names_from = symbol, values_from = price)
fred_monthly_things
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 375 x 4
## date RSXFSN FPCPITOTLZGUSA UNRATE
## &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 1992-01-01 130683 3.03 7.3
## 2 1992-02-01 131244 NA 7.4
## 3 1992-03-01 142488 NA 7.4
## 4 1992-04-01 147175 NA 7.4
## 5 1992-05-01 152420 NA 7.6
## 6 1992-06-01 151849 NA 7.8
## 7 1992-07-01 152586 NA 7.7
## 8 1992-08-01 152476 NA 7.6
## 9 1992-09-01 148158 NA 7.6
## 10 1992-10-01 155987 NA 7.3
## # â€¦ with 365 more rows
&lt;/code>&lt;/pre>
&lt;p>But wait! There&amp;rsquo;s a problem! The inflation rate we got isn&amp;rsquo;t actually monthlyâ€”it seems to be annual, which explains all the &lt;code>NA&lt;/code>s. Let&amp;rsquo;s fix it by not including it. We&amp;rsquo;ll also rename the columns so they&amp;rsquo;re easier to work with&lt;/p>
&lt;pre>&lt;code class="language-r">fred_monthly_things &amp;lt;- fred_raw %&amp;gt;%
filter(symbol %in% c(&amp;quot;UNRATE&amp;quot;, &amp;quot;RSXFSN&amp;quot;)) %&amp;gt;%
# Convert the symbol column into multiple columns, using the &amp;quot;prices&amp;quot; for values
pivot_wider(names_from = symbol, values_from = price) %&amp;gt;%
rename(unemployment = UNRATE, retail_sales = RSXFSN)
fred_monthly_things
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 375 x 3
## date retail_sales unemployment
## &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 1992-01-01 130683 7.3
## 2 1992-02-01 131244 7.4
## 3 1992-03-01 142488 7.4
## 4 1992-04-01 147175 7.4
## 5 1992-05-01 152420 7.6
## 6 1992-06-01 151849 7.8
## 7 1992-07-01 152586 7.7
## 8 1992-08-01 152476 7.6
## 9 1992-09-01 148158 7.6
## 10 1992-10-01 155987 7.3
## # â€¦ with 365 more rows
&lt;/code>&lt;/pre>
&lt;p>All better.&lt;/p>
&lt;p>We can make as many subsets of the long, tidy, raw data as we want.&lt;/p>
&lt;h3 id="plotting-time">Plotting time&lt;/h3>
&lt;p>Let&amp;rsquo;s plot some of these and see what the trends look like. We&amp;rsquo;ll just use &lt;code>geom_line()&lt;/code>.&lt;/p>
&lt;p>Here&amp;rsquo;s GDP:&lt;/p>
&lt;pre>&lt;code class="language-r"># Get just GDP data from the raw FRED data
gdp_only &amp;lt;- fred_raw %&amp;gt;%
filter(symbol == &amp;quot;GDPC1&amp;quot;)
ggplot(gdp_only, aes(x = date, y = price)) +
geom_line()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/gdp-basic-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Here&amp;rsquo;s retail sales:&lt;/p>
&lt;pre>&lt;code class="language-r"># Get just GDP data from the raw FRED data
retail_sales_only &amp;lt;- fred_raw %&amp;gt;%
filter(symbol == &amp;quot;RSXFSN&amp;quot;)
ggplot(retail_sales_only, aes(x = date, y = price)) +
geom_line()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/retail-sales-basic-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>And here&amp;rsquo;s unemployment claims:&lt;/p>
&lt;pre>&lt;code class="language-r">unemployment_claims_only &amp;lt;- fred_raw %&amp;gt;%
filter(symbol == &amp;quot;ICSA&amp;quot;)
ggplot(unemployment_claims_only, aes(x = date, y = price)) +
geom_line()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/unemp-claims-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Yikes COVID-19.&lt;/p>
&lt;p>There, we visualized time. âœ…&lt;/p>
&lt;h3 id="improving-graphics">Improving graphics&lt;/h3>
&lt;p>These were simple graphs and they&amp;rsquo;re kind of helpful, but they&amp;rsquo;re not incredibly informative. We can clean these up a little. First we can change the labels and themes and colors:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(gdp_only, aes(x = date, y = price)) +
geom_line(color = &amp;quot;#0074D9&amp;quot;, size = 1) +
scale_y_continuous(labels = dollar) +
labs(y = &amp;quot;Billions of 2012 dollars&amp;quot;,
x = NULL,
title = &amp;quot;US Gross Domestic Product&amp;quot;,
subtitle = &amp;quot;Quarterly data; real 2012 dollars&amp;quot;,
caption = &amp;quot;Source: US Bureau of Economic Analysis and FRED&amp;quot;) +
theme_bw(base_family = &amp;quot;Roboto Condensed&amp;quot;) +
theme(plot.title = element_text(face = &amp;quot;bold&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/gdp-better-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>That&amp;rsquo;s great and almost good enough to publish! We can add one additional layer of information onto the plot and highlight when recessions start and end. We included a recessions variable (&lt;code>USREC&lt;/code>) when we got data from FRED, so let&amp;rsquo;s see what it looks like:&lt;/p>
&lt;pre>&lt;code class="language-r">fred_raw %&amp;gt;%
filter(symbol == &amp;quot;USREC&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 375 x 3
## symbol date price
## &amp;lt;chr&amp;gt; &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt;
## 1 USREC 1990-01-01 0
## 2 USREC 1990-02-01 0
## 3 USREC 1990-03-01 0
## 4 USREC 1990-04-01 0
## 5 USREC 1990-05-01 0
## 6 USREC 1990-06-01 0
## 7 USREC 1990-07-01 0
## 8 USREC 1990-08-01 1
## 9 USREC 1990-09-01 1
## 10 USREC 1990-10-01 1
## # â€¦ with 365 more rows
&lt;/code>&lt;/pre>
&lt;p>This is monthly data that shows a 1 if we were in a recession that month and a 0 if we weren&amp;rsquo;t. The Fed doesn&amp;rsquo;t decide when recessions happenâ€”the &lt;a href="https://www.nber.org/" target="_blank" rel="noopener">National Bureau of Economic Research (NBER)&lt;/a> does, and they have &lt;a href="https://en.wikipedia.org/wiki/Recession#Definition" target="_blank" rel="noopener">specific guidelines&lt;/a> for defining one. We&amp;rsquo;re probably in one right now, but there&amp;rsquo;s not enough data for NBER to formally declare it yet.&lt;/p>
&lt;p>This data is long and tidy, but that makes it harder to work with given our GDP. We want the start and end dates for each recession so that we can shade those areas on the plot. To find those dates, we need to do a little data reshaping. First, we&amp;rsquo;ll create a temporary variable that marks if there was a switch from 0 to 1 or 1 to 0 in a given row by looking at the previous row&lt;/p>
&lt;pre>&lt;code class="language-r">recessions_tidy &amp;lt;- fred_raw %&amp;gt;%
filter(symbol == &amp;quot;USREC&amp;quot;) %&amp;gt;%
mutate(recession_change = price - lag(price))
recessions_tidy
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 375 x 4
## symbol date price recession_change
## &amp;lt;chr&amp;gt; &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 USREC 1990-01-01 0 NA
## 2 USREC 1990-02-01 0 0
## 3 USREC 1990-03-01 0 0
## 4 USREC 1990-04-01 0 0
## 5 USREC 1990-05-01 0 0
## 6 USREC 1990-06-01 0 0
## 7 USREC 1990-07-01 0 0
## 8 USREC 1990-08-01 1 1
## 9 USREC 1990-09-01 1 0
## 10 USREC 1990-10-01 1 0
## # â€¦ with 365 more rows
&lt;/code>&lt;/pre>
&lt;p>Notice the new column we have that is mostly 0s, but 1 when there&amp;rsquo;s a switch, like in August 1990. 1 means we went from 0 to 1 (no recession â†’ recession), while -1 means we went from 1 to 0 (recession â†’ no recession).&lt;/p>
&lt;p>We can see all the start and end dates if we filter:&lt;/p>
&lt;pre>&lt;code class="language-r">recessions_start_end &amp;lt;- fred_raw %&amp;gt;%
filter(symbol == &amp;quot;USREC&amp;quot;) %&amp;gt;%
mutate(recession_change = price - lag(price)) %&amp;gt;%
filter(recession_change != 0)
recessions_start_end
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 7 x 4
## symbol date price recession_change
## &amp;lt;chr&amp;gt; &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 USREC 1990-08-01 1 1
## 2 USREC 1991-04-01 0 -1
## 3 USREC 2001-04-01 1 1
## 4 USREC 2001-12-01 0 -1
## 5 USREC 2008-01-01 1 1
## 6 USREC 2009-07-01 0 -1
## 7 USREC 2020-03-01 1 1
&lt;/code>&lt;/pre>
&lt;p>Finally, we can use &lt;code>tibble()&lt;/code> to create a brand new little dataset that includes columns for the start and end dates. Since we&amp;rsquo;re currently in a recession, we have a little bit of a problemâ€”there&amp;rsquo;s no end date to the current recession, so we can&amp;rsquo;t plot it. We need to create our own fake end date for the sake of putting it on a graph. We&amp;rsquo;ll add a row to &lt;code>recessions_start_end&lt;/code> using &lt;code>bind_rows()&lt;/code> and give it today&amp;rsquo;s date with &lt;code>today()&lt;/code> (&lt;code>today()&lt;/code> by itself returns regular text like &lt;code>&amp;quot;2021-06-01&amp;quot;&lt;/code>; we need to tell R that this is a date by feeding it to &lt;code>ymd()&lt;/code>).&lt;/p>
&lt;p>We can then extract the pairs of recession start and end dates in a miniature dataset of recessions.&lt;/p>
&lt;pre>&lt;code class="language-r"># If you're running this code not during a recession, there's no need for this
# intermediate step
recessions_fake_end &amp;lt;- recessions_start_end %&amp;gt;%
bind_rows(tibble(date = ymd(today()),
recession_change = -1))
recessions &amp;lt;- tibble(start = filter(recessions_fake_end, recession_change == 1)$date,
end = filter(recessions_fake_end, recession_change == -1)$date)
recessions
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 4 x 2
## start end
## &amp;lt;date&amp;gt; &amp;lt;date&amp;gt;
## 1 1990-08-01 1991-04-01
## 2 2001-04-01 2001-12-01
## 3 2008-01-01 2009-07-01
## 4 2020-03-01 2021-05-07
&lt;/code>&lt;/pre>
&lt;p>We can now add this tiny dataset to our plot using &lt;code>geom_rect()&lt;/code>. Notice how we put &lt;code>geom_rect()&lt;/code> &lt;em>before&lt;/em> &lt;code>geom_line()&lt;/code>â€”that&amp;rsquo;s so the recession rectangles go under the line instead of on top of it. Also notice that we have to specify 4 new aesthetics for &lt;code>geom_rect()&lt;/code>: min and max values for both x and y. We use the recession start and end dates for &lt;code>xmin&lt;/code> and &lt;code>xmax&lt;/code>, and then use âˆ’âˆž and âˆž for &lt;code>ymin&lt;/code> and &lt;code>ymax&lt;/code> to make the rectangles stretch from the bottom of the plot to the top.&lt;/p>
&lt;p>The last odd/new thing here is that we also use &lt;code>inherit.aes = FALSE&lt;/code> in &lt;code>geom_rect()&lt;/code>. That&amp;rsquo;s because we specified a global &lt;code>x&lt;/code> and &lt;code>y&lt;/code> aesthetic in &lt;code>ggplot()&lt;/code>, which applies to all the other layers we add. &lt;code>geom_rect()&lt;/code> doesn&amp;rsquo;t use &lt;code>x&lt;/code> or &lt;code>y&lt;/code>, though, and it&amp;rsquo;ll complain that those columns are missing. The &lt;code>inherit.aes&lt;/code> argument tells ggplot that the &lt;code>geom_rect()&lt;/code> layer should not get any of the global aesthetics like &lt;code>x&lt;/code> or &lt;code>y&lt;/code>.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(gdp_only, aes(x = date, y = price)) +
geom_rect(data = recessions,
aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
inherit.aes = FALSE, fill = &amp;quot;#B10DC9&amp;quot;, alpha = 0.3) +
geom_line(color = &amp;quot;#0074D9&amp;quot;, size = 1) +
scale_y_continuous(labels = dollar) +
labs(y = &amp;quot;Billions of 2012 dollars&amp;quot;,
x = NULL,
title = &amp;quot;US Gross Domestic Product&amp;quot;,
subtitle = &amp;quot;Quarterly data; real 2012 dollars&amp;quot;,
caption = &amp;quot;Source: US Bureau of Economic Analysis and FRED&amp;quot;) +
theme_bw(base_family = &amp;quot;Roboto Condensed&amp;quot;) +
theme(plot.title = element_text(face = &amp;quot;bold&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/gdp-fancy-awesom-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>And that&amp;rsquo;s it!&lt;/p>
&lt;p>Now that we have the tiny recessions data frame, we can add it to any plot we want. Here&amp;rsquo;s initial unemployment claims with some extra annotations for fun:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(unemployment_claims_only, aes(x = date, y = price)) +
geom_rect(data = recessions,
aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
inherit.aes = FALSE, fill = &amp;quot;#B10DC9&amp;quot;, alpha = 0.3) +
geom_line(color = &amp;quot;#FF4136&amp;quot;, size = 0.5) +
annotate(geom = &amp;quot;label&amp;quot;, x = as.Date(&amp;quot;2010-01-01&amp;quot;), y = 1000000,
label = &amp;quot;The Great Recession&amp;quot;, size = 3, family = &amp;quot;Roboto Condensed&amp;quot;) +
annotate(geom = &amp;quot;label&amp;quot;, x = as.Date(&amp;quot;2020-01-01&amp;quot;), y = 6000000,
label = &amp;quot;COVID-19&amp;quot;, size = 3, family = &amp;quot;Roboto Condensed&amp;quot;, hjust = 1) +
scale_y_continuous(labels = comma) +
labs(y = &amp;quot;Initial unemployment claims&amp;quot;,
x = NULL,
title = &amp;quot;Initial unemployment claims&amp;quot;,
subtitle = &amp;quot;Weekly data&amp;quot;,
caption = &amp;quot;Source: US Employment and Training Administration and FRED&amp;quot;) +
theme_bw(base_family = &amp;quot;Roboto Condensed&amp;quot;) +
theme(plot.title = element_text(face = &amp;quot;bold&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/unemployment-fancy-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="decomposition">Decomposition&lt;/h3>
&lt;p>The mechanics of decomposing and forecasting time series goes beyond the scope of this class, but there are lots of resources you can use to learn more, including &lt;a href="https://otexts.com/fpp3/" target="_blank" rel="noopener">this phenomenal free textbook&lt;/a>.&lt;/p>
&lt;p>There&amp;rsquo;s a whole ecosystem of time-related packages that make working with time and decomposing trends easy (named &lt;a href="https://tidyverts.org/" target="_blank" rel="noopener">&lt;strong>tidyverts&lt;/strong>&lt;/a>):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://lubridate.tidyverse.org/" target="_blank" rel="noopener">&lt;strong>lubridate&lt;/strong>&lt;/a>: Helpful functions for manipulating dates (you&amp;rsquo;ve used this before)&lt;/li>
&lt;li>&lt;a href="https://tsibble.tidyverts.org/" target="_blank" rel="noopener">&lt;strong>tsibble&lt;/strong>&lt;/a>: Add fancy support for time variables to data frames&lt;/li>
&lt;li>&lt;a href="https://feasts.tidyverts.org/" target="_blank" rel="noopener">&lt;strong>feasts&lt;/strong>&lt;/a>: Decompose time series and do other statistical things with time&lt;/li>
&lt;li>&lt;a href="https://fable.tidyverts.org/" target="_blank" rel="noopener">&lt;strong>fable&lt;/strong>&lt;/a>: Make forecasts&lt;/li>
&lt;/ul>
&lt;p>Here&amp;rsquo;s a super short example of how these all work.&lt;/p>
&lt;p>The retail sales data we got from FRED was not seasonally adjusted, so it looks like it has a heartbeat embedded in it:&lt;/p>
&lt;pre>&lt;code class="language-r">retail_sales &amp;lt;- fred_raw %&amp;gt;%
filter(symbol == &amp;quot;RSXFSN&amp;quot;)
ggplot(retail_sales, aes(x = date, y = price)) +
geom_line()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/retail-sales-full-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can divide this trend into its main components: the trend, the seasonality, and stuff that&amp;rsquo;s not explained by either the trend or the seasonality. To do that, we need to first modify our little dataset and tell it to be a time-enabled data frame (a &lt;code>tsibble&lt;/code>) that is indexed by the year+month for each row. We&amp;rsquo;ll create a new column called &lt;code>year_month&lt;/code> and then use &lt;code>as_tsibble()&lt;/code> to tell R that this is really truly dealing with time:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tsibble) # For embedding time things into data frames
retail_sales &amp;lt;- fred_raw %&amp;gt;%
filter(symbol == &amp;quot;RSXFSN&amp;quot;) %&amp;gt;%
mutate(year_month = yearmonth(date)) %&amp;gt;%
as_tsibble(index = year_month)
retail_sales
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tsibble: 351 x 4 [1M]
## symbol date price year_month
## &amp;lt;chr&amp;gt; &amp;lt;date&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;mth&amp;gt;
## 1 RSXFSN 1992-01-01 130683 1992 Jan
## 2 RSXFSN 1992-02-01 131244 1992 Feb
## 3 RSXFSN 1992-03-01 142488 1992 Mar
## 4 RSXFSN 1992-04-01 147175 1992 Apr
## 5 RSXFSN 1992-05-01 152420 1992 May
## 6 RSXFSN 1992-06-01 151849 1992 Jun
## 7 RSXFSN 1992-07-01 152586 1992 Jul
## 8 RSXFSN 1992-08-01 152476 1992 Aug
## 9 RSXFSN 1992-09-01 148158 1992 Sep
## 10 RSXFSN 1992-10-01 155987 1992 Oct
## # â€¦ with 341 more rows
&lt;/code>&lt;/pre>
&lt;p>Notice that the &lt;code>year_month&lt;/code> column is now just the year+month. Neato.&lt;/p>
&lt;p>Next we need to create a time series model using that data. There are lots of different ways to model time series, and distinguishing between the different types is &lt;em>way&lt;/em> beyond the scope of this class. &lt;a href="https://otexts.com/fpp3/" target="_blank" rel="noopener">Rob Hyndman&amp;rsquo;s free books covers them all&lt;/a>. We&amp;rsquo;ll do this with &lt;a href="https://otexts.com/fpp2/stl.html" target="_blank" rel="noopener">STL decomposition&lt;/a> (&amp;quot;&lt;strong>S&lt;/strong>easonal and &lt;strong>T&lt;/strong>rend decomposition using &lt;strong>L&lt;/strong>oess&amp;rdquo;) There are other models we can use, like ETS or ARIMA, but again, that&amp;rsquo;s all beyond this class.&lt;/p>
&lt;pre>&lt;code class="language-r">library(feasts) # For decomposition things like STL()
retail_model &amp;lt;- retail_sales %&amp;gt;%
model(stl = STL(price))
retail_model
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A mable: 1 x 1
## stl
## &amp;lt;model&amp;gt;
## 1 &amp;lt;STL&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>The decomposition model we create is kind of boring and uselessâ€”it&amp;rsquo;s all stored in a single cell.&lt;/p>
&lt;p>We can extract the different components of the decomposition with the &lt;code>components()&lt;/code> function:&lt;/p>
&lt;pre>&lt;code class="language-r">retail_components &amp;lt;- components(retail_model)
retail_components
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A dable: 351 x 7 [1M]
## # Key: .model [1]
## # : price = trend + season_year + remainder
## .model year_month price trend season_year remainder season_adjust
## &amp;lt;chr&amp;gt; &amp;lt;mth&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 stl 1992 Jan 130683 148453. -22505. 4735. 153188.
## 2 stl 1992 Feb 131244 148960. -23009. 5292. 154253.
## 3 stl 1992 Mar 142488 149468. -1326. -5654. 143814.
## 4 stl 1992 Apr 147175 149976. -2978. 177. 150153.
## 5 stl 1992 May 152420 150513. 5927. -4020. 146493.
## 6 stl 1992 Jun 151849 151051. 3205. -2407. 148644.
## 7 stl 1992 Jul 152586 151589. 294. 703. 152292.
## 8 stl 1992 Aug 152476 152155. 4343. -4022. 148133.
## 9 stl 1992 Sep 148158 152722. -6162. 1598. 154320.
## 10 stl 1992 Oct 155987 153289. -33.3 2732. 156020.
## # â€¦ with 341 more rows
&lt;/code>&lt;/pre>
&lt;p>And we can use the &lt;code>autoplot()&lt;/code> function from the &lt;strong>feasts&lt;/strong> package to quickly plot all the components. The plot that &lt;code>autoplot()&lt;/code> creates is made with ggplot, so any normal ggplot layers work with it:&lt;/p>
&lt;pre>&lt;code class="language-r">autoplot(retail_components) +
labs(x = NULL) +
theme_bw(base_family = &amp;quot;Roboto Condensed&amp;quot;) +
theme(plot.title = element_text(face = &amp;quot;bold&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/auto-plot-theme-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can also plot individual components on their own using the &lt;code>retail_components&lt;/code> dataset we made. Here&amp;rsquo;s seasonality by itself:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(retail_components,
aes(x = year_month, y = season_year)) +
geom_rect(data = recessions,
aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
inherit.aes = FALSE, fill = &amp;quot;#B10DC9&amp;quot;, alpha = 0.3) +
geom_line() +
scale_y_continuous(labels = dollar) +
# ggplot needs to know that the main data is a yearmonth column so that it'll
# deal with the recessions data correctly; without this, you'll get an error
scale_x_yearmonth() +
labs(x = NULL, y = &amp;quot;Difference from trend, millions of dollars&amp;quot;,
title = &amp;quot;Seasonal trends in retail sales&amp;quot;,
subtitle = &amp;quot;Nominal US dollars&amp;quot;) +
theme_bw(base_family = &amp;quot;Roboto Condensed&amp;quot;) +
theme(plot.title = element_text(face = &amp;quot;bold&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/retail-season-only-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>And here&amp;rsquo;s the trend by itself:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(retail_components,
aes(x = year_month, y = trend)) +
geom_rect(data = recessions,
aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
inherit.aes = FALSE, fill = &amp;quot;#B10DC9&amp;quot;, alpha = 0.3) +
geom_line() +
scale_y_continuous(labels = dollar) +
scale_x_yearmonth() +
labs(x = NULL, y = &amp;quot;Trend, millions of dollars&amp;quot;,
title = &amp;quot;Seasonally adjusted trends in retail sales&amp;quot;,
subtitle = &amp;quot;Nominal US dollars&amp;quot;) +
theme_bw(base_family = &amp;quot;Roboto Condensed&amp;quot;) +
theme(plot.title = element_text(face = &amp;quot;bold&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/retail-trend-only-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>If you want more control over the combined decomposed plot you can either (1) make individual plots for each of the components and then stitch them together with &lt;a href="https://patchwork.data-imaginist.com/" target="_blank" rel="noopener">&lt;strong>patchwork&lt;/strong>&lt;/a>, or (2) make the components dataset tidy and facet by component. Here&amp;rsquo;s what that looks like:&lt;/p>
&lt;pre>&lt;code class="language-r">retail_components_tidy &amp;lt;- retail_components %&amp;gt;%
# Get rid of this column
select(-season_adjust) %&amp;gt;%
# Take all these component columns and put them into a long column
pivot_longer(cols = c(price, trend, season_year, remainder),
names_to = &amp;quot;component&amp;quot;, values_to = &amp;quot;value&amp;quot;) %&amp;gt;%
# Recode this values so they're nicer
mutate(component = recode(component,
price = &amp;quot;Actual data&amp;quot;,
trend = &amp;quot;Trend&amp;quot;,
season_year = &amp;quot;Seasonality&amp;quot;,
remainder = &amp;quot;Remainder&amp;quot;)) %&amp;gt;%
# Make the component categories follow the order they're in in the data so
# that &amp;quot;Actual data&amp;quot; is first, etc.
mutate(component = fct_inorder(component))
retail_components_tidy
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tsibble: 1,404 x 4 [1M]
## # Key: .model, component [4]
## .model year_month component value
## &amp;lt;chr&amp;gt; &amp;lt;mth&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt;
## 1 stl 1992 Jan Actual data 130683
## 2 stl 1992 Jan Trend 148453.
## 3 stl 1992 Jan Seasonality -22505.
## 4 stl 1992 Jan Remainder 4735.
## 5 stl 1992 Feb Actual data 131244
## 6 stl 1992 Feb Trend 148960.
## 7 stl 1992 Feb Seasonality -23009.
## 8 stl 1992 Feb Remainder 5292.
## 9 stl 1992 Mar Actual data 142488
## 10 stl 1992 Mar Trend 149468.
## # â€¦ with 1,394 more rows
&lt;/code>&lt;/pre>
&lt;p>Now that we have a long dataset, we can facet by component:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(retail_components_tidy,
aes(x = year_month, y = value)) +
geom_rect(data = recessions,
aes(xmin = start, xmax = end, ymin = -Inf, ymax = Inf),
inherit.aes = FALSE, fill = &amp;quot;#B10DC9&amp;quot;, alpha = 0.3) +
geom_line() +
scale_y_continuous(labels = dollar) +
scale_x_yearmonth() +
labs(x = NULL, y = &amp;quot;Millions of dollars&amp;quot;,
title = &amp;quot;Decomposed US Advance Retail Sales&amp;quot;,
subtitle = &amp;quot;Nominal US dollars&amp;quot;,
caption = &amp;quot;Source: US Census Bureau and FRED (RSXFSN)&amp;quot;) +
facet_wrap(vars(component), ncol = 1, scales = &amp;quot;free_y&amp;quot;) +
theme_minimal(base_family = &amp;quot;Roboto Condensed&amp;quot;) +
theme(plot.title = element_text(face = &amp;quot;bold&amp;quot;),
plot.title.position = &amp;quot;plot&amp;quot;,
strip.text = element_text(face = &amp;quot;bold&amp;quot;, hjust = 0))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/11-example_files/figure-html/plot-seasonality-fancy-1.png" width="672" style="display: block; margin: auto;" />
&lt;p>Beautiful!&lt;/p></description></item><item><title>Space</title><link>https://aem2850.toddgerarden.com/example/12-example/</link><pubDate>Mon, 12 Jul 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/12-example/</guid><description>&lt;h2 id="shapefiles">Shapefiles&lt;/h2>
&lt;p>Shapefiles are special types of data that include information about geography, such as points (latitude, longitude), paths (a bunch of connected latitudes and longitudes) and areas (a bunch of connected latitudes and longitudes that form a complete shape). Nowadays, most government agencies provide shapefiles for their jurisdictions. For global mapping data, you can use the Natural Earth project:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://www.naturalearthdata.com/" target="_blank" rel="noopener">Natural Earth&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html" target="_blank" rel="noopener">US Census Bureau&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://data.georgiaspatial.org/" target="_blank" rel="noopener">Georgia GIS Clearinghouse&lt;/a> (requires a free account; the interface is &lt;em>incredibly&lt;/em> clunky)&lt;/li>
&lt;li>&lt;a href="https://opendata.atlantaregional.com/" target="_blank" rel="noopener">Atlanta Regional Council&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://gisdata.fultoncountyga.gov/" target="_blank" rel="noopener">Fulton County GIS Portal&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://dcp-coaplangis.opendata.arcgis.com/" target="_blank" rel="noopener">City of Atlanta, Department of City Planning&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="projections-and-coordinate-reference-systems">Projections and coordinate reference systems&lt;/h2>
&lt;p>As you read in this week&amp;rsquo;s readings, projections matter a lot for maps. You can convert your geographic data between different coordinate systems (or projections)&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup> fairly easily with &lt;strong>sf&lt;/strong>. You can use &lt;code>coord_sf(crs = st_crs(&amp;quot;XXXX&amp;quot;))&lt;/code> to convert coordinate reference systems (CRS) as you plot, or use &lt;code>st_transform()&lt;/code> to convert data frames to a different CRS.&lt;/p>
&lt;p>There are standard indexes of more than 4,000 of these projections (!!!) at &lt;a href="https://epsg.io/" target="_blank" rel="noopener">epsg.io&lt;/a>.&lt;/p>
&lt;p>&lt;strong>Super important&lt;/strong>: When using these projections, you need to specify both the projection catalog (ESRI or EPSG; &lt;a href="https://gis.stackexchange.com/a/169211/56265" target="_blank" rel="noopener">see here for the difference&lt;/a>) and the projection number, separated by a colon (e.g. &amp;ldquo;&lt;code>ESRI:54030&lt;/code>&amp;quot;). Fortunately &lt;a href="http://epsg.io/" target="_blank" rel="noopener">epsg.io&lt;/a> makes this super easy: go to the epsg.io page for the projection you want to use and the page title will have the correct name.&lt;/p>
&lt;p>Here are some common ones:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="http://epsg.io/54002" target="_blank" rel="noopener">ESRI:54002&lt;/a>: Equidistant cylindrical projection for the world&lt;sup id="fnref:2">&lt;a href="#fn:2" class="footnote-ref" role="doc-noteref">2&lt;/a>&lt;/sup>&lt;/li>
&lt;li>&lt;a href="http://epsg.io/3395" target="_blank" rel="noopener">EPSG:3395&lt;/a>: Mercator projection for the world&lt;/li>
&lt;li>&lt;a href="http://epsg.io/54008" target="_blank" rel="noopener">ESRI:54008&lt;/a>: Sinusoidal projection for the world&lt;/li>
&lt;li>&lt;a href="http://epsg.io/54009" target="_blank" rel="noopener">ESRI:54009&lt;/a>: Mollweide projection for the world&lt;/li>
&lt;li>&lt;a href="http://epsg.io/54030" target="_blank" rel="noopener">ESRI:54030&lt;/a>: Robinson projection for the world (This is my favorite world projection.)&lt;/li>
&lt;li>&lt;a href="http://epsg.io/4326" target="_blank" rel="noopener">EPSG:4326&lt;/a>: WGS 84: DOD GPS coordinates (standard âˆ’180 to 180 system)&lt;/li>
&lt;li>&lt;a href="http://epsg.io/4269" target="_blank" rel="noopener">EPSG:4269&lt;/a>: NAD 83: Relatively common projection for North America&lt;/li>
&lt;li>&lt;a href="https://epsg.io/102003" target="_blank" rel="noopener">ESRI:102003&lt;/a>: Albers projection specifically for the contiguous United States&lt;/li>
&lt;/ul>
&lt;p>Alternatively, instead of using these index numbers, you can use any of the names listed &lt;a href="https://proj.org/operations/projections/index.html" target="_blank" rel="noopener">here&lt;/a>, such as:&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;quot;+proj=merc&amp;quot;&lt;/code>: Mercator&lt;/li>
&lt;li>&lt;code>&amp;quot;+proj=robin&amp;quot;&lt;/code>: Robinson&lt;/li>
&lt;li>&lt;code>&amp;quot;+proj=moll&amp;quot;&lt;/code>: Mollweide&lt;/li>
&lt;li>&lt;code>&amp;quot;+proj=aeqd&amp;quot;&lt;/code>: Azimuthal Equidistant&lt;/li>
&lt;li>&lt;code>&amp;quot;+proj=cass&amp;quot;&lt;/code>: Cassini-Soldner&lt;/li>
&lt;/ul>
&lt;h2 id="shapefiles-to-download">Shapefiles to download&lt;/h2>
&lt;p>I use a lot of different shapefiles in this example. To save you from having to go find and download each individual one, you can download this zip file:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://datavizm20.s3.amazonaws.com/shapefiles.zip" target="_blank" rel="noopener">&lt;i class="fas fa-file-archive">&lt;/i> &lt;code>shapefiles.zip&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Unzip this and put all the contained folders in a folder named &lt;code>data&lt;/code> if you want to follow along. &lt;strong>You don&amp;rsquo;t need to follow along!&lt;/strong>&lt;/p>
&lt;p>Your project should be structured like this:&lt;/p>
&lt;pre>&lt;code class="language-text">your-project-name\
some-name.Rmd
your-project-name.Rproj
data\
cb_2018_us_county_5m\
...
cb_2018_us_county_5m.shp
...
cb_2018_us_state_20m\
ne_10m_admin_1_states_provinces\
ne_10m_lakes\
ne_10m_rivers_lake_centerlines\
ne_10m_rivers_north_america\
ne_110m_admin_0_countries\
schools_2009\
&lt;/code>&lt;/pre>
&lt;p>These shapefiles all came from these sources:&lt;/p>
&lt;ul>
&lt;li>&lt;i class="far fa-map">&lt;/i> &lt;strong>World map&lt;/strong>: &lt;a href="https://www.naturalearthdata.com/downloads/110m-cultural-vectors/" target="_blank" rel="noopener">110m &amp;ldquo;Admin 0 - Countries&amp;rdquo; from Natural Earth&lt;/a>&lt;/li>
&lt;li>&lt;i class="far fa-map">&lt;/i> &lt;strong>US states&lt;/strong>: &lt;a href="https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html" target="_blank" rel="noopener">20m 2018 state boundaries from the US Census Bureau&lt;/a>&lt;/li>
&lt;li>&lt;i class="far fa-map">&lt;/i> &lt;strong>US counties&lt;/strong>: &lt;a href="https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html" target="_blank" rel="noopener">5m 2018 county boundaries from the US Census Bureau&lt;/a>&lt;/li>
&lt;li>&lt;i class="far fa-map">&lt;/i> &lt;strong>US states high resolution&lt;/strong>: &lt;a href="https://www.naturalearthdata.com/downloads/10m-cultural-vectors/" target="_blank" rel="noopener">10m &amp;ldquo;Admin 1 â€“ States, Provinces&amp;rdquo; from Natural Earth&lt;/a>&lt;/li>
&lt;li>&lt;i class="far fa-map">&lt;/i> &lt;strong>Global rivers&lt;/strong>: &lt;a href="https://www.naturalearthdata.com/downloads/10m-cultural-vectors/" target="_blank" rel="noopener">10m &amp;ldquo;Rivers + lake centerlines&amp;rdquo; from Natural Earth&lt;/a>&lt;/li>
&lt;li>&lt;i class="far fa-map">&lt;/i> &lt;strong>North American rivers&lt;/strong>: &lt;a href="https://www.naturalearthdata.com/downloads/10m-physical-vectors/" target="_blank" rel="noopener">10m &amp;ldquo;Rivers + lake centerlines, North America supplement&amp;rdquo; from Natural Earth&lt;/a>&lt;/li>
&lt;li>&lt;i class="far fa-map">&lt;/i> &lt;strong>Global lakes&lt;/strong>: &lt;a href="https://www.naturalearthdata.com/downloads/10m-physical-vectors/" target="_blank" rel="noopener">10m &amp;ldquo;Lakes + Reservoirs&amp;rdquo; from Natural Earth&lt;/a>&lt;/li>
&lt;li>&lt;i class="far fa-map">&lt;/i> &lt;strong>Georgia Kâ€“12 schools, 2009&lt;/strong>: &lt;a href="https://data.georgiaspatial.org/index.asp?body=preview&amp;amp;dataId=41516" target="_blank" rel="noopener">&amp;ldquo;Georgia K-12 Schools&amp;rdquo; from the Georgia Department of Education&lt;/a> &lt;em>(you must be logged in to access this)&lt;/em>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/Opzwtegvuv4" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a slightly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="load-and-look-at-data">Load and look at data&lt;/h3>
&lt;p>First we&amp;rsquo;ll load the libraries we&amp;rsquo;re going to use:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse) # For ggplot, dplyr, and friends
library(sf) # For GIS magic
&lt;/code>&lt;/pre>
&lt;p>Next we&amp;rsquo;ll load all the different shapefiles we downloaded using &lt;code>read_sf()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r"># Download &amp;quot;Admin 0 â€“ Countries&amp;quot; from
# https://www.naturalearthdata.com/downloads/110m-cultural-vectors/
world_map &amp;lt;- read_sf(&amp;quot;data/ne_110m_admin_0_countries/ne_110m_admin_0_countries.shp&amp;quot;)
# Download cb_2018_us_state_20m.zip under &amp;quot;States&amp;quot; from
# https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html
us_states &amp;lt;- read_sf(&amp;quot;data/cb_2018_us_state_20m/cb_2018_us_state_20m.shp&amp;quot;)
# Download cb_2018_us_county_5m.zip under &amp;quot;County&amp;quot; from
# https://www.census.gov/geographies/mapping-files/time-series/geo/carto-boundary-file.html
us_counties &amp;lt;- read_sf(&amp;quot;data/cb_2018_us_county_5m/cb_2018_us_county_5m.shp&amp;quot;)
# Download &amp;quot;Admin 1 â€“ States, Provinces&amp;quot; from
# https://www.naturalearthdata.com/downloads/10m-cultural-vectors/
us_states_hires &amp;lt;- read_sf(&amp;quot;data/ne_10m_admin_1_states_provinces/ne_10m_admin_1_states_provinces.shp&amp;quot;)
# Download &amp;quot;Rivers + lake centerlines&amp;quot; from
# https://www.naturalearthdata.com/downloads/10m-physical-vectors/
rivers_global &amp;lt;- read_sf(&amp;quot;data/ne_10m_rivers_lake_centerlines/ne_10m_rivers_lake_centerlines.shp&amp;quot;)
# Download &amp;quot;Rivers + lake centerlines, North America supplement&amp;quot; from
# https://www.naturalearthdata.com/downloads/10m-physical-vectors/
rivers_na &amp;lt;- read_sf(&amp;quot;data/ne_10m_rivers_north_america/ne_10m_rivers_north_america.shp&amp;quot;)
# Download &amp;quot;Lakes + Reservoirs&amp;quot; from
# https://www.naturalearthdata.com/downloads/10m-physical-vectors/
lakes &amp;lt;- read_sf(&amp;quot;data/ne_10m_lakes/ne_10m_lakes.shp&amp;quot;)
# Download from https://data.georgiaspatial.org/index.asp?body=preview&amp;amp;dataId=41516
# after creating an account and logging in
ga_schools &amp;lt;- read_sf(file.path(&amp;quot;data&amp;quot;, &amp;quot;schools_2009&amp;quot;, &amp;quot;DOE Schools 2009.shp&amp;quot;))
&lt;/code>&lt;/pre>
&lt;h3 id="basic-plotting">Basic plotting&lt;/h3>
&lt;p>If you look at the &lt;code>world_map&lt;/code> dataset in RStudio, you&amp;rsquo;ll see it&amp;rsquo;s just a standard data frame with 177 rows and 95 columns. The last column is the magical &lt;code>geometry&lt;/code> column with the latitude/longitude details for the borders for every country. RStudio only shows you 50 columns at a time in the RStudio viewer, so you&amp;rsquo;ll need to move to the next page of columns with the Â» button in the top left corner.&lt;/p>
&lt;p>Because this is just a data frame, we can do all our normal dplyr things to it. Let&amp;rsquo;s get rid of Antarctica, since it takes up a big proportion of the southern hemisphere:&lt;/p>
&lt;pre>&lt;code class="language-r">world_sans_antarctica &amp;lt;- world_map %&amp;gt;%
filter(ISO_A3 != &amp;quot;ATA&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Ready to plot a map? Here&amp;rsquo;s all you need to do:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = world_sans_antarctica)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/map-super-basic-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>If you couldn&amp;rsquo;t tell from the lecture, I&amp;rsquo;m completely blown away by how amazingly easy this every time I plot a map :)&lt;/p>
&lt;p>Because this a regular ggplot geom, all our regular aesthetics and themes and everything work:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = world_sans_antarctica,
fill = &amp;quot;#669438&amp;quot;, color = &amp;quot;#32481B&amp;quot;, size = 0.25) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/map-super-basic-filled-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>The Natural Earth dataset happens to come with some columns with a coloring scheme with 7â€“13 colors (&lt;code>MAPCOLOR7&lt;/code>, &lt;code>MAPCOLOR9&lt;/code>, etc.) so that no countries with a shared border share a color. We can fill by that column:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = world_sans_antarctica,
aes(fill = as.factor(MAPCOLOR7)),
color = &amp;quot;#401D16&amp;quot;, size = 0.25) +
scale_fill_viridis_d(option = &amp;quot;plasma&amp;quot;) +
guides(fill = &amp;quot;none&amp;quot;) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/map-super-basic-filled-7-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="world-map-with-different-projections">World map with different projections&lt;/h3>
&lt;p>Changing projections is trivial: add a &lt;code>coord_sf()&lt;/code> layer where you specify the CRS you want to use.&lt;/p>
&lt;p>Here&amp;rsquo;s Robinson (yay):&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = world_sans_antarctica,
fill = &amp;quot;#669438&amp;quot;, color = &amp;quot;#32481B&amp;quot;, size = 0.25) +
coord_sf(crs = st_crs(&amp;quot;ESRI:54030&amp;quot;)) + # Robinson
# Or use the name instead of the number
# coord_sf(crs = &amp;quot;+proj=robin&amp;quot;)
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/map-basic-robinson-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Here&amp;rsquo;s sinusoidal:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = world_sans_antarctica,
fill = &amp;quot;#669438&amp;quot;, color = &amp;quot;#32481B&amp;quot;, size = 0.25) +
coord_sf(crs = st_crs(&amp;quot;ESRI:54008&amp;quot;)) + # Sinusoidal
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/map-basic-sinusoidal-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>And here&amp;rsquo;s Mercator (ewww):&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = world_sans_antarctica,
fill = &amp;quot;#669438&amp;quot;, color = &amp;quot;#32481B&amp;quot;, size = 0.25) +
coord_sf(crs = st_crs(&amp;quot;EPSG:3395&amp;quot;)) + # Mercator
# Or use the name instead of the number
# coord_sf(crs = &amp;quot;+proj=merc&amp;quot;)
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/map-basic-mercator-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="us-map-with-different-projections">US map with different projections&lt;/h3>
&lt;p>This same process works for any shapefile. The map of the US can also be projected differentlyâ€”two common projections are NAD83 and Albers. We&amp;rsquo;ll take the &lt;code>us_states&lt;/code> dataset, remove Alaska, Hawaii, and Puerto Rico (they&amp;rsquo;re so far from the rest of the lower 48 states that they make an unusable mapâ€”see the next section for a way to include them), and plot it.&lt;/p>
&lt;pre>&lt;code class="language-r">lower_48 &amp;lt;- us_states %&amp;gt;%
filter(!(NAME %in% c(&amp;quot;Alaska&amp;quot;, &amp;quot;Hawaii&amp;quot;, &amp;quot;Puerto Rico&amp;quot;)))
ggplot() +
geom_sf(data = lower_48, fill = &amp;quot;#192DA1&amp;quot;, color = &amp;quot;white&amp;quot;, size = 0.25) +
coord_sf(crs = st_crs(&amp;quot;EPSG:4269&amp;quot;)) + # NAD83
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/us-nad83-1.png" width="576" style="display: block; margin: auto;" />
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = lower_48, fill = &amp;quot;#192DA1&amp;quot;, color = &amp;quot;white&amp;quot;, size = 0.25) +
coord_sf(crs = st_crs(&amp;quot;ESRI:102003&amp;quot;)) + # Albers
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/us-albers-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="us-map-with-non-continguous-parts">US map with non-continguous parts&lt;/h3>
&lt;p>Plotting places like Alaska, Hawaii, and Puerto Rico gets a little tricky since they&amp;rsquo;re far away from the contiguous 48 states. There&amp;rsquo;s an easy way to handle it though!&lt;/p>
&lt;p>First, there&amp;rsquo;s a package named &lt;a href="https://github.com/walkerke/tigris" target="_blank" rel="noopener">&lt;strong>tigris&lt;/strong>&lt;/a> that provides a neat interface for working with spatial data from the &lt;a href="https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-line-file.html" target="_blank" rel="noopener">US Census&amp;rsquo;s TIGER shapefiles&lt;/a> (like downloading them directly for you). &lt;strong>tigris&lt;/strong> is on CRAN, but as of May 2021, it&amp;rsquo;s an older version from July 2020 that&amp;rsquo;s missing some neat additions. Install the latest development version &lt;a href="https://github.com/walkerke/tigris" target="_blank" rel="noopener">following the instructions at GitHub&lt;/a> (i.e. run &lt;code>remotes::install_github('walkerke/tigris')&lt;/code> in your console).&lt;/p>
&lt;p>In addition to providing a ton of functions for getting shapefiles for states, counties, voting districts, Tribal areas, military bases, and dozens of other things, &lt;strong>tigris&lt;/strong> has a &lt;code>shift_geometry()&lt;/code> function that will change the coordinates for Alaska, Hawaii, and Puerto Rico so that they end up in Mexico and the Gulf of Mexico.&lt;/p>
&lt;pre>&lt;code class="language-r">library(tigris)
# This is the Census shapefile we loaded earlier. Note how we're not filtering
# out AK, HI, and PR now
us_states_shifted &amp;lt;- us_states %&amp;gt;%
shift_geometry() # Move AK, HI, and PR around
ggplot() +
geom_sf(data = us_states_shifted) +
coord_sf(crs = st_crs(&amp;quot;ESRI:102003&amp;quot;)) + # Albers
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/tigris-shifting-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>The &lt;code>shift_geometry()&lt;/code> function should work on any shapefile. What if you have a shapefile with the coordinates of all public libraries in Alaska? Those will use the actual coordinates, not the shifted-to-Mexico coordinates. Feed that data to &lt;code>shift_geometry()&lt;/code> and it should translate any coordinates you have in Alaska, Hawaii, and Puerto Rico to the Mexico area so they&amp;rsquo;ll plot correctly.&lt;/p>
&lt;p>&lt;code>shift_geometry()&lt;/code> has an optional &lt;code>position&lt;/code> argument that lets you control where the non-contiguous states go. By default they&amp;rsquo;ll go below the continental US (&lt;code>position = &amp;quot;below&amp;quot;&lt;/code>), but you can also use &lt;code>position = &amp;quot;outside&amp;quot;&lt;/code> to place them more in relation to where they are in real life:&lt;/p>
&lt;pre>&lt;code class="language-r">us_states_shifted &amp;lt;- us_states %&amp;gt;%
shift_geometry(position = &amp;quot;outside&amp;quot;)
ggplot() +
geom_sf(data = us_states_shifted) +
coord_sf(crs = st_crs(&amp;quot;ESRI:102003&amp;quot;)) + # Albers
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/tigris-shifting-alt-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="individual-states">Individual states&lt;/h3>
&lt;p>Again, because these shapefiles are really just fancy data frames, we can filter them with normal dplyr functions. Let&amp;rsquo;s plot just Georgia:&lt;/p>
&lt;pre>&lt;code class="language-r">only_georgia &amp;lt;- lower_48 %&amp;gt;%
filter(NAME == &amp;quot;Georgia&amp;quot;)
ggplot() +
geom_sf(data = only_georgia, fill = &amp;quot;#EC8E55&amp;quot;) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/georgia-only-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can also use a different projection. If we look at &lt;a href="http://epsg.io/" target="_blank" rel="noopener">epsg.io&lt;/a>, there&amp;rsquo;s &lt;a href="http://epsg.io/2239-1713" target="_blank" rel="noopener">a version of NAD83 that&amp;rsquo;s focused specifically on Georgia&lt;/a>.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia, fill = &amp;quot;#EC8E55&amp;quot;) +
theme_void() +
coord_sf(crs = st_crs(&amp;quot;EPSG:2239&amp;quot;)) # NAD83 focused on Georgia
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/georgia-only-projection-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>There&amp;rsquo;s one small final issue though: we&amp;rsquo;re missing all the Atlantic islands in the southeast like Cumberland Island and Amelia Island. That&amp;rsquo;s because we&amp;rsquo;re using the Census&amp;rsquo;s low resolution (20m) data. That&amp;rsquo;s fine for the map of the whole country, but if we&amp;rsquo;re looking at a single state, we probably want better detail in the borders. We can use the Census&amp;rsquo;s high resolution (500k) data, but even then it doesn&amp;rsquo;t include the islands for whatever reason, but &lt;a href="https://www.naturalearthdata.com/downloads/10m-cultural-vectors/10m-admin-1-states-provinces/" target="_blank" rel="noopener">Natural Earth has high resolution US state data&lt;/a> that &lt;em>does&lt;/em> have the islands, so we can use that:&lt;/p>
&lt;pre>&lt;code class="language-r">only_georgia_high &amp;lt;- us_states_hires %&amp;gt;%
filter(iso_3166_2 == &amp;quot;US-GA&amp;quot;)
ggplot() +
geom_sf(data = only_georgia_high, fill = &amp;quot;#EC8E55&amp;quot;) +
theme_void() +
coord_sf(crs = st_crs(&amp;quot;EPSG:2239&amp;quot;)) # NAD83 focused on Georgia
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/georgia-only-hires-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Perfect.&lt;/p>
&lt;h3 id="plotting-multiple-shapefile-layers">Plotting multiple shapefile layers&lt;/h3>
&lt;p>The state shapefiles from the Census Bureau only include state boundaries. If we want to see counties in Georgia, we need to download and load the Census&amp;rsquo;s county shapefiles (which we did above). We can then add a second &lt;code>geom_sf()&lt;/code> layer for the counties.&lt;/p>
&lt;p>First we need to filter the county data to only include Georgia counties. The counties data doesn&amp;rsquo;t include a column with the state name or state abbreviation, but it does include a column named &lt;code>STATEFP&lt;/code>, which is the &lt;a href="https://en.wikipedia.org/wiki/Federal_Information_Processing_Standard_state_code" target="_blank" rel="noopener">state FIPS code&lt;/a>. Looking at &lt;code>lower_48&lt;/code> we can see that the state FIPS code for Georgia is 13, so we use that to filter.&lt;/p>
&lt;pre>&lt;code class="language-r">ga_counties &amp;lt;- us_counties %&amp;gt;%
filter(STATEFP == 13)
&lt;/code>&lt;/pre>
&lt;p>Now we can plot just the counties:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = ga_counties) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/ga-counties-only-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Technically we can just draw the county boundaries instead of layer the state boundary + the counties, since the borders of the counties make up the border of the state. But there&amp;rsquo;s an advantage to including both: we can use different aesthetics on each, like adding a thicker border on the state:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia_high, color = &amp;quot;#EC8E55&amp;quot;, size = 3) +
geom_sf(data = ga_counties, fill = &amp;quot;#A5D46A&amp;quot;, color = &amp;quot;white&amp;quot;) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/ga-counties-in-state-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>It&amp;rsquo;s also useful if we want to only show some counties, like metropolitan Atlanta:&lt;/p>
&lt;pre>&lt;code class="language-r">atl_counties &amp;lt;- ga_counties %&amp;gt;%
filter(NAME %in% c(&amp;quot;Cherokee&amp;quot;, &amp;quot;Clayton&amp;quot;, &amp;quot;Cobb&amp;quot;, &amp;quot;DeKalb&amp;quot;, &amp;quot;Douglas&amp;quot;,
&amp;quot;Fayette&amp;quot;, &amp;quot;Fulton&amp;quot;, &amp;quot;Gwinnett&amp;quot;, &amp;quot;Henry&amp;quot;, &amp;quot;Rockdale&amp;quot;))
ggplot() +
geom_sf(data = only_georgia_high, fill = &amp;quot;#EC8E55&amp;quot;) +
geom_sf(data = atl_counties, fill = &amp;quot;#A5D46A&amp;quot;, color = &amp;quot;white&amp;quot;) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/atl-counties-in-state-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="plotting-multiple-shapefile-layers-when-some-are-bigger-than-the-parent-shape">Plotting multiple shapefile layers when some are bigger than the parent shape&lt;/h3>
&lt;p>So far we&amp;rsquo;ve been able to filter out states and counties that we don&amp;rsquo;t want to plot using &lt;code>filter()&lt;/code>, which works because the shapefiles have geometry data for each state or county. But what if you&amp;rsquo;re plotting stuff that doesn&amp;rsquo;t follow state or county boundaries, like freeways, roads, rivers, or lakes?&lt;/p>
&lt;p>At the beginning we loaded a shapefile for all large and small rivers in the US. Look at the first few rows of &lt;code>rivers_na&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">head(rivers_na)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Simple feature collection with 6 features and 37 fields
## Geometry type: MULTILINESTRING
## Dimension: XY
## Bounding box: xmin: -100 ymin: 29 xmax: -86 ymax: 36
## Geodetic CRS: WGS 84
## # A tibble: 6 x 38
## featurecla scalerank rivernum dissolve name name_alt note name_full min_zoom strokeweig uident min_label label wikidataid name_ar name_bn name_de
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 River 10 22360 22360Rivâ€¦ Coloâ€¦ &amp;lt;NA&amp;gt; ID iâ€¦ Coloradoâ€¦ 6 0.3 1.99e6 7 Coloâ€¦ Q847785 &amp;lt;NA&amp;gt; &amp;lt;NA&amp;gt; Coloraâ€¦
## 2 River 10 22572 22572Rivâ€¦ Cimaâ€¦ &amp;lt;NA&amp;gt; ID iâ€¦ Cimarronâ€¦ 6 0.25 2.15e6 7 Cimaâ€¦ Q1092055 &amp;lt;NA&amp;gt; &amp;lt;NA&amp;gt; Cimarrâ€¦
## 3 River 10 22519 22519Rivâ€¦ Washâ€¦ &amp;lt;NA&amp;gt; ID iâ€¦ Washita â€¦ 6 0.25 1.95e6 7 Washâ€¦ Q2993598 &amp;lt;NA&amp;gt; &amp;lt;NA&amp;gt; Washita
## 4 River 10 22519 22519Rivâ€¦ Washâ€¦ &amp;lt;NA&amp;gt; ID iâ€¦ Washita â€¦ 6 0.15 1.95e6 7 Washâ€¦ Q2993598 &amp;lt;NA&amp;gt; &amp;lt;NA&amp;gt; Washita
## 5 River 11 22422 22422Rivâ€¦ Coneâ€¦ &amp;lt;NA&amp;gt; ID iâ€¦ Conecuh â€¦ 6.7 0.15 2.17e6 7.7 Coneâ€¦ Q5159475 &amp;lt;NA&amp;gt; &amp;lt;NA&amp;gt; &amp;lt;NA&amp;gt;
## 6 River 10 22421 22421Rivâ€¦ Pea &amp;lt;NA&amp;gt; ID iâ€¦ Pea River 6 0.15 1.96e6 7 Pea Q7157190 &amp;lt;NA&amp;gt; &amp;lt;NA&amp;gt; &amp;lt;NA&amp;gt;
## # â€¦ with 21 more variables: name_en &amp;lt;chr&amp;gt;, name_es &amp;lt;chr&amp;gt;, name_fr &amp;lt;chr&amp;gt;, name_el &amp;lt;chr&amp;gt;, name_hi &amp;lt;chr&amp;gt;, name_hu &amp;lt;chr&amp;gt;, name_id &amp;lt;chr&amp;gt;, name_it &amp;lt;chr&amp;gt;,
## # name_ja &amp;lt;chr&amp;gt;, name_ko &amp;lt;chr&amp;gt;, name_nl &amp;lt;chr&amp;gt;, name_pl &amp;lt;chr&amp;gt;, name_pt &amp;lt;chr&amp;gt;, name_ru &amp;lt;chr&amp;gt;, name_sv &amp;lt;chr&amp;gt;, name_tr &amp;lt;chr&amp;gt;, name_vi &amp;lt;chr&amp;gt;,
## # name_zh &amp;lt;chr&amp;gt;, wdid_score &amp;lt;int&amp;gt;, ne_id &amp;lt;dbl&amp;gt;, geometry &amp;lt;MULTILINESTRING [Â°]&amp;gt;
&lt;/code>&lt;/pre>
&lt;p>The first row is the whole Colorado river, which flows through seven states. We can&amp;rsquo;t just use &lt;code>filter()&lt;/code> to only select some parts of it based on states.&lt;/p>
&lt;p>Here&amp;rsquo;s what happens if we combine our Georgia map with rivers and lakes:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia, fill = &amp;quot;#EC8E55&amp;quot;) +
geom_sf(data = rivers_na) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/ga-rivers-bad-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>It plots Georgia, and it&amp;rsquo;s filled with orange, but it also plots every single river in North America. Oops.&lt;/p>
&lt;p>We need to do a little GIS work to basically use &lt;code>only_georgia&lt;/code> as a cookie cutter and keep only the rivers that are contained in the &lt;code>only_georgia&lt;/code> boundaries. Fortunately, there&amp;rsquo;s a function in the &lt;strong>sf&lt;/strong> package that does this: &lt;code>st_intersection()&lt;/code>. Feed it two shapefile datasets and it will select the parts of the second that fall within the boundaries of the first:&lt;/p>
&lt;pre>&lt;code class="language-r">ga_rivers_na &amp;lt;- st_intersection(only_georgia, rivers_na)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Error in geos_op2_geom(&amp;quot;intersection&amp;quot;, x, y): st_crs(x) == st_crs(y) is not TRUE
&lt;/code>&lt;/pre>
&lt;p>Oh no! An error! It&amp;rsquo;s complaining that the reference systems used in these two datasets don&amp;rsquo;t match. We can check the CRS with &lt;code>st_crs()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">st_crs(only_georgia)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Coordinate Reference System:
## User input: NAD83
## wkt:
## GEOGCRS[&amp;quot;NAD83&amp;quot;,
## DATUM[&amp;quot;North American Datum 1983&amp;quot;,
## ELLIPSOID[&amp;quot;GRS 1980&amp;quot;,6378137,298.257222101,
## LENGTHUNIT[&amp;quot;metre&amp;quot;,1]]],
## PRIMEM[&amp;quot;Greenwich&amp;quot;,0,
## ANGLEUNIT[&amp;quot;degree&amp;quot;,0.0174532925199433]],
## CS[ellipsoidal,2],
## AXIS[&amp;quot;latitude&amp;quot;,north,
## ORDER[1],
## ANGLEUNIT[&amp;quot;degree&amp;quot;,0.0174532925199433]],
## AXIS[&amp;quot;longitude&amp;quot;,east,
## ORDER[2],
## ANGLEUNIT[&amp;quot;degree&amp;quot;,0.0174532925199433]],
## ID[&amp;quot;EPSG&amp;quot;,4269]]
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">st_crs(rivers_na)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Coordinate Reference System:
## User input: WGS 84
## wkt:
## GEOGCRS[&amp;quot;WGS 84&amp;quot;,
## DATUM[&amp;quot;World Geodetic System 1984&amp;quot;,
## ELLIPSOID[&amp;quot;WGS 84&amp;quot;,6378137,298.257223563,
## LENGTHUNIT[&amp;quot;metre&amp;quot;,1]]],
## PRIMEM[&amp;quot;Greenwich&amp;quot;,0,
## ANGLEUNIT[&amp;quot;degree&amp;quot;,0.0174532925199433]],
## CS[ellipsoidal,2],
## AXIS[&amp;quot;latitude&amp;quot;,north,
## ORDER[1],
## ANGLEUNIT[&amp;quot;degree&amp;quot;,0.0174532925199433]],
## AXIS[&amp;quot;longitude&amp;quot;,east,
## ORDER[2],
## ANGLEUNIT[&amp;quot;degree&amp;quot;,0.0174532925199433]],
## ID[&amp;quot;EPSG&amp;quot;,4326]]
&lt;/code>&lt;/pre>
&lt;p>The Georgia map uses EPSG:4269 (&lt;a href="https://epsg.io/4269" target="_blank" rel="noopener">or NAD83&lt;/a>), while the rivers map uses EPSG:4326 (or &lt;a href="https://epsg.io/4326" target="_blank" rel="noopener">the GPS system of latitude and longitude&lt;/a>). We need to convert one of them to make them match. It doesn&amp;rsquo;t matter which one.&lt;/p>
&lt;pre>&lt;code class="language-r">only_georgia_4326 &amp;lt;- only_georgia %&amp;gt;%
st_transform(crs = st_crs(&amp;quot;EPSG:4326&amp;quot;))
ga_rivers_na &amp;lt;- st_intersection(only_georgia_4326, rivers_na)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Warning: attribute variables are assumed to be spatially constant throughout all geometries
&lt;/code>&lt;/pre>
&lt;p>You&amp;rsquo;ll get an ominous warning, but you should be okayâ€”it&amp;rsquo;s just because flattening globes into flat planes is hard, and the cutting &lt;a href="https://github.com/r-spatial/sf/issues/493" target="_blank" rel="noopener">might not be 100% accurate&lt;/a>, but it&amp;rsquo;ll be close enough for our mapping purposes.&lt;/p>
&lt;p>Now we can plot our state shape and the truncated rivers:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia, fill = &amp;quot;#EC8E55&amp;quot;) +
geom_sf(data = ga_rivers_na) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/ga-rivers-good-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Hey! It worked! Let&amp;rsquo;s put all the rivers and lakes on at once and make it a little more artsy. We&amp;rsquo;ll use the high resolution Georgia map too, which conveniently already matches the CRS of the rivers and lakes:&lt;/p>
&lt;pre>&lt;code class="language-r">ga_rivers_na &amp;lt;- st_intersection(only_georgia_high, rivers_na)
ga_rivers_global &amp;lt;- st_intersection(only_georgia_high, rivers_global)
# sf v1.0 changed how it handles shapefiles with spherical elements, which
# apparently the lakes data uses. Currently when using st_intersection() and
# other GIS-related functions, it breaks. This can be fixed by feeding the lakes
# data to st_make_valid(), which does something fancy behind the scenes to make
# it work. See this: https://github.com/r-spatial/sf/issues/1649#issuecomment-853279986
ga_lakes &amp;lt;- st_intersection(only_georgia_high, st_make_valid(lakes))
ggplot() +
geom_sf(data = only_georgia_high,
color = &amp;quot;black&amp;quot;, size = 0.1, fill = &amp;quot;black&amp;quot;) +
geom_sf(data = ga_rivers_global, size = 0.3, color = &amp;quot;grey80&amp;quot;) +
geom_sf(data = ga_rivers_na, size = 0.15, color = &amp;quot;grey80&amp;quot;) +
geom_sf(data = ga_lakes, size = 0.3, fill = &amp;quot;grey80&amp;quot;, color = NA) +
coord_sf(crs = st_crs(&amp;quot;EPSG:4326&amp;quot;)) + # NAD83
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/ga-all-water-1.png" width="960" style="display: block; margin: auto;" />
&lt;p>Heck yeah. That&amp;rsquo;s a great map. This is basically what &lt;a href="https://kieranhealy.org/prints/rivers/" target="_blank" rel="noopener">Kieran Healy did here&lt;/a>, but he used &lt;a href="https://www.usgs.gov/core-science-systems/ngp/national-hydrography" target="_blank" rel="noopener">even more detailed shapefiles from the US Geological Survey&lt;/a>.&lt;/p>
&lt;h3 id="plotting-schools-in-georgia">Plotting schools in Georgia&lt;/h3>
&lt;p>Shapefiles are not limited to just lines and areasâ€”they can also contain points. I made a free account at the Georgia GIS Clearinghouse, searched for &amp;ldquo;schools&amp;rdquo; and found a shapefile of all the Kâ€“12 schools in 2009. &lt;a href="https://data.georgiaspatial.org/index.asp?body=preview&amp;amp;dataId=41516" target="_blank" rel="noopener">This is the direct link to the page&lt;/a>, but it only works if you&amp;rsquo;re logged in to their system. &lt;a href="https://data.georgiaspatial.org/data/statewide/other/schools_2009.html" target="_blank" rel="noopener">This is the official metadata for the shapefile&lt;/a>, which you can see if you&amp;rsquo;re not logged in, but you can&amp;rsquo;t download anything. It&amp;rsquo;s a dumb system and other states are a lot better at offering their GIS data (like, &lt;a href="https://gis.utah.gov/data/society/schools-libraries/" target="_blank" rel="noopener">here&amp;rsquo;s a shapefile of all of Utah&amp;rsquo;s schools and libraries&lt;/a> as of 2017, publicly accessible without an account).&lt;/p>
&lt;p>We loaded the shapefile up at the top, but now let&amp;rsquo;s look at it:&lt;/p>
&lt;pre>&lt;code class="language-r">head(ga_schools)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Simple feature collection with 6 features and 16 fields
## Geometry type: POINT
## Dimension: XY
## Bounding box: xmin: 2100000 ymin: 320000 xmax: 2200000 ymax: 5e+05
## Projected CRS: NAD83 / Georgia West (ftUS)
## # A tibble: 6 x 17
## ID DATA COUNTY DISTRICT SCHOOLNAME GRADES ADDRESS CITY STATE ZIP TOTAL SCHOOLID DOE_CONGRE CONGRESS SENATE HOUSE geometry
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;POINT [m]&amp;gt;
## 1 4313 224 Early Early Coâ€¦ Early Countâ€¦ PK,KKâ€¦ 283 Maâ€¦ Blakâ€¦ GA 3982â€¦ 1175 43549 2 002 011 149 (2052182 494322)
## 2 4321 227 Early Early Coâ€¦ ETN Eckerd â€¦ 06,07â€¦ 313 E â€¦ Blakâ€¦ GA 3982â€¦ 30 47559 2 002 011 149 (2053200 5e+05)
## 3 4329 226 Early Early Coâ€¦ Early Countâ€¦ 06,07â€¦ 12053 â€¦ Blakâ€¦ GA 3982â€¦ 539 43550 2 002 011 149 (2055712 5e+05)
## 4 4337 225 Early Early Coâ€¦ Early Countâ€¦ 09,10â€¦ 12020 â€¦ Blakâ€¦ GA 3982â€¦ 716 43552 2 002 011 149 (2055712 5e+05)
## 5 4345 189 Decatur Decatur â€¦ John Johnsoâ€¦ PK,KKâ€¦ 1947 Sâ€¦ Bainâ€¦ GA 3981â€¦ 555 43279 2 002 011 172 (2168090 321781)
## 6 4353 192 Decatur Decatur â€¦ Potter Streâ€¦ PK,KKâ€¦ 725 Poâ€¦ Bainâ€¦ GA 3981â€¦ 432 43273 2 002 011 172 (2168751 327375)
&lt;/code>&lt;/pre>
&lt;p>We have a bunch of columns like &lt;code>GRADES&lt;/code> that has a list of what grades are included in the school, and &lt;code>TOTAL&lt;/code>, which I&amp;rsquo;m guessing is the number of students. Let&amp;rsquo;s map it!&lt;/p>
&lt;p>If we add a &lt;code>geom_sf()&lt;/code> layer just for &lt;code>ga_schools&lt;/code>, it&amp;rsquo;ll plot a bunch of points:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = ga_schools)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/plot-ga-schools-initial-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>One of these rows is wildly miscoded and ended up Indonesia! If you sort by the &lt;code>geometry&lt;/code> column in RStudio, you&amp;rsquo;ll see that it&amp;rsquo;s most likely Allatoona High School in Cobb County (id = 22097). The coordinates are different from all the others, and it has no congressional district information. Let&amp;rsquo;s remove it.&lt;/p>
&lt;pre>&lt;code class="language-r">ga_schools_fixed &amp;lt;- ga_schools %&amp;gt;%
filter(ID != 22097)
ggplot() +
geom_sf(data = ga_schools_fixed)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/plot-ga-schools-fixed-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>That&amp;rsquo;s better. However, all we&amp;rsquo;re plotting now are the pointsâ€”we&amp;rsquo;ve lost the state and/or county boundaries. Let&amp;rsquo;s include those:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia_high) +
geom_sf(data = ga_schools_fixed) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/plot-ga-schools-borders-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We&amp;rsquo;re getting closer. We have some issues with overplotting, so let&amp;rsquo;s shrink the points down and make them a little transparent:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia_high) +
geom_sf(data = ga_schools_fixed, size = 0.5, alpha = 0.5) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/plot-ga-schools-shrunk-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Neat. One last thing we can do is map the &lt;code>TOTAL&lt;/code> column to the color aesthetic and color the points by how many students attend each school:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia_high) +
geom_sf(data = ga_schools_fixed, aes(color = TOTAL), size = 0.75, alpha = 0.5) +
scale_color_viridis_c() +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/plot-ga-schools-color-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Most schools appear to be under 1,000 students, except for a cluster in Gwinnett County north of Atlanta. Its high schools have nearly 4,000 students each!&lt;/p>
&lt;pre>&lt;code class="language-r">ga_schools_fixed %&amp;gt;%
select(COUNTY, SCHOOLNAME, TOTAL) %&amp;gt;%
arrange(desc(TOTAL)) %&amp;gt;%
head()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Simple feature collection with 6 features and 3 fields
## Geometry type: POINT
## Dimension: XY
## Bounding box: xmin: 2300000 ymin: 1400000 xmax: 2400000 ymax: 1500000
## Projected CRS: NAD83 / Georgia West (ftUS)
## # A tibble: 6 x 4
## COUNTY SCHOOLNAME TOTAL geometry
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;POINT [m]&amp;gt;
## 1 Gwinnett Mill Creek High School 3997 (2384674 1482772)
## 2 Gwinnett Collins Hill High School 3720 (2341010 1461730)
## 3 Gwinnett Brookwood High School 3455 (2334543 1413396)
## 4 Gwinnett Grayson High School 3230 (2370186 1408579)
## 5 Gwinnett Peachtree Ridge High School 3118 (2319344 1459458)
## 6 Gwinnett Berkmar High School 3095 (2312983 1421933)
&lt;/code>&lt;/pre>
&lt;h3 id="making-your-own-geoencoded-data">Making your own geoencoded data&lt;/h3>
&lt;p>So, plotting shapefiles with &lt;code>geom_sf()&lt;/code> is magical because &lt;strong>sf&lt;/strong> deals with all of the projection issues for us automatically and it figures out how to plot all the latitude and longitude data for us automatically. But lots of data &lt;em>doesn&amp;rsquo;t&lt;/em> some as shapefiles. The &lt;a href="https://aem2850.toddgerarden.com/assignment/01-mini-project/">rats data from mini project 1&lt;/a>, for instance, has two columns indicating the latitude and longitude of each rat sighting, but those are stored as just numbers. If we try to use &lt;code>geom_sf()&lt;/code> with the rat data, it won&amp;rsquo;t work. We need that magical &lt;code>geometry&lt;/code> column.&lt;/p>
&lt;p>Fortunately, if we have latitude and longitude information, we can make our own &lt;code>geometry&lt;/code> column.&lt;/p>
&lt;p>Let&amp;rsquo;s say we want to mark some cities on our map of Georgia. We can make a mini dataset using &lt;code>tribble()&lt;/code>. I found these points from Google Maps: right click anywhere in Google Maps, select &amp;ldquo;What&amp;rsquo;s here?&amp;rdquo;, and you&amp;rsquo;ll see the exact coordinates for that spot.&lt;/p>
&lt;pre>&lt;code class="language-r">ga_cities &amp;lt;- tribble(
~city, ~lat, ~long,
&amp;quot;Atlanta&amp;quot;, 33.748955, -84.388099,
&amp;quot;Athens&amp;quot;, 33.950794, -83.358884,
&amp;quot;Savannah&amp;quot;, 32.113192, -81.089350
)
ga_cities
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 3 x 3
## city lat long
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 Atlanta 33.7 -84.4
## 2 Athens 34.0 -83.4
## 3 Savannah 32.1 -81.1
&lt;/code>&lt;/pre>
&lt;p>This is just a normal dataset, and the &lt;code>lat&lt;/code> and &lt;code>long&lt;/code> columns are just numbers. R doesn&amp;rsquo;t know that those are actually geographic coordinates. This is similar to the rats data, or any other data that has columns for latitude and longitude.&lt;/p>
&lt;p>We can convert those two columns to the magic &lt;code>geometry&lt;/code> column with the &lt;code>st_as_sf()&lt;/code> function. We have to define two things in the function: which coordinates are the longitude and latitude, and what CRS the coordinates are using. Google Maps uses &lt;a href="http://epsg.io/4326" target="_blank" rel="noopener">EPSG:4326, or the GPS system&lt;/a>, so we specify that:&lt;/p>
&lt;pre>&lt;code class="language-r">ga_cities_geometry &amp;lt;- ga_cities %&amp;gt;%
st_as_sf(coords = c(&amp;quot;long&amp;quot;, &amp;quot;lat&amp;quot;), crs = st_crs(&amp;quot;EPSG:4326&amp;quot;))
ga_cities_geometry
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Simple feature collection with 3 features and 1 field
## Geometry type: POINT
## Dimension: XY
## Bounding box: xmin: -84 ymin: 32 xmax: -81 ymax: 34
## Geodetic CRS: WGS 84
## # A tibble: 3 x 2
## city geometry
## * &amp;lt;chr&amp;gt; &amp;lt;POINT [Â°]&amp;gt;
## 1 Atlanta (-84 34)
## 2 Athens (-83 34)
## 3 Savannah (-81 32)
&lt;/code>&lt;/pre>
&lt;p>The longitude and latitude columns are gone now, and we have a single magical &lt;code>geometry&lt;/code> column. That means we can plot it with &lt;code>geom_sf()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia_high, fill = &amp;quot;#EC8E55&amp;quot;) +
geom_sf(data = ga_cities_geometry, size = 3) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/ga-with-cities-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can use &lt;code>geom_sf_label()&lt;/code> (or &lt;code>geom_sf_text()&lt;/code>) to add labels in the correct locations too. It will give you a warning, but you can ignore itâ€”again, it&amp;rsquo;s complaining that the positioning might not be 100% accurate because of issues related to taking a globe and flattening it. It&amp;rsquo;s fine.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = only_georgia_high, fill = &amp;quot;#EC8E55&amp;quot;) +
geom_sf(data = ga_cities_geometry, size = 3) +
geom_sf_label(data = ga_cities_geometry, aes(label = city),
nudge_y = 0.2) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/ga-with-cities-text-1.png" width="960" style="display: block; margin: auto;" />
&lt;h3 id="automatic-geoencoding-by-address">Automatic geoencoding by address&lt;/h3>
&lt;p>Using &lt;code>st_as_sf()&lt;/code> is neat when you have latitude and longitude data already, but what if you have a list of addresses or cities instead, with no fancy geographic information? It&amp;rsquo;s easy enough to right click on Google Maps, but you don&amp;rsquo;t really want to do that hundreds of times for large-scale data.&lt;/p>
&lt;p>Fortunately there are a bunch of different online geoencoding services that return GIS data for addresses and locations that you feed them, like magic.&lt;/p>
&lt;p>The easiest way to use any of these services is to use the &lt;a href="https://jessecambon.github.io/tidygeocoder/" target="_blank" rel="noopener">&lt;strong>tidygeocoder&lt;/strong>&lt;/a> package, which connects with all these different free and paid services (run &lt;code>?geo&lt;/code> in R for complete details):&lt;/p>
&lt;ul>
&lt;li>&lt;code>&amp;quot;osm&amp;quot;&lt;/code>: OpenStreetMap through &lt;a href="https://nominatim.org/" target="_blank" rel="noopener">Nominatim&lt;/a>. &lt;strong>FREE&lt;/strong>.&lt;/li>
&lt;li>&lt;code>&amp;quot;census&amp;quot;&lt;/code>: &lt;a href="https://geocoding.geo.census.gov/" target="_blank" rel="noopener">US Census&lt;/a>. Geographic coverage is limited to the United States. &lt;strong>FREE&lt;/strong>.&lt;/li>
&lt;li>&lt;code>&amp;quot;arcgis&amp;quot;&lt;/code>: &lt;a href="https://developers.arcgis.com/rest/geocode/api-reference/overview-world-geocoding-service.htm" target="_blank" rel="noopener">ArcGIS&lt;/a>. &lt;strong>FREE&lt;/strong> and paid.&lt;/li>
&lt;li>&lt;code>&amp;quot;geocodio&amp;quot;&lt;/code>: &lt;a href="https://www.geocod.io/" target="_blank" rel="noopener">Geocodio&lt;/a>. Geographic coverage is limited to the United States and Canada. An API key must be stored in &lt;code>&amp;quot;GEOCODIO_API_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;quot;iq&amp;quot;&lt;/code>: &lt;a href="https://locationiq.com/" target="_blank" rel="noopener">Location IQ&lt;/a>. An API key must be stored in &lt;code>&amp;quot;LOCATIONIQ_API_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;quot;google&amp;quot;&lt;/code>: &lt;a href="https://developers.google.com/maps/documentation/geocoding/overview" target="_blank" rel="noopener">Google&lt;/a>. An API key must be stored in &lt;code>&amp;quot;GOOGLEGEOCODE_API_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;quot;opencage&amp;quot;&lt;/code>: &lt;a href="https://opencagedata.com/" target="_blank" rel="noopener">OpenCage&lt;/a>. An API key must be stored in &lt;code>&amp;quot;OPENCAGE_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;quot;mapbox&amp;quot;&lt;/code>: &lt;a href="https://docs.mapbox.com/api/search/" target="_blank" rel="noopener">Mapbox&lt;/a>. An API key must be stored in &lt;code>&amp;quot;MAPBOX_API_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;quot;here&amp;quot;&lt;/code>: &lt;a href="https://developer.here.com/products/geocoding-and-search" target="_blank" rel="noopener">HERE&lt;/a>. An API key must be stored in &lt;code>&amp;quot;HERE_API_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;quot;tomtom&amp;quot;&lt;/code>: &lt;a href="https://developer.tomtom.com/search-api/search-api-documentation/geocoding" target="_blank" rel="noopener">TomTom&lt;/a>. An API key must be stored in &lt;code>&amp;quot;TOMTOM_API_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;quot;mapquest&amp;quot;&lt;/code>: &lt;a href="https://developer.mapquest.com/documentation/geocoding-api/" target="_blank" rel="noopener">MapQuest&lt;/a>. An API key must be stored in &lt;code>&amp;quot;MAPQUEST_API_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;li>&lt;code>&amp;quot;bing&amp;quot;&lt;/code>: &lt;a href="https://docs.microsoft.com/en-us/bingmaps/rest-services/locations/" target="_blank" rel="noopener">Bing&lt;/a>. An API key must be stored in &lt;code>&amp;quot;BINGMAPS_API_KEY&amp;quot;&lt;/code>.&lt;/li>
&lt;/ul>
&lt;p>Not all services work equally well, and the free ones have rate limits (like, don&amp;rsquo;t try to geocode a million rows of data with the US Census), so you&amp;rsquo;ll have to play around with different services. You can also provide a list of services and &lt;strong>tidygeocoder&lt;/strong> will cascade through themâ€”if it can&amp;rsquo;t geocode an address with OpenStreetMap, it can move on to the Census, then ArcGIS, and so on. You need to set the &lt;code>cascade_order&lt;/code> argument in &lt;code>geocode()&lt;/code> for this to work.&lt;/p>
&lt;p>Let&amp;rsquo;s make a little dataset with some addresses to geocode:&lt;/p>
&lt;pre>&lt;code class="language-r">some_addresses &amp;lt;- tribble(
~name, ~address,
&amp;quot;The White House&amp;quot;, &amp;quot;1600 Pennsylvania Ave NW, Washington, DC&amp;quot;,
&amp;quot;The Andrew Young School of Policy Studies&amp;quot;, &amp;quot;14 Marietta Street NW, Atlanta, GA 30303&amp;quot;
)
some_addresses
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 2 x 2
## name address
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 The White House 1600 Pennsylvania Ave NW, Washington, DC
## 2 The Andrew Young School of Policy Studies 14 Marietta Street NW, Atlanta, GA 30303
&lt;/code>&lt;/pre>
&lt;p>To geocode these addresses, we can feed this data into &lt;code>geocode()&lt;/code> and tell it to use the &lt;code>address&lt;/code> column. We&amp;rsquo;ll use the Census geocoding system for fun (surely they know where the White House is):&lt;/p>
&lt;pre>&lt;code class="language-r">geocoded_addresses &amp;lt;- some_addresses %&amp;gt;%
geocode(address, method = &amp;quot;census&amp;quot;)
geocoded_addresses
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 2 x 3
## name lat long
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 The White House 38.9 -77.0
## 2 The Andrew Young School of Policy Studies 33.8 -84.4
&lt;/code>&lt;/pre>
&lt;p>It worked!&lt;/p>
&lt;p>Those are just numbers, though, and not the magical &lt;code>geometry&lt;/code> column, so we need to use &lt;code>st_as_sf()&lt;/code> to convert them to actual GIS data.&lt;/p>
&lt;pre>&lt;code class="language-r">addresses_geometry &amp;lt;- geocoded_addresses %&amp;gt;%
st_as_sf(coords = c(&amp;quot;long&amp;quot;, &amp;quot;lat&amp;quot;), crs = st_crs(&amp;quot;EPSG:4326&amp;quot;))
addresses_geometry %&amp;gt;% select(-address)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Simple feature collection with 2 features and 1 field
## Geometry type: POINT
## Dimension: XY
## Bounding box: xmin: -84 ymin: 34 xmax: -77 ymax: 39
## Geodetic CRS: WGS 84
## # A tibble: 2 x 2
## name geometry
## &amp;lt;chr&amp;gt; &amp;lt;POINT [Â°]&amp;gt;
## 1 The White House (-77 39)
## 2 The Andrew Young School of Policy Studies (-84 34)
&lt;/code>&lt;/pre>
&lt;p>Let&amp;rsquo;s plot these on a US map:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = lower_48, fill = &amp;quot;#192DA1&amp;quot;, color = &amp;quot;white&amp;quot;, size = 0.25) +
geom_sf(data = addresses_geometry, size = 5, color = &amp;quot;#FF851B&amp;quot;) +
# Albers uses meters as its unit of measurement, so we need to nudge these
# labels up by a lot. I only settled on 175,000 here after a bunch of trial
# and error, adding single zeroes and rerunning the plot until the labels
# moved. 175,000 meters = 108.74 miles
geom_sf_label(data = addresses_geometry, aes(label = name),
size = 4, fill = &amp;quot;#FF851B&amp;quot;, nudge_y = 175000) +
coord_sf(crs = st_crs(&amp;quot;ESRI:102003&amp;quot;)) + # Albers
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/plot-geocoded-cities-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="plotting-other-data-on-maps">Plotting other data on maps&lt;/h3>
&lt;p>So far we&amp;rsquo;ve just plotted whatever data the shapefile creators decided to include and publish in their data. But what if you want to visualize some other variable on a map? We can do this by combining our shapefile data with any other kind of data, as long as the two have a shared column. For instance, we can make a choropleth map of life expectancy with data from the World Bank.&lt;/p>
&lt;p>First, let&amp;rsquo;s grab some data from the World Bank for just 2015:&lt;/p>
&lt;pre>&lt;code class="language-r">library(WDI) # For getting data from the World Bank
indicators &amp;lt;- c(&amp;quot;SP.DYN.LE00.IN&amp;quot;) # Life expectancy
wdi_raw &amp;lt;- WDI(country = &amp;quot;all&amp;quot;, indicators, extra = TRUE,
start = 2015, end = 2015)
&lt;/code>&lt;/pre>
&lt;p>Let&amp;rsquo;s see what we got:&lt;/p>
&lt;pre>&lt;code class="language-r">head(wdi_raw)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 11
## iso2c country SP.DYN.LE00.IN year iso3c region capital longitude latitude income lending
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 1A Arab World 71.2 2015 ARB Aggregates &amp;lt;NA&amp;gt; NA NA Aggregatâ€¦ Aggregates
## 2 1W World 71.9 2015 WLD Aggregates &amp;lt;NA&amp;gt; NA NA Aggregatâ€¦ Aggregates
## 3 4E East Asia &amp;amp; Pacific (excluding high iâ€¦ 74.5 2015 EAP Aggregates &amp;lt;NA&amp;gt; NA NA Aggregatâ€¦ Aggregates
## 4 7E Europe &amp;amp; Central Asia (excluding highâ€¦ 72.6 2015 ECA Aggregates &amp;lt;NA&amp;gt; NA NA Aggregatâ€¦ Aggregates
## 5 8S South Asia 68.6 2015 SAS Aggregates &amp;lt;NA&amp;gt; NA NA Aggregatâ€¦ Aggregates
## 6 AD Andorra NA 2015 AND Europe &amp;amp; Central â€¦ Andorra la Velâ€¦ 1.52 42.5 High incâ€¦ Not classifâ€¦
&lt;/code>&lt;/pre>
&lt;p>We have a bunch of columns here, but we care about two in particular: life expectancy, and the ISO3 code. This three-letter code is a standard system for identifying countries (&lt;a href="https://en.wikipedia.org/wiki/ISO_3166-1_alpha-3" target="_blank" rel="noopener">see the full list here&lt;/a>), and that column will let us combine this World Bank data with the global shapefile, which also has a column for the ISO3 code.&lt;/p>
&lt;p>&lt;em>(We also have columns for the latitude and longitude for each capital, so we could theoretically convert those to a &lt;code>geometry&lt;/code> column with &lt;code>st_as_sf()&lt;/code> and plot world capitals, which would be neat, but we won&amp;rsquo;t do that now.)&lt;/em>&lt;/p>
&lt;p>Let&amp;rsquo;s clean up the WDI data and shrink it down substantially:&lt;/p>
&lt;pre>&lt;code class="language-r">wdi_clean_small &amp;lt;- wdi_raw %&amp;gt;%
select(life_expectancy = SP.DYN.LE00.IN, iso3c)
wdi_clean_small
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 264 x 2
## life_expectancy iso3c
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
## 1 71.2 ARB
## 2 71.9 WLD
## 3 74.5 EAP
## 4 72.6 ECA
## 5 68.6 SAS
## 6 NA AND
## 7 77.3 ARE
## 8 63.4 AFG
## 9 76.5 ATG
## 10 78.0 ALB
## # â€¦ with 254 more rows
&lt;/code>&lt;/pre>
&lt;p>Next we need to merge this tiny dataset into the &lt;code>world_map_sans_antarctica&lt;/code> shapefile data we were using earlier. To do this we&amp;rsquo;ll use a function named &lt;code>left_join()&lt;/code>. We feed two data frames into &lt;code>left_join()&lt;/code>, and R will keep all the rows from the first and include all the columns from both the first and the second wherever the two datasets match with one specific column. That&amp;rsquo;s wordy and weirdâ€”&lt;a href="https://github.com/gadenbuie/tidyexplain#left-join" target="_blank" rel="noopener">stare at this animation here&lt;/a> for a few seconds to see what&amp;rsquo;s really going to happen. We&amp;rsquo;re essentially going to append the World Bank data to the end of the world shapefiles and line up rows that have matching ISO3 codes. The ISO3 column is named &lt;code>ISO_A3&lt;/code> in the shapefile data, and it&amp;rsquo;s named &lt;code>iso3c&lt;/code> in the WDI data, so we tell &lt;code>left_join()&lt;/code> that those are the same column:&lt;/p>
&lt;pre>&lt;code class="language-r">world_map_with_life_expectancy &amp;lt;- world_sans_antarctica %&amp;gt;%
left_join(wdi_clean_small, by = c(&amp;quot;ISO_A3&amp;quot; = &amp;quot;iso3c&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>If you look at this dataset in RStudio now and look at the last column, you&amp;rsquo;ll see the WDI life expectancy right next to the magic &lt;code>geometry&lt;/code> column.&lt;/p>
&lt;p>We technically didn&amp;rsquo;t need to shrink the WDI data down to just two columnsâ€”had we left everything else, all the WDI columns would have come over to the &lt;code>world_sans_antarctica&lt;/code>, including columns for region and income level, etc. But I generally find it easier and cleaner to only merge in the columns I care about instead of making massive datasets with a billion extra columns.&lt;/p>
&lt;p>Now that we have a column for life expectancy, we can map it to the fill aesthetic and fill each country by 2015 life expectancy:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot() +
geom_sf(data = world_map_with_life_expectancy,
aes(fill = life_expectancy),
size = 0.25) +
coord_sf(crs = st_crs(&amp;quot;ESRI:54030&amp;quot;)) + # Robinson
scale_fill_viridis_c(option = &amp;quot;viridis&amp;quot;) +
labs(fill = &amp;quot;Life expectancy&amp;quot;) +
theme_void() +
theme(legend.position = &amp;quot;bottom&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/world-life-exp-2015-1.png" width="960" style="display: block; margin: auto;" />
&lt;p>Voila! Global life expectancy in 2015!&lt;/p>
&lt;hr>
&lt;p>&lt;em>(Sharp-eyed readers will notice that France and Norway are grayed out because they&amp;rsquo;re missing data. That&amp;rsquo;s because the &lt;code>ISO_A3&lt;/code> code in the Natural Earth data is missing for both France and Norway for whatever reason, so the WDI data didn&amp;rsquo;t merge with those rows. To fix that, we can do some manual recoding before joining in the WDI data)&lt;/em>&lt;/p>
&lt;pre>&lt;code class="language-r">world_sans_antarctica_fixed &amp;lt;- world_sans_antarctica %&amp;gt;%
mutate(ISO_A3 = case_when(
# If the country name is Norway or France, redo the ISO3 code
ADMIN == &amp;quot;Norway&amp;quot; ~ &amp;quot;NOR&amp;quot;,
ADMIN == &amp;quot;France&amp;quot; ~ &amp;quot;FRA&amp;quot;,
# Otherwise use the existing ISO3 code
TRUE ~ ISO_A3
)) %&amp;gt;%
left_join(wdi_clean_small, by = c(&amp;quot;ISO_A3&amp;quot; = &amp;quot;iso3c&amp;quot;))
ggplot() +
geom_sf(data = world_sans_antarctica_fixed,
aes(fill = life_expectancy),
size = 0.25) +
coord_sf(crs = st_crs(&amp;quot;ESRI:54030&amp;quot;)) + # Robinson
scale_fill_viridis_c(option = &amp;quot;viridis&amp;quot;) +
labs(fill = &amp;quot;Life expectancy&amp;quot;) +
theme_void() +
theme(legend.position = &amp;quot;bottom&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/12-example_files/figure-html/world-life-exp-2015-fixed-1.png" width="960" style="display: block; margin: auto;" />
&lt;section class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1" role="doc-endnote">
&lt;p>TECHNICALLY coordinate systems and projection systems &lt;a href="https://gis.stackexchange.com/a/149751/56265" target="_blank" rel="noopener">are different things&lt;/a>, but I&amp;rsquo;m not a geographer and I don&amp;rsquo;t care that much about the nuance.&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;li id="fn:2" role="doc-endnote">
&lt;p>This is essentially the &lt;a href="https://en.wikipedia.org/wiki/Gall%E2%80%93Peters_projection" target="_blank" rel="noopener">Gall-Peters projection&lt;/a> from &lt;a href="https://www.youtube.com/watch?v=vVX-PrBRtTY" target="_blank" rel="noopener">the West Wing clip&lt;/a>.&amp;#160;&lt;a href="#fnref:2" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/section></description></item><item><title>Interactivity</title><link>https://aem2850.toddgerarden.com/example/10-example/</link><pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/10-example/</guid><description>&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/htmlwidgets/htmlwidgets.js">&lt;/script>
&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/pymjs/pym.v1.js">&lt;/script>
&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/widgetframe-binding/widgetframe.js">&lt;/script>
&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/htmlwidgets/htmlwidgets.js">&lt;/script>
&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/pymjs/pym.v1.js">&lt;/script>
&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/widgetframe-binding/widgetframe.js">&lt;/script>
&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/htmlwidgets/htmlwidgets.js">&lt;/script>
&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/pymjs/pym.v1.js">&lt;/script>
&lt;script src="https://aem2850.toddgerarden.com/rmarkdown-libs/widgetframe-binding/widgetframe.js">&lt;/script>
&lt;p>For this example weâ€™ll use data from the &lt;a href="https://data.worldbank.org/" target="_blank" rel="noopener">World Bank&lt;/a> once again, which we download using the &lt;a href="https://cran.r-project.org/web/packages/WDI/index.html" target="_blank" rel="noopener">&lt;strong>WDI&lt;/strong> package&lt;/a>.&lt;/p>
&lt;p>If you want to skip the data downloading, you can download the data below (youâ€™ll likely need to right click and choose â€œSave Link Asâ€¦â€):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/wdi_parl.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>wdi_parl.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;p>There is no video for this one, since it really only involves feeding a few ggplot plots fed into &lt;code>ggplotly()&lt;/code>.&lt;/p>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;h3 id="get-and-clean-data">Get and clean data&lt;/h3>
&lt;p>First, we load the libraries weâ€™ll be using:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse) # For ggplot, dplyr, and friends
library(WDI) # Get data from the World Bank
library(scales) # For nicer label formatting
library(plotly) # For easy interactive plots
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">indicators &amp;lt;- c(&amp;quot;SP.POP.TOTL&amp;quot;, # Population
&amp;quot;SG.GEN.PARL.ZS&amp;quot;, # Proportion of seats held by women in national parliaments (%)
&amp;quot;NY.GDP.PCAP.KD&amp;quot;) # GDP per capita
wdi_parl_raw &amp;lt;- WDI(country = &amp;quot;all&amp;quot;, indicators, extra = TRUE,
start = 2000, end = 2019)
&lt;/code>&lt;/pre>
&lt;p>Then we clean the data by removing non-country countries and renaming some of the columns.&lt;/p>
&lt;pre>&lt;code class="language-r">wdi_clean &amp;lt;- wdi_parl_raw %&amp;gt;%
filter(region != &amp;quot;Aggregates&amp;quot;) %&amp;gt;%
select(iso2c, iso3c, country, year,
population = SP.POP.TOTL,
prop_women_parl = SG.GEN.PARL.ZS,
gdp_per_cap = NY.GDP.PCAP.KD,
region, income)
&lt;/code>&lt;/pre>
&lt;h3 id="creating-a-basic-interactive-chart">Creating a basic interactive chart&lt;/h3>
&lt;p>Letâ€™s make a chart that shows the distribution of the proportion of women in national parliaments in 2019, by continent. Weâ€™ll use a strip plot with jittered points.&lt;/p>
&lt;p>First we need to make a regular static plot with ggplot:&lt;/p>
&lt;pre>&lt;code class="language-r">wdi_2019 &amp;lt;- wdi_clean %&amp;gt;%
filter(year == 2019) %&amp;gt;%
drop_na(prop_women_parl) %&amp;gt;%
# Scale this down from 0-100 to 0-1 so that scales::percent() can format it as
# an actual percent
mutate(prop_women_parl = prop_women_parl / 100)
static_plot &amp;lt;- ggplot(wdi_2019,
aes(y = fct_rev(region), x = prop_women_parl, color = region)) +
geom_point(position = position_jitter(width = 0, height = 0.15, seed = 1234)) +
guides(color = &amp;quot;none&amp;quot;) +
scale_x_continuous(labels = percent) +
# I used https://medialab.github.io/iwanthue/ to generate these colors
scale_color_manual(values = c(&amp;quot;#425300&amp;quot;, &amp;quot;#e680ff&amp;quot;, &amp;quot;#01bd71&amp;quot;, &amp;quot;#ff3aad&amp;quot;,
&amp;quot;#9f3e00&amp;quot;, &amp;quot;#0146bf&amp;quot;, &amp;quot;#671d56&amp;quot;)) +
labs(x = &amp;quot;% women in parliament&amp;quot;, y = NULL, caption = &amp;quot;Source: The World Bank&amp;quot;) +
theme_bw()
static_plot
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/10-example_files/figure-html/strip-plot-basic-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Great! That looks pretty good.&lt;/p>
&lt;p>To make it interactive, &lt;em>all we have to do&lt;/em> is feed the &lt;code>static_plot&lt;/code> object into &lt;code>ggplotly()&lt;/code>. Thatâ€™s it.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplotly(static_plot)
&lt;/code>&lt;/pre>
&lt;div id="htmlwidget-1" style="width:100%;height:400px;" class="widgetframe html-widget">&lt;/div>
&lt;script type="application/json" data-for="htmlwidget-1">{"x":{"url":"/example/10-example_files/figure-html//widgets/widget_strip-plot-basic-interactive-real.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}&lt;/script>
&lt;p>Not &lt;em>everything&lt;/em> translates over to JavaScriptâ€”the caption is gone now, and the legend is back (which is fine, I guess, since the legend is interactive). But still, this is magic.&lt;/p>
&lt;h3 id="modifying-the-tooltip">Modifying the tooltip&lt;/h3>
&lt;p>Right now, the default tooltip you see when you hover over the points includes the actual proportion of women in parliament for each point, along with the continent, which is neat, but itâ€™d be great if we could see the country name too. The tooltip picks up the information to include from the variables we use in &lt;code>aes()&lt;/code>, and we never map the &lt;code>country&lt;/code> column to any aesthetic, so it doesnâ€™t show up.&lt;/p>
&lt;p>To get around this, we can add a new aesthetic for country to the points. Instead of using one of the real ggplot aesthetics like &lt;code>color&lt;/code> or &lt;code>fill&lt;/code>, weâ€™ll use a fake one called &lt;code>text&lt;/code> (we can call it whatever we want! &lt;code>asdf&lt;/code> would also work). ggplot has no idea how to do anything with the &lt;code>text&lt;/code> aesthetic, and itâ€™ll give you a warning, but thatâ€™s okay. The static plot looks the same:&lt;/p>
&lt;pre>&lt;code class="language-r">static_plot_toolip &amp;lt;- ggplot(wdi_2019,
aes(y = fct_rev(region), x = prop_women_parl, color = region)) +
geom_point(aes(text = country),
position = position_jitter(width = 0, height = 0.15, seed = 1234)) +
guides(color = &amp;quot;none&amp;quot;) +
scale_x_continuous(labels = percent) +
# I used https://medialab.github.io/iwanthue/ to generate these colors
scale_color_manual(values = c(&amp;quot;#425300&amp;quot;, &amp;quot;#e680ff&amp;quot;, &amp;quot;#01bd71&amp;quot;, &amp;quot;#ff3aad&amp;quot;,
&amp;quot;#9f3e00&amp;quot;, &amp;quot;#0146bf&amp;quot;, &amp;quot;#671d56&amp;quot;)) +
labs(x = &amp;quot;% women in parliament&amp;quot;, y = NULL, caption = &amp;quot;Source: The World Bank&amp;quot;) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Warning: Ignoring unknown aesthetics: text
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">static_plot_toolip
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/10-example_files/figure-html/strip-plot-text-aes-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Now we can tell plotly to use this fake &lt;code>text&lt;/code> aesthetic for the tooltip:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplotly(static_plot_toolip, tooltip = &amp;quot;text&amp;quot;)
&lt;/code>&lt;/pre>
&lt;div id="htmlwidget-2" style="width:100%;height:400px;" class="widgetframe html-widget">&lt;/div>
&lt;script type="application/json" data-for="htmlwidget-2">{"x":{"url":"/example/10-example_files/figure-html//widgets/widget_strip-plot-text-interactive-real.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}&lt;/script>
&lt;p>Now we should just see the country names in the tooltips!&lt;/p>
&lt;h3 id="including-more-information-in-the-tooltip">Including more information in the tooltip&lt;/h3>
&lt;p>We have country names, but we lost the values in the x-axis. Rwanda has the highest proportion of women in parliament, but whatâ€™s the exact number? Itâ€™s somewhere above 60%, but thatâ€™s all we can see now.&lt;/p>
&lt;p>To fix this, we can make a new column in the data with all the text we want to include in the tooltip. Weâ€™ll use &lt;code>paste0()&lt;/code> to combine text and variable values to make the tooltip follow this format:&lt;/p>
&lt;pre>&lt;code class="language-text">Name of country
X% women in parliament
&lt;/code>&lt;/pre>
&lt;p>Letâ€™s add a new column with &lt;code>mutate()&lt;/code>. A couple things to note here:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>The &lt;code>&amp;lt;br&amp;gt;&lt;/code> is HTML code for a line break&lt;/p>
&lt;/li>
&lt;li>
&lt;p>We use the &lt;code>percent()&lt;/code> function to format numbers as percents. The &lt;code>accuracy&lt;/code> argument tells R how many decimal points to use. If we used &lt;code>1&lt;/code>, it would say 12%; if we used &lt;code>0.01&lt;/code>, it would say 12.08%; etc.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">wdi_2019 &amp;lt;- wdi_clean %&amp;gt;%
filter(year == 2019) %&amp;gt;%
drop_na(prop_women_parl) %&amp;gt;%
# Scale this down from 0-100 to 0-1 so that scales::percent() can format it as
# an actual percent
mutate(prop_women_parl = prop_women_parl / 100) %&amp;gt;%
mutate(fancy_label = paste0(country, &amp;quot;&amp;lt;br&amp;gt;&amp;quot;,
percent(prop_women_parl, accuracy = 0.1),
&amp;quot; women in parliament&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>Letâ€™s check to see if it worked:&lt;/p>
&lt;pre>&lt;code class="language-r">wdi_2019 %&amp;gt;% select(country, prop_women_parl, fancy_label) %&amp;gt;% head()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 3
## country prop_women_parl fancy_label
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt;
## 1 Andorra 0.5 Andorra&amp;lt;br&amp;gt;50.0% women in parliament
## 2 United Arab Emirates 0.225 United Arab Emirates&amp;lt;br&amp;gt;22.5% women in parliament
## 3 Afghanistan 0.279 Afghanistan&amp;lt;br&amp;gt;27.9% women in parliament
## 4 Antigua and Barbuda 0.111 Antigua and Barbuda&amp;lt;br&amp;gt;11.1% women in parliament
## 5 Albania 0.295 Albania&amp;lt;br&amp;gt;29.5% women in parliament
## 6 Armenia 0.242 Armenia&amp;lt;br&amp;gt;24.2% women in parliament
&lt;/code>&lt;/pre>
&lt;p>Now instead of using &lt;code>text = country&lt;/code> weâ€™ll use &lt;code>text = fancy_label&lt;/code> to map that new column onto the plot. Again, this wonâ€™t be visible in the static plot (and youâ€™ll get a warning), but it will show up in the interactive plot.&lt;/p>
&lt;pre>&lt;code class="language-r">static_plot_toolip_fancy &amp;lt;- ggplot(wdi_2019,
aes(y = fct_rev(region),
x = prop_women_parl,
color = region)) +
geom_point(aes(text = fancy_label),
position = position_jitter(width = 0, height = 0.15, seed = 1234)) +
guides(color = &amp;quot;none&amp;quot;) +
scale_x_continuous(labels = percent) +
# I used https://medialab.github.io/iwanthue/ to generate these colors
scale_color_manual(values = c(&amp;quot;#425300&amp;quot;, &amp;quot;#e680ff&amp;quot;, &amp;quot;#01bd71&amp;quot;, &amp;quot;#ff3aad&amp;quot;,
&amp;quot;#9f3e00&amp;quot;, &amp;quot;#0146bf&amp;quot;, &amp;quot;#671d56&amp;quot;)) +
labs(x = &amp;quot;% women in parliament&amp;quot;, y = NULL, caption = &amp;quot;Source: The World Bank&amp;quot;) +
theme_bw()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## Warning: Ignoring unknown aesthetics: text
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">ggplotly(static_plot_toolip_fancy, tooltip = &amp;quot;text&amp;quot;)
&lt;/code>&lt;/pre>
&lt;div id="htmlwidget-3" style="width:100%;height:400px;" class="widgetframe html-widget">&lt;/div>
&lt;script type="application/json" data-for="htmlwidget-3">{"x":{"url":"/example/10-example_files/figure-html//widgets/widget_strip-plot-text-interactive-fancy-real.html","options":{"xdomain":"*","allowfullscreen":false,"lazyload":false}},"evals":[],"jsHooks":[]}&lt;/script>
&lt;p>Perfect!&lt;/p>
&lt;p>Finally, if we want to save this plot as a standalone self-contained HTML file, we can use the &lt;code>saveWidget()&lt;/code> function from the &lt;strong>htmlwidgets&lt;/strong> package.&lt;/p>
&lt;pre>&lt;code class="language-r"># This is like ggsave, but for interactive HTML plots
interactive_plot &amp;lt;- static_plot_toolip_fancy
htmlwidgets::saveWidget(interactive_plot, &amp;quot;fancy_plot.html&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h3 id="making-a-dashboard-with-flexdashboard">Making a dashboard with &lt;strong>flexdashboard&lt;/strong>&lt;/h3>
&lt;p>The &lt;a href="https://rmarkdown.rstudio.com/flexdashboard/" target="_blank" rel="noopener">documentation for &lt;strong>flexdashboard&lt;/strong> is so great and complete&lt;/a> that Iâ€™m not going to include a full example here. There is also a brief overview in &lt;a href="https://bookdown.org/yihui/rmarkdown/dashboards.html" target="_blank" rel="noopener">chapter 5 of the official R Markdown book&lt;/a>. You can also watch &lt;a href="https://www.youtube.com/watch?v=_oDfBVr9wmQ" target="_blank" rel="noopener">this really quick video here&lt;/a>. She uses a package called &lt;strong>dimple&lt;/strong> instead of &lt;strong>plotly&lt;/strong>, which doesnâ€™t work with ggplot like &lt;code>ggplotly()&lt;/code>, so &lt;em>ignore her code&lt;/em> about &lt;code>dimple()&lt;/code> and use your &lt;code>ggplotly()&lt;/code> skills instead. You can search YouTube for a bunch of other short tutorial videos, too.&lt;/p>
&lt;p>The quickest and easiest way to get started is to install the &lt;strong>flexdashboard&lt;/strong> package and then in RStudio go to File &amp;gt; New Fileâ€¦ &amp;gt; R Markdownâ€¦ &amp;gt; From Template &amp;gt; Flexdashboard:&lt;/p>
&lt;img src="https://aem2850.toddgerarden.com/img/examples/flexdashboard-template.png" width="60%" style="display: block; margin: auto;" />
&lt;p>That will give you an empty dashboard with three chart areas spread across two columns. Put static or dynamic graphs in the different chart areas, knit, and youâ€™ll be good to go!&lt;/p>
&lt;p>If youâ€™re interested in making the dashboard reactive with Shiny-like elements, &lt;a href="https://www.andrewheiss.com/blog/2020/01/01/flexdashboard-dynamic-data/" target="_blank" rel="noopener">check out this tutorial&lt;/a>.&lt;/p></description></item><item><title>Annotations</title><link>https://aem2850.toddgerarden.com/example/09-example/</link><pubDate>Mon, 05 Jul 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/09-example/</guid><description>&lt;p>For this example, we&amp;rsquo;re again going to use cross-national data from the &lt;a href="https://data.worldbank.org/" target="_blank" rel="noopener">World Bank&amp;rsquo;s Open Data portal&lt;/a>. We&amp;rsquo;ll download the data with the &lt;a href="https://cran.r-project.org/web/packages/WDI/index.html" target="_blank" rel="noopener">&lt;strong>WDI&lt;/strong> package&lt;/a>.&lt;/p>
&lt;p>If you want to skip the data downloading, you can download the data below (you&amp;rsquo;ll likely need to right click and choose &amp;ldquo;Save Link Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/wdi_co2.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>wdi_co2.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/gMSMsOy7KF0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a slightly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="load-data">Load data&lt;/h3>
&lt;p>First, we load the libraries we&amp;rsquo;ll be using:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse) # For ggplot, dplyr, and friends
library(WDI) # Get data from the World Bank
library(ggrepel) # For non-overlapping labels
# You need to install ggtext from GitHub. Follow the instructions at
# https://github.com/wilkelab/ggtext
library(ggtext) # For fancier text handling
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">indicators &amp;lt;- c(&amp;quot;SP.POP.TOTL&amp;quot;, # Population
&amp;quot;EN.ATM.CO2E.PC&amp;quot;, # CO2 emissions
&amp;quot;NY.GDP.PCAP.KD&amp;quot;) # GDP per capita
wdi_co2_raw &amp;lt;- WDI(country = &amp;quot;all&amp;quot;, indicators, extra = TRUE,
start = 1995, end = 2015)
&lt;/code>&lt;/pre>
&lt;p>Then we clean the data by removing non-country countries and renaming some of the columns.&lt;/p>
&lt;pre>&lt;code class="language-r">wdi_clean &amp;lt;- wdi_co2_raw %&amp;gt;%
filter(region != &amp;quot;Aggregates&amp;quot;) %&amp;gt;%
select(iso2c, iso3c, country, year,
population = SP.POP.TOTL,
co2_emissions = EN.ATM.CO2E.PC,
gdp_per_cap = NY.GDP.PCAP.KD,
region, income)
&lt;/code>&lt;/pre>
&lt;h3 id="clean-and-reshape-data">Clean and reshape data&lt;/h3>
&lt;p>Next we&amp;rsquo;ll do some substantial filtering and reshaping so that we can end up with the rankings of CO~2~ emissions in 1995 and 2014. I annotate as much as possible below so you can see what&amp;rsquo;s happening in each step.&lt;/p>
&lt;pre>&lt;code class="language-r">co2_rankings &amp;lt;- wdi_clean %&amp;gt;%
# Get rid of smaller countries
filter(population &amp;gt; 200000) %&amp;gt;%
# Only look at two years
filter(year %in% c(1995, 2014)) %&amp;gt;%
# Get rid of all the rows that have missing values in co2_emissions
drop_na(co2_emissions) %&amp;gt;%
# Look at each year individually and rank countries based on their emissions that year
group_by(year) %&amp;gt;%
mutate(ranking = rank(co2_emissions)) %&amp;gt;%
ungroup() %&amp;gt;%
# Only select a handful of columns, mostly just the newly created &amp;quot;ranking&amp;quot;
# column and some country identifiers
select(iso3c, country, year, region, income, ranking) %&amp;gt;%
# Right now the data is tidy and long, but we want to widen it and create
# separate columns for emissions in 1995 and in 2014. pivot_wider() will make
# new columns based on the existing &amp;quot;year&amp;quot; column (that's what `names_from`
# does), and it will add &amp;quot;rank_&amp;quot; as the prefix, so that the new columns will
# be &amp;quot;rank_1995&amp;quot; and &amp;quot;rank_2014&amp;quot;. The values that go in those new columns will
# come from the existing &amp;quot;ranking&amp;quot; column
pivot_wider(names_from = year, names_prefix = &amp;quot;rank_&amp;quot;, values_from = ranking) %&amp;gt;%
# Find the difference in ranking between 2014 and 1995
mutate(rank_diff = rank_2014 - rank_1995) %&amp;gt;%
# Remove all rows where there's a missing value in the rank_diff column
drop_na(rank_diff) %&amp;gt;%
# Make an indicator variable that is true of the absolute value of the
# difference in rankings is greater than 25. 25 is arbitrary hereâ€”that just
# felt like a big change in rankings
mutate(big_change = ifelse(abs(rank_diff) &amp;gt;= 25, TRUE, FALSE)) %&amp;gt;%
# Make another indicator variable that indicates if the rank improved by a
# lot, worsened by a lot, or didn't change much. We use the case_when()
# function, which is like a fancy version of ifelse() that takes multiple
# conditions. This is how it generally works:
#
# case_when(
# some_test ~ value_if_true,
# some_other_test ~ value_if_true,
# TRUE ~ value_otherwise
#)
mutate(better_big_change = case_when(
rank_diff &amp;lt;= -25 ~ &amp;quot;Rank improved&amp;quot;,
rank_diff &amp;gt;= 25 ~ &amp;quot;Rank worsened&amp;quot;,
TRUE ~ &amp;quot;Rank changed a little&amp;quot;
))
&lt;/code>&lt;/pre>
&lt;p>Here&amp;rsquo;s what that reshaped data looked like before:&lt;/p>
&lt;pre>&lt;code class="language-r">head(wdi_clean)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 9
## iso2c iso3c country year population co2_emissions gdp_per_cap region income
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 AD AND Andorra 2015 78011 NA 41768. Europe &amp;amp; Central Asia High income
## 2 AD AND Andorra 2004 76244 7.36 47033. Europe &amp;amp; Central Asia High income
## 3 AD AND Andorra 2001 67341 7.79 41421. Europe &amp;amp; Central Asia High income
## 4 AD AND Andorra 2002 70049 7.59 42396. Europe &amp;amp; Central Asia High income
## 5 AD AND Andorra 2014 79213 5.83 40790. Europe &amp;amp; Central Asia High income
## 6 AD AND Andorra 1995 63850 6.66 32918. Europe &amp;amp; Central Asia High income
&lt;/code>&lt;/pre>
&lt;p>And here&amp;rsquo;s what it looks like now:&lt;/p>
&lt;pre>&lt;code class="language-r">head(co2_rankings)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 9
## iso3c country region income rank_1995 rank_2014 rank_diff big_change better_big_change
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt;
## 1 ARE United Arab Emirates Middle East &amp;amp; North Africa High income 167 171 4 FALSE Rank changed a little
## 2 AFG Afghanistan South Asia Low income 8 24 16 FALSE Rank changed a little
## 3 ALB Albania Europe &amp;amp; Central Asia Upper middle income 54 78 24 FALSE Rank changed a little
## 4 ARM Armenia Europe &amp;amp; Central Asia Upper middle income 71 76 5 FALSE Rank changed a little
## 5 AGO Angola Sub-Saharan Africa Lower middle income 59 61 2 FALSE Rank changed a little
## 6 ARG Argentina Latin America &amp;amp; Caribbean High income 103 119 16 FALSE Rank changed a little
&lt;/code>&lt;/pre>
&lt;h3 id="plot-the-data-and-annotate">Plot the data and annotate&lt;/h3>
&lt;p>I use IBM Plex Sans in this plot. You can &lt;a href="https://fonts.google.com/specimen/IBM&amp;#43;Plex&amp;#43;Sans" target="_blank" rel="noopener">download it from Google Fonts&lt;/a>.&lt;/p>
&lt;pre>&lt;code class="language-r"># These three functions make it so all geoms that use text, label, and
# label_repel will use IBM Plex Sans as the font. Those layers are *not*
# influenced by whatever you include in the base_family argument in something
# like theme_bw(), so ordinarily you'd need to specify the font in each
# individual annotate(geom = &amp;quot;text&amp;quot;) layer or geom_label() layer, and that's
# tedious! This removes that tediousness.
update_geom_defaults(&amp;quot;text&amp;quot;, list(family = &amp;quot;IBM Plex Sans&amp;quot;))
update_geom_defaults(&amp;quot;label&amp;quot;, list(family = &amp;quot;IBM Plex Sans&amp;quot;))
update_geom_defaults(&amp;quot;label_repel&amp;quot;, list(family = &amp;quot;IBM Plex Sans&amp;quot;))
ggplot(co2_rankings,
aes(x = rank_1995, y = rank_2014)) +
# Add a reference line that goes from the bottom corner to the top corner
annotate(geom = &amp;quot;segment&amp;quot;, x = 0, xend = 175, y = 0, yend = 175) +
# Add points and color them by the type of change in rankings
geom_point(aes(color = better_big_change)) +
# Add repelled labels. Only use data where big_change is TRUE. Fill them by
# the type of change (so they match the color in geom_point() above) and use
# white text
geom_label_repel(data = filter(co2_rankings, big_change == TRUE),
aes(label = country, fill = better_big_change),
color = &amp;quot;white&amp;quot;) +
# Add notes about what the outliers mean in the bottom left and top right
# corners. These are italicized and light grey. The text in the bottom corner
# is justified to the right with hjust = 1, and the text in the top corner is
# justified to the left with hjust = 0
annotate(geom = &amp;quot;text&amp;quot;, x = 170, y = 6, label = &amp;quot;Outliers improving&amp;quot;,
fontface = &amp;quot;italic&amp;quot;, hjust = 1, color = &amp;quot;grey50&amp;quot;) +
annotate(geom = &amp;quot;text&amp;quot;, x = 2, y = 170, label = &amp;quot;Outliers worsening&amp;quot;,
fontface = &amp;quot;italic&amp;quot;, hjust = 0, color = &amp;quot;grey50&amp;quot;) +
# Add mostly transparent rectangles in the bottom right and top left corners
annotate(geom = &amp;quot;rect&amp;quot;, xmin = 0, xmax = 25, ymin = 0, ymax = 25,
fill = &amp;quot;#2ECC40&amp;quot;, alpha = 0.25) +
annotate(geom = &amp;quot;rect&amp;quot;, xmin = 150, xmax = 175, ymin = 150, ymax = 175,
fill = &amp;quot;#FF851B&amp;quot;, alpha = 0.25) +
# Add text to define what the rectangles abovee actually mean. The \n in
# &amp;quot;highest\nemitters&amp;quot; will put a line break in the label
annotate(geom = &amp;quot;text&amp;quot;, x = 40, y = 6, label = &amp;quot;Lowest emitters&amp;quot;,
hjust = 0, color = &amp;quot;#2ECC40&amp;quot;) +
annotate(geom = &amp;quot;text&amp;quot;, x = 162.5, y = 135, label = &amp;quot;Highest\nemitters&amp;quot;,
hjust = 0.5, vjust = 1, lineheight = 1, color = &amp;quot;#FF851B&amp;quot;) +
# Add arrows between the text and the rectangles. These use the segment geom,
# and the arrows are added with the arrow() function, which lets us define the
# angle of the arrowhead and the length of the arrowhead pieces. Here we use
# 0.5 lines, which is a unit of measurement that ggplot uses internally (think
# of how many lines of text fit in the plot). We could also use unit(1, &amp;quot;cm&amp;quot;)
# or unit(0.25, &amp;quot;in&amp;quot;) or anything else
annotate(geom = &amp;quot;segment&amp;quot;, x = 38, xend = 20, y = 6, yend = 6, color = &amp;quot;#2ECC40&amp;quot;,
arrow = arrow(angle = 15, length = unit(0.5, &amp;quot;lines&amp;quot;))) +
annotate(geom = &amp;quot;segment&amp;quot;, x = 162.5, xend = 162.5, y = 140, yend = 155, color = &amp;quot;#FF851B&amp;quot;,
arrow = arrow(angle = 15, length = unit(0.5, &amp;quot;lines&amp;quot;))) +
# Use three different colors for the points
scale_color_manual(values = c(&amp;quot;grey50&amp;quot;, &amp;quot;#0074D9&amp;quot;, &amp;quot;#FF4136&amp;quot;)) +
# Use two different colors for the filled labels. There are no grey labels, so
# we don't have to specify that color
scale_fill_manual(values = c(&amp;quot;#0074D9&amp;quot;, &amp;quot;#FF4136&amp;quot;)) +
# Make the x and y axes expand all the way to the edges of the plot area and
# add breaks every 25 units from 0 to 175
scale_x_continuous(expand = c(0, 0), breaks = seq(0, 175, 25)) +
scale_y_continuous(expand = c(0, 0), breaks = seq(0, 175, 25)) +
# Add labels! There are a couple fancy things here.
# 1. In the title we wrap the 2 of CO2 in the HTML &amp;lt;sub&amp;gt;&amp;lt;/sub&amp;gt; tag so that the
# number gets subscripted. The only way this will actually get parsed as
# HTML is if we tell the plot.title to use element_markdown() in the
# theme() function, and element_markdown() comes from the ggtext package.
# 2. In the subtitle we bold the two words **improved** and **worsened** using
# Markdown asterisks. We also wrap these words with HTML span tags with
# inline CSS to specify the color of the text. Like the title, this will
# only be processed and parsed as HTML and Markdown if we tell the p
# lot.subtitle to use element_markdown() in the theme() function.
labs(x = &amp;quot;Rank in 1995&amp;quot;, y = &amp;quot;Rank in 2014&amp;quot;,
title = &amp;quot;Changes in CO&amp;lt;sub&amp;gt;2&amp;lt;/sub&amp;gt; emission rankings between 1995 and 2014&amp;quot;,
subtitle = &amp;quot;Countries that &amp;lt;span style='color: #0074D9'&amp;gt;**improved**&amp;lt;/span&amp;gt; or &amp;lt;span style='color: #FF4136'&amp;gt;**worsened**&amp;lt;/span&amp;gt; more than 25 positions in the rankings highlighted&amp;quot;,
caption = &amp;quot;Source: The World Bank.\nCountries with populations of less than 200,000 excluded.&amp;quot;) +
# Turn off the legends for color and fill, since the subtitle includes that
guides(color = &amp;quot;none&amp;quot;, fill = &amp;quot;none&amp;quot;) +
# Use theme_bw() with IBM Plex Sans
theme_bw(base_family = &amp;quot;IBM Plex Sans&amp;quot;) +
# Tell the title and subtitle to be treated as Markdown/HTML, make the title
# 1.6x the size of the base font, and make the subtitle 1.3x the size of the
# base font. Also add a little larger margin on the right of the plot so that
# the 175 doesn't get cut off.
theme(plot.title = element_markdown(face = &amp;quot;bold&amp;quot;, size = rel(1.6)),
plot.subtitle = element_markdown(size = rel(1.3)),
plot.margin = unit(c(0.5, 1, 0.5, 0.5), units = &amp;quot;lines&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/09-example_files/figure-html/build-pretty-plot-1.png" width="960" style="display: block; margin: auto;" /></description></item><item><title>Relationships</title><link>https://aem2850.toddgerarden.com/example/07-example/</link><pubDate>Mon, 28 Jun 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/07-example/</guid><description>&lt;p>For this example, we&amp;rsquo;re again going to use historical weather data from &lt;a href="https://darksky.net/forecast/33.7546,-84.39/us12/en" target="_blank" rel="noopener">Dark Sky&lt;/a> about wind speed and temperature trends for downtown Atlanta (&lt;a href="https://www.google.com/maps/place/33%c2%b045%2716.4%22N&amp;#43;84%c2%b023%2724.0%22W/@33.754557,-84.3921977,17z/" target="_blank" rel="noopener">specifically &lt;code>33.754557, -84.390009&lt;/code>&lt;/a>) in 2019. I downloaded this data using Dark Sky&amp;rsquo;s (about-to-be-retired-because-they-were-bought-by-Apple) API using the &lt;a href="https://github.com/hrbrmstr/darksky" target="_blank" rel="noopener"> &lt;strong>darksky&lt;/strong> package&lt;/a>.&lt;/p>
&lt;p>If you want to follow along with this example, you can download the data below (you&amp;rsquo;ll likely need to right click and choose &amp;ldquo;Save Link Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/atl-weather-2019.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>atl-weather-2019.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/zfEAmJzfbkE" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a slightly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="load-and-clean-data">Load and clean data&lt;/h3>
&lt;p>First, we load the libraries we&amp;rsquo;ll be using:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse) # For ggplot, dplyr, and friends
library(patchwork) # For combining ggplot plots
library(GGally) # For scatterplot matrices
library(broom) # For converting model objects to data frames
&lt;/code>&lt;/pre>
&lt;p>Then we load the data with &lt;code>read_csv()&lt;/code>. Here I assume that the CSV file lives in a subfolder in my project named &lt;code>data&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">weather_atl &amp;lt;- read_csv(&amp;quot;data/atl-weather-2019.csv&amp;quot;)
&lt;/code>&lt;/pre>
&lt;h3 id="legal-dual-y-axes">Legal dual y-axes&lt;/h3>
&lt;p>It is fine (and often helpful!) to use two y-axes if the two different scales measure the same thing, like counts and percentages, Fahrenheit and Celsius, pounds and kilograms, inches and centimeters, etc.&lt;/p>
&lt;p>To do this, you need to add an argument (&lt;code>sec.axis&lt;/code>) to &lt;code>scale_y_continuous()&lt;/code> to tell it to use a second axis. This &lt;code>sec.axis&lt;/code> argument takes a &lt;code>sec_axis()&lt;/code> function that tells ggplot how to transform the scale. You need to specify a formula or function that defines how the original axis gets transformed. This formula uses a special syntax. It needs to start with a &lt;code>~&lt;/code>, which indicates that it&amp;rsquo;s a function, and it needs to use &lt;code>.&lt;/code> to stand in for the original value in the original axis.&lt;/p>
&lt;p>Since the equation for converting Fahrenheit to Celsius is thisâ€¦&lt;/p>
&lt;p>$$
\text{C} = (32 - \text{F}) \times -\frac{5}{9}
$$&lt;/p>
&lt;p>â€¦we can specify this with code like so (where &lt;code>.&lt;/code> stands for the Fahrenheit value):&lt;/p>
&lt;pre>&lt;code class="language-text">~ (32 - .) * -5 / 9
&lt;/code>&lt;/pre>
&lt;p>Here&amp;rsquo;s a plot of daily high temperatures in Atlanta throughout 2019, with a second axis:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = time, y = temperatureHigh)) +
geom_line() +
scale_y_continuous(sec.axis = sec_axis(trans = ~ (32 - .) * -5/9,
name = &amp;quot;Celsius&amp;quot;)) +
labs(x = NULL, y = &amp;quot;Fahrenheit&amp;quot;) +
theme_minimal()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/atl-weather-dual-axes-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>For fun, we could also convert it to Kelvin, which uses this formula:&lt;/p>
&lt;p>$$
\text{K} = (\text{F} - 32) \times \frac{5}{9} + 273.15
$$&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = time, y = temperatureHigh)) +
geom_line() +
scale_y_continuous(sec.axis = sec_axis(trans = ~ (. - 32) * 5/9 + 273.15,
name = &amp;quot;Kelvin&amp;quot;)) +
labs(x = NULL, y = &amp;quot;Fahrenheit&amp;quot;) +
theme_minimal()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/atl-weather-dual-axes-kelvin-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="combining-plots">Combining plots&lt;/h3>
&lt;p>A good alternative to using two y-axes is to use two plots instead. The &lt;a href="https://github.com/thomasp85/patchwork" target="_blank" rel="noopener">&lt;strong>patchwork&lt;/strong> package&lt;/a> makes this &lt;em>really&lt;/em> easy to do with R. There are other similar packages that do this, like &lt;strong>cowplot&lt;/strong> and &lt;strong>gridExtra&lt;/strong>, but I&amp;rsquo;ve found that &lt;strong>patchwork&lt;/strong> is the easiest to use &lt;em>and&lt;/em> it actually aligns the different plot elements like axis lines and legends (yay alignment in CRAP!). The &lt;a href="https://patchwork.data-imaginist.com/articles/guides/assembly.html" target="_blank" rel="noopener">documentation for &lt;strong>patchwork&lt;/strong>&lt;/a> is really great and full of examplesâ€”you should check it out to see all the things you can do with it!&lt;/p>
&lt;p>To use &lt;strong>patchwork&lt;/strong>, we need to (1) save our plots as objects and (2) add them together with &lt;code>+&lt;/code>.&lt;/p>
&lt;p>For instance, is there a relationship between temperature and humidity in Atlanta? We can plot both:&lt;/p>
&lt;pre>&lt;code class="language-r"># Temperature in Atlanta
temp_plot &amp;lt;- ggplot(weather_atl, aes(x = time, y = temperatureHigh)) +
geom_line() +
geom_smooth() +
scale_y_continuous(sec.axis = sec_axis(trans = ~ (32 - .) * -5/9,
name = &amp;quot;Celsius&amp;quot;)) +
labs(x = NULL, y = &amp;quot;Fahrenheit&amp;quot;) +
theme_minimal()
temp_plot
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/create-temp-humid-plots-1.png" width="576" style="display: block; margin: auto;" />
&lt;pre>&lt;code class="language-r"># Humidity in Atlanta
humidity_plot &amp;lt;- ggplot(weather_atl, aes(x = time, y = humidity)) +
geom_line() +
geom_smooth() +
labs(x = NULL, y = &amp;quot;Humidity&amp;quot;) +
theme_minimal()
humidity_plot
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/create-temp-humid-plots-2.png" width="576" style="display: block; margin: auto;" />
&lt;p>Right now, these are two separate plots, but we can combine them with &lt;code>+&lt;/code> if we load &lt;strong>patchwork&lt;/strong>:&lt;/p>
&lt;pre>&lt;code class="language-r">library(patchwork)
temp_plot + humidity_plot
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/patchwork-first-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>By default, &lt;strong>patchwork&lt;/strong> will put these side-by-side, but we can change that with the &lt;code>plot_layout()&lt;/code> function:&lt;/p>
&lt;pre>&lt;code class="language-r">temp_plot + humidity_plot +
plot_layout(ncol = 1)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/patchwork-vertical-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can also play with other arguments in &lt;code>plot_layout()&lt;/code>. If we want to make the temperature plot taller and shrink the humidity section, we can specify the proportions for the plot heights. Here, the temperature plot is 70% of the height and the humidity plot is 30%:&lt;/p>
&lt;pre>&lt;code class="language-r">temp_plot + humidity_plot +
plot_layout(ncol = 1, heights = c(0.7, 0.3))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/patchwork-vertical-resized-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="scatterplot-matrices">Scatterplot matrices&lt;/h3>
&lt;p>We can visualize the correlations between pairs of variables with the &lt;code>ggpairs()&lt;/code> function in the &lt;strong>GGally&lt;/strong> package. For instance, how correlated are high and low temperatures, humidity, wind speed, and the chance of precipitation? We first make a smaller dataset with just those columns, and then we feed that dataset into &lt;code>ggpairs()&lt;/code> to see all the correlation information:&lt;/p>
&lt;pre>&lt;code class="language-r">library(GGally)
weather_correlations &amp;lt;- weather_atl %&amp;gt;%
select(temperatureHigh, temperatureLow, humidity, windSpeed, precipProbability)
ggpairs(weather_correlations)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/ggpairs-1.png" width="864" style="display: block; margin: auto;" />
&lt;p>It looks like high and low temperatures are extremely highly positively correlated (r = 0.92). Wind spped and temperature are moderately negatively correlated, with low temperatures having a stronger negative correlation (r = -0.45). There&amp;rsquo;s no correlation whatsoever between low temperatures and the precipitation probability (r = -0.03) or humidity and high temperatures (r = -0.03).&lt;/p>
&lt;p>Even though &lt;code>ggpairs()&lt;/code> doesn&amp;rsquo;t use the standard &lt;code>ggplot(...) + geom_whatever()&lt;/code> syntax we&amp;rsquo;re familiar with, it does behind the scenes, so you can add regular ggplot layers to it:&lt;/p>
&lt;pre>&lt;code class="language-r">ggpairs(weather_correlations) +
labs(title = &amp;quot;Correlations!&amp;quot;) +
theme_dark()
&lt;/code>&lt;/pre>
&lt;h3 id="correlograms">Correlograms&lt;/h3>
&lt;p>Scatterplot matrices typically include way too much information to be used in actual publications. I use them when doing my own analysis just to see how different variables are related, but I rarely polish them up for public consumption. In the readings for today, Claus Wilke showed a type of plot called a &lt;a href="https://clauswilke.com/dataviz/visualizing-associations.html#associations-correlograms" target="_blank" rel="noopener">&lt;em>correlogram&lt;/em>&lt;/a> which &lt;em>is&lt;/em> more appropriate for publication.&lt;/p>
&lt;p>These are essentially heatmaps of the different correlation coefficients. To make these with ggplot, we need to do a little bit of extra data processing, mostly to reshape data into a long, tidy format that we can plot. Here&amp;rsquo;s how.&lt;/p>
&lt;p>First we need to build a correlation matrix of the main variables we care about. Ordinarily the &lt;code>cor()&lt;/code> function in R takes two argumentsâ€”x and yâ€”and it will return a single correlation value. If you feed a data frame into &lt;code>cor()&lt;/code> though, it&amp;rsquo;ll calculate the correlation between each pair of columns&lt;/p>
&lt;pre>&lt;code class="language-r"># Create a correlation matrix
things_to_correlate &amp;lt;- weather_atl %&amp;gt;%
select(temperatureHigh, temperatureLow, humidity, windSpeed, precipProbability) %&amp;gt;%
cor()
things_to_correlate
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## temperatureHigh temperatureLow humidity windSpeed precipProbability
## temperatureHigh 1.00 0.920 -0.030 -0.377 -0.124
## temperatureLow 0.92 1.000 0.112 -0.450 -0.026
## humidity -0.03 0.112 1.000 0.011 0.722
## windSpeed -0.38 -0.450 0.011 1.000 0.196
## precipProbability -0.12 -0.026 0.722 0.196 1.000
&lt;/code>&lt;/pre>
&lt;p>The two halves of this matrix (split along the diagonal line) are identical, so we can remove the lower triangle with this code (which will set all the cells in the lower triangle to &lt;code>NA&lt;/code>):&lt;/p>
&lt;pre>&lt;code class="language-r"># Get rid of the lower triangle
things_to_correlate[lower.tri(things_to_correlate)] &amp;lt;- NA
things_to_correlate
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## temperatureHigh temperatureLow humidity windSpeed precipProbability
## temperatureHigh 1 0.92 -0.03 -0.377 -0.124
## temperatureLow NA 1.00 0.11 -0.450 -0.026
## humidity NA NA 1.00 0.011 0.722
## windSpeed NA NA NA 1.000 0.196
## precipProbability NA NA NA NA 1.000
&lt;/code>&lt;/pre>
&lt;p>Finally, in order to plot this, the data needs to be in tidy (or long) format. Here we convert the &lt;code>things_to_correlate&lt;/code> matrix into a data frame, add a column for the row names, take all the columns and put them into a single column named &lt;code>measure1&lt;/code>, and take all the correlation numbers and put them in a column named &lt;code>cor&lt;/code> In the end, we make sure the measure variables are ordered by their order of appearance (otherwise they plot alphabetically and don&amp;rsquo;t make a triangle)&lt;/p>
&lt;pre>&lt;code class="language-r">things_to_correlate_long &amp;lt;- things_to_correlate %&amp;gt;%
# Convert from a matrix to a data frame
as.data.frame() %&amp;gt;%
# Matrixes have column names that don't get converted to columns when using
# as.data.frame(), so this adds those names as a column
rownames_to_column(&amp;quot;measure2&amp;quot;) %&amp;gt;%
# Make this long. Take all the columns except measure2 and put their names in
# a column named measure1 and their values in a column named cor
pivot_longer(cols = -measure2,
names_to = &amp;quot;measure1&amp;quot;,
values_to = &amp;quot;cor&amp;quot;) %&amp;gt;%
# Make a new column with the rounded version of the correlation value
mutate(nice_cor = round(cor, 2)) %&amp;gt;%
# Remove rows where the two measures are the same (like the correlation
# between humidity and humidity)
filter(measure2 != measure1) %&amp;gt;%
# Get rid of the empty triangle
filter(!is.na(cor)) %&amp;gt;%
# Put these categories in order
mutate(measure1 = fct_inorder(measure1),
measure2 = fct_inorder(measure2))
things_to_correlate_long
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 10 x 4
## measure2 measure1 cor nice_cor
## &amp;lt;fct&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 temperatureHigh temperatureLow 0.920 0.92
## 2 temperatureHigh humidity -0.0301 -0.03
## 3 temperatureHigh windSpeed -0.377 -0.38
## 4 temperatureHigh precipProbability -0.124 -0.12
## 5 temperatureLow humidity 0.112 0.11
## 6 temperatureLow windSpeed -0.450 -0.45
## 7 temperatureLow precipProbability -0.0255 -0.03
## 8 humidity windSpeed 0.0108 0.01
## 9 humidity precipProbability 0.722 0.72
## 10 windSpeed precipProbability 0.196 0.2
&lt;/code>&lt;/pre>
&lt;p>Phew. With the data all tidied like that, we can make a correlogram with a heatmap. This is just like &lt;a href="https://datavizm20.classes.andrewheiss.com/example/04-example/#heatmap" target="_blank" rel="noopener">the heatmap you made in session 4&lt;/a>, but here we manipulate the fill scale a little so that it&amp;rsquo;s diverging with three colors: a high value, a midpoint value, and a low value.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(things_to_correlate_long,
aes(x = measure2, y = measure1, fill = cor)) +
geom_tile() +
geom_text(aes(label = nice_cor)) +
scale_fill_gradient2(low = &amp;quot;#E16462&amp;quot;, mid = &amp;quot;white&amp;quot;, high = &amp;quot;#0D0887&amp;quot;,
limits = c(-1, 1)) +
labs(x = NULL, y = NULL) +
coord_equal() +
theme_minimal() +
theme(panel.grid = element_blank())
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/cor-heatmap-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>Instead of using a heatmap, we can also use points, which encode the correlation information both as color &lt;em>and&lt;/em> as size. To do that, we just need to switch &lt;code>geom_tile()&lt;/code> to &lt;code>geom_point()&lt;/code> and set the &lt;code>size = cor&lt;/code> mapping:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(things_to_correlate_long,
aes(x = measure2, y = measure1, color = cor)) +
# Size by the absolute value so that -0.7 and 0.7 are the same size
geom_point(aes(size = abs(cor))) +
scale_color_gradient2(low = &amp;quot;#E16462&amp;quot;, mid = &amp;quot;white&amp;quot;, high = &amp;quot;#0D0887&amp;quot;,
limits = c(-1, 1)) +
scale_size_area(max_size = 15, limits = c(-1, 1), guide = &amp;quot;none&amp;quot;) +
labs(x = NULL, y = NULL) +
coord_equal() +
theme_minimal() +
theme(panel.grid = element_blank())
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/cor-points-1.png" width="480" style="display: block; margin: auto;" />
&lt;h3 id="simple-regression">Simple regression&lt;/h3>
&lt;p>We can also visualize the relationships between variables using regression. Simple regression is easy to visualize, since you&amp;rsquo;re only working with an X and a Y. For instance, what&amp;rsquo;s the relationship between humidity and high temperatures during the summer?&lt;/p>
&lt;p>First, let&amp;rsquo;s filter the data to only look at the summer. We also add a column to scale up the humidity valueâ€”right now it&amp;rsquo;s on a scale of 0-1 (for percentages), but when interpreting regression we talk about increases in whole units, so we&amp;rsquo;d talk about moving from 0% humidity to 100% humidity, which isn&amp;rsquo;t helpful, so instead we multiply everything by 100 so we can talk about moving from 50% humidity to 51% humidity. We also scale up a couple other variables that we&amp;rsquo;ll use in the larger model later.&lt;/p>
&lt;pre>&lt;code class="language-r">weather_atl_summer &amp;lt;- weather_atl %&amp;gt;%
filter(time &amp;gt;= &amp;quot;2019-05-01&amp;quot;, time &amp;lt;= &amp;quot;2019-09-30&amp;quot;) %&amp;gt;%
mutate(humidity_scaled = humidity * 100,
moonPhase_scaled = moonPhase * 100,
precipProbability_scaled = precipProbability * 100,
cloudCover_scaled = cloudCover * 100)
&lt;/code>&lt;/pre>
&lt;p>Then we can build a simple regression model:&lt;/p>
&lt;pre>&lt;code class="language-r">model_simple &amp;lt;- lm(temperatureHigh ~ humidity_scaled,
data = weather_atl_summer)
tidy(model_simple, conf.int = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 2 x 7
## term estimate std.error statistic p.value conf.low conf.high
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) 104. 2.35 44.3 1.88e-88 99.5 109.
## 2 humidity_scaled -0.241 0.0358 -6.74 3.21e-10 -0.312 -0.170
&lt;/code>&lt;/pre>
&lt;p>We can interpret these coefficients like so:&lt;/p>
&lt;ul>
&lt;li>The intercept shows that the average temperature when there&amp;rsquo;s 0% humidity is 104Â°. There are no days with 0% humidity though, so we can ignore the interceptâ€”it&amp;rsquo;s really just here so that we can draw the line.&lt;/li>
&lt;li>The coefficient for &lt;code>humidity_scaled&lt;/code> shows that a one percent increase in humidity is associated with a 0.241Â° decrease in temperature, on average.&lt;/li>
&lt;/ul>
&lt;p>Visualizing this model is simple, since there are only two variables:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl_summer,
aes(x = humidity_scaled, y = temperatureHigh)) +
geom_point() +
geom_smooth(method = &amp;quot;lm&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## `geom_smooth()` using formula 'y ~ x'
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/plot-simple-model-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>And indeed, as humidity increases, temperatures decrease.&lt;/p>
&lt;h3 id="coefficient-plots">Coefficient plots&lt;/h3>
&lt;p>But if we use multiple variables in the model, it gets really hard to visualize the results since we&amp;rsquo;re working with multiple dimensions. Instead, we can use coefficient plots to see the individual coefficients in the model.&lt;/p>
&lt;p>First, let&amp;rsquo;s build a more complex model:&lt;/p>
&lt;pre>&lt;code class="language-r">model_complex &amp;lt;- lm(temperatureHigh ~ humidity_scaled + moonPhase_scaled +
precipProbability_scaled + windSpeed + pressure + cloudCover_scaled,
data = weather_atl_summer)
tidy(model_complex, conf.int = TRUE)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 7 x 7
## term estimate std.error statistic p.value conf.low conf.high
## &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 (Intercept) 262. 125. 2.09 0.0380 14.8 510.
## 2 humidity_scaled -0.111 0.0757 -1.47 0.143 -0.261 0.0381
## 3 moonPhase_scaled 0.0116 0.0126 0.917 0.360 -0.0134 0.0366
## 4 precipProbability_scaled 0.0356 0.0203 1.75 0.0820 -0.00458 0.0758
## 5 windSpeed -1.78 0.414 -4.29 0.0000326 -2.59 -0.958
## 6 pressure -0.157 0.122 -1.28 0.203 -0.398 0.0854
## 7 cloudCover_scaled -0.0952 0.0304 -3.14 0.00207 -0.155 -0.0352
&lt;/code>&lt;/pre>
&lt;p>We can interpret these coefficients like so:&lt;/p>
&lt;ul>
&lt;li>Holding everything else constant, a 1% increase in humidity is associated with a 0.11Â° decrease in the high temperature, on average, but the effect is not statistically significant&lt;/li>
&lt;li>Holding everything else constant, a 1% increase in moon visibility is associated with a 0.01Â° increase in the high temperature, on average, and the effect is not statistically significant&lt;/li>
&lt;li>Holding everything else constant, a 1% increase in the probability of precipitation is associated with a 0.04Â° increase in the high temperature, on average, and the effect is not statistically significant&lt;/li>
&lt;li>Holding everything else constant, a 1 mph increase in the wind speed is associated with a 1.8Â° decrease in the high temperature, on average, and the effect &lt;em>is&lt;/em> statistically significant&lt;/li>
&lt;li>Holding everything else constant, a 1 unit increase in barometric pressure is associated with a 0.15Â° decrease in the high temperature, on average, and the effect is not statistically significant&lt;/li>
&lt;li>Holding everything else constant, a 1% increase in cloud cover is associated with a 0.01Â° decrease in the high temperature, on average, and the effect &lt;em>is&lt;/em> statistically significant&lt;/li>
&lt;li>The intercept is pretty useless. It shows that the predicted temperature will be 262Â° when humidity is 0%, the moon is invisible, there&amp;rsquo;s no chance of precipitation, no wind, no barometric pressure, and no cloud cover. Yikes.&lt;/li>
&lt;/ul>
&lt;p>To plot all these things at once, we&amp;rsquo;ll store the results of &lt;code>tidy(model_complex)&lt;/code> as a data frame, remove the useless intercept, and plot it using &lt;code>geom_pointrange()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">model_tidied &amp;lt;- tidy(model_complex, conf.int = TRUE) %&amp;gt;%
filter(term != &amp;quot;(Intercept)&amp;quot;)
ggplot(model_tidied,
aes(x = estimate, y = term)) +
geom_vline(xintercept = 0, color = &amp;quot;red&amp;quot;, linetype = &amp;quot;dotted&amp;quot;) +
geom_pointrange(aes(xmin = conf.low, xmax = conf.high)) +
labs(x = &amp;quot;Coefficient estimate&amp;quot;, y = NULL) +
theme_minimal()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/coef-plot-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Neat! Now we can see how big these different coefficients are and how close they are to zero. Wind speed has a big significant effect on temperature. The others are all very close to zero.&lt;/p>
&lt;h3 id="marginal-effects-plots">Marginal effects plots&lt;/h3>
&lt;p>Instead of just looking at the coefficients, we can also see the effect of moving different variables up and down like sliders and switches. Remember that regression coefficients allow us to build actual mathematical formulas that predict the value of Y. The coefficients from &lt;code>model_compex&lt;/code> yield the following big hairy ugly equation:&lt;/p>
&lt;p>$$
&lt;code>\begin{aligned} \hat{\text{High temperature}} =&amp;amp; 262 - 0.11 \times \text{humidity_scaled } \\ &amp;amp; + 0.01 \times \text{moonPhase_scaled } + 0.04 \times \text{precipProbability_scaled } \\ &amp;amp; - 1.78 \times \text{windSpeed} - 0.16 \times \text{pressure} - 0.095 \times \text{cloudCover_scaled} \end{aligned}&lt;/code>
$$&lt;/p>
&lt;p>If we plug in values for each of the explanatory variables, we can get the predicted value of high temperature, or &lt;code>\(\hat{y}\)&lt;/code>.&lt;/p>
&lt;p>The &lt;code>augment()&lt;/code> function in the &lt;strong>broom&lt;/strong> library allows us to take a data frame of explanatory variable values, plug them into the model equation, and get predictions out. For example, let&amp;rsquo;s set each of the variables to some arbitrary values (50% for humidity, moon phase, chance of rain, and cloud cover; 1000 for pressure, and 1 MPH for wind speed).&lt;/p>
&lt;pre>&lt;code class="language-r">newdata_example &amp;lt;- tibble(humidity_scaled = 50, moonPhase_scaled = 50,
precipProbability_scaled = 50, windSpeed = 1,
pressure = 1000, cloudCover_scaled = 50)
newdata_example
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 1 x 6
## humidity_scaled moonPhase_scaled precipProbability_scaled windSpeed pressure cloudCover_scaled
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 50 50 50 1 1000 50
&lt;/code>&lt;/pre>
&lt;p>We can plug these values into the model with &lt;code>augment()&lt;/code>. The &lt;code>se_fit&lt;/code> argument gives us standard errors for each prediction:&lt;/p>
&lt;pre>&lt;code class="language-r"># I use select() here because augment() returns columns for all the explanatory
# variables, and the .fitted column with the predicted value is on the far right
# and gets cut off
augment(model_complex, newdata = newdata_example, se_fit = TRUE) %&amp;gt;%
select(.fitted, .se.fit)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 1 x 2
## .fitted .se.fit
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 96.2 3.19
&lt;/code>&lt;/pre>
&lt;p>Given these weather conditions, the predicted high temperature is 96.2Â°. Now you&amp;rsquo;re an armchair meteorologist!&lt;/p>
&lt;p>We can follow the same pattern to show how the predicted temperature changes as specific variables change across a whole range. Here, we create a data frame of possible wind speeds and keep all the other explanatory variables at their means:&lt;/p>
&lt;pre>&lt;code class="language-r">newdata &amp;lt;- tibble(windSpeed = seq(0, 8, 0.5),
pressure = mean(weather_atl_summer$pressure),
precipProbability_scaled = mean(weather_atl_summer$precipProbability_scaled),
moonPhase_scaled = mean(weather_atl_summer$moonPhase_scaled),
humidity_scaled = mean(weather_atl_summer$humidity_scaled),
cloudCover_scaled = mean(weather_atl_summer$cloudCover_scaled))
newdata
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 17 x 6
## windSpeed pressure precipProbability_scaled moonPhase_scaled humidity_scaled cloudCover_scaled
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0 1016. 40.2 50.7 64.8 29.5
## 2 0.5 1016. 40.2 50.7 64.8 29.5
## 3 1 1016. 40.2 50.7 64.8 29.5
## 4 1.5 1016. 40.2 50.7 64.8 29.5
## 5 2 1016. 40.2 50.7 64.8 29.5
## 6 2.5 1016. 40.2 50.7 64.8 29.5
## 7 3 1016. 40.2 50.7 64.8 29.5
## 8 3.5 1016. 40.2 50.7 64.8 29.5
## 9 4 1016. 40.2 50.7 64.8 29.5
## 10 4.5 1016. 40.2 50.7 64.8 29.5
## 11 5 1016. 40.2 50.7 64.8 29.5
## 12 5.5 1016. 40.2 50.7 64.8 29.5
## 13 6 1016. 40.2 50.7 64.8 29.5
## 14 6.5 1016. 40.2 50.7 64.8 29.5
## 15 7 1016. 40.2 50.7 64.8 29.5
## 16 7.5 1016. 40.2 50.7 64.8 29.5
## 17 8 1016. 40.2 50.7 64.8 29.5
&lt;/code>&lt;/pre>
&lt;p>If we feed this big data frame into &lt;code>augment()&lt;/code>, we can get the predicted high temperature for each row. We can also use the &lt;code>.se.fit&lt;/code> column to calculate the 95% confidence interval for each predicted value. We take the standard error, multiply it by -1.96 and 1.96 (or the quantile of the normal distribution at 2.5% and 97.5%), and add that value to the estimate.&lt;/p>
&lt;pre>&lt;code class="language-r">predicted_values &amp;lt;- augment(model_complex,
newdata = newdata,
se_fit = TRUE) %&amp;gt;%
mutate(conf.low = .fitted + (-1.96 * .se.fit),
conf.high = .fitted + (1.96 * .se.fit))
predicted_values %&amp;gt;%
select(windSpeed, .fitted, .se.fit, conf.low, conf.high) %&amp;gt;%
head()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 5
## windSpeed .fitted .se.fit conf.low conf.high
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0 95.3 1.63 92.2 98.5
## 2 0.5 94.5 1.42 91.7 97.2
## 3 1 93.6 1.22 91.2 96.0
## 4 1.5 92.7 1.03 90.7 94.7
## 5 2 91.8 0.836 90.1 93.4
## 6 2.5 90.9 0.653 89.6 92.2
&lt;/code>&lt;/pre>
&lt;p>Cool! Just looking at the data in the table, we can see that predicted temperature drops as windspeed increases. We can plot this to visualize the effect:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(predicted_values, aes(x = windSpeed, y = .fitted)) +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high),
fill = &amp;quot;#BF3984&amp;quot;, alpha = 0.5) +
geom_line(size = 1, color = &amp;quot;#BF3984&amp;quot;) +
labs(x = &amp;quot;Wind speed (MPH)&amp;quot;, y = &amp;quot;Predicted high temperature (F)&amp;quot;) +
theme_minimal()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/mfx-plot-simple-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We just manipulated one of the model coefficients and held everything else at its mean. We can manipulate multiple variables too and encode them all on the graph. For instance, what is the effect of windspeed &lt;em>and&lt;/em> cloud cover on the temperature?&lt;/p>
&lt;p>We&amp;rsquo;ll follow the same process, but vary both &lt;code>windSpeed&lt;/code> and &lt;code>cloudCover_scaled&lt;/code>. Instead of using &lt;code>tibble()&lt;/code>, we use &lt;code>exapnd_grid()&lt;/code>, which creates every combination of the variables we specify. Instead of varying cloud cover by every possible value (like from 0 to 100), we&amp;rsquo;ll choose four possible cloud cover types: 0%, 33%, 66%, and 100%. Everything else will be at its mean.&lt;/p>
&lt;pre>&lt;code class="language-r">newdata_fancy &amp;lt;- expand_grid(windSpeed = seq(0, 8, 0.5),
pressure = mean(weather_atl_summer$pressure),
precipProbability_scaled = mean(weather_atl_summer$precipProbability_scaled),
moonPhase_scaled = mean(weather_atl_summer$moonPhase_scaled),
humidity_scaled = mean(weather_atl_summer$humidity_scaled),
cloudCover_scaled = c(0, 33, 66, 100))
newdata_fancy
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 68 x 6
## windSpeed pressure precipProbability_scaled moonPhase_scaled humidity_scaled cloudCover_scaled
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 0 1016. 40.2 50.7 64.8 0
## 2 0 1016. 40.2 50.7 64.8 33
## 3 0 1016. 40.2 50.7 64.8 66
## 4 0 1016. 40.2 50.7 64.8 100
## 5 0.5 1016. 40.2 50.7 64.8 0
## 6 0.5 1016. 40.2 50.7 64.8 33
## 7 0.5 1016. 40.2 50.7 64.8 66
## 8 0.5 1016. 40.2 50.7 64.8 100
## 9 1 1016. 40.2 50.7 64.8 0
## 10 1 1016. 40.2 50.7 64.8 33
## # â€¦ with 58 more rows
&lt;/code>&lt;/pre>
&lt;p>Notice now that &lt;code>windSpeed&lt;/code> repeats four times (0, 0, 0, 0, 0.5, 0.5, etc.), since there are four possible &lt;code>cloudCover_scaled&lt;/code> values (0, 33, 66, 100).&lt;/p>
&lt;p>We can plot this now, just like before, with wind speed on the x-axis, the predicted temperature on the y-axis, and colored and faceted by cloud cover:&lt;/p>
&lt;pre>&lt;code class="language-r">predicted_values_fancy &amp;lt;- augment(model_complex,
newdata = newdata_fancy,
se_fit = TRUE) %&amp;gt;%
mutate(conf.low = .fitted + (-1.96 * .se.fit),
conf.high = .fitted + (1.96 * .se.fit)) %&amp;gt;%
# Make cloud cover a categorical variable
mutate(cloudCover_scaled = factor(cloudCover_scaled))
ggplot(predicted_values_fancy, aes(x = windSpeed, y = .fitted)) +
geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = cloudCover_scaled),
alpha = 0.5) +
geom_line(aes(color = cloudCover_scaled), size = 1) +
labs(x = &amp;quot;Wind speed (MPH)&amp;quot;, y = &amp;quot;Predicted high temperature (F)&amp;quot;) +
theme_minimal() +
guides(fill = &amp;quot;none&amp;quot;, color = &amp;quot;none&amp;quot;) +
facet_wrap(vars(cloudCover_scaled), nrow = 1)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/07-example_files/figure-html/mfx-complex-1.png" width="864" style="display: block; margin: auto;" />
&lt;p>That&amp;rsquo;s so neat! Temperatures go down slightly as cloud cover increases. If we wanted to improve the model, we&amp;rsquo;d add an interaction term between cloud cover and windspeed so that each line would have a different slope in addition to a different intercept, but that&amp;rsquo;s beyond the scope of this class.&lt;/p></description></item><item><title>Comparisons</title><link>https://aem2850.toddgerarden.com/example/08-example/</link><pubDate>Mon, 28 Jun 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/08-example/</guid><description>&lt;p>For this example, we&amp;rsquo;re going to use cross-national data, but instead of using the typical &lt;code>gapminder&lt;/code> dataset, we&amp;rsquo;re going to collect data directly from the &lt;a href="https://data.worldbank.org/" target="_blank" rel="noopener">World Bank&amp;rsquo;s Open Data portal&lt;/a>&lt;/p>
&lt;p>If you want to skip the data downloading, you can download the data below (you&amp;rsquo;ll likely need to right click and choose &amp;ldquo;Save Link Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/wdi_raw.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>wdi_raw.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/tCnfTLHtMs8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a slightly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="load-and-clean-data">Load and clean data&lt;/h3>
&lt;p>First, we load the libraries we&amp;rsquo;ll be using:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse) # For ggplot, dplyr, and friends
library(WDI) # For getting data from the World Bank
library(geofacet) # For map-shaped facets
library(scales) # For helpful scale functions like dollar()
library(ggrepel) # For non-overlapping labels
&lt;/code>&lt;/pre>
&lt;p>The World Bank has a ton of country-level data at &lt;a href="https://data.worldbank.org/" target="_blank" rel="noopener">data.worldbank.org&lt;/a>. We can use &lt;a href="https://cran.r-project.org/package=WDI" target="_blank" rel="noopener">a package named &lt;strong>WDI&lt;/strong>&lt;/a> (&lt;strong>w&lt;/strong>orld &lt;strong>d&lt;/strong>evelopment &lt;strong>i&lt;/strong>ndicators) to access their servers and download the data directly into R.&lt;/p>
&lt;p>To do this, we need to find the special World Bank codes for specific variables we want to get. These codes come from the URLs of the World Bank&amp;rsquo;s website. For instance, if you search for &amp;ldquo;access to electricity&amp;rdquo; at the World Bank&amp;rsquo;s website, you&amp;rsquo;ll find &lt;a href="https://data.worldbank.org/indicator/EG.ELC.ACCS.ZS" target="_blank" rel="noopener">this page&lt;/a>. If you look at the end of the URL, you&amp;rsquo;ll see a cryptic code: &lt;code>EG.ELC.ACCS.ZS&lt;/code>. That&amp;rsquo;s the World Bank&amp;rsquo;s ID code for the &amp;ldquo;Access to electricity (% of population)&amp;rdquo; indicator.&lt;/p>
&lt;p>We can feed a list of ID codes to the &lt;code>WDI()&lt;/code> function to download data for those specific indicators. We want data from 1995-2015, so we set the start and end years accordingly. The &lt;code>extra=TRUE&lt;/code> argument means that it&amp;rsquo;ll also include other helpful details like region, aid status, etc. Without it, it would only download the indicators we listed.&lt;/p>
&lt;pre>&lt;code class="language-r">indicators &amp;lt;- c(&amp;quot;SP.DYN.LE00.IN&amp;quot;, # Life expectancy
&amp;quot;EG.ELC.ACCS.ZS&amp;quot;, # Access to electricity
&amp;quot;EN.ATM.CO2E.PC&amp;quot;, # CO2 emissions
&amp;quot;NY.GDP.PCAP.KD&amp;quot;) # GDP per capita
wdi_raw &amp;lt;- WDI(country = &amp;quot;all&amp;quot;, indicators, extra = TRUE,
start = 1995, end = 2015)
head(wdi_raw)
&lt;/code>&lt;/pre>
&lt;p>Downloading data from the World Bank every time you knit will get tedious and take a long time (plus if their servers are temporarily down, you won&amp;rsquo;t be able to get the data). It&amp;rsquo;s good practice to save this raw data as a CSV file and then work with that.&lt;/p>
&lt;pre>&lt;code class="language-r">write_csv(wdi_raw, &amp;quot;data/wdi_raw.csv&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>Since we care about reproducibility, we still want to include the code we used to get data from the World Bank, we just don&amp;rsquo;t want it to actually run. You can include chunks but not run them by setting &lt;code>eval=FALSE&lt;/code> in the chunk options. In this little example, we show the code for downloading the data, but we don&amp;rsquo;t evaluate the chunk. We then include a chunk that loads the data from a CSV file with &lt;code>read_csv()&lt;/code>, but we don&amp;rsquo;t include it (&lt;code>include=FALSE&lt;/code>). That way, in the knitted file we see the &lt;code>WDI()&lt;/code> code, but in reality it&amp;rsquo;s loading the data from CSV. Super tricky.&lt;/p>
&lt;pre>&lt;code class="language-text">I first download data from the World Bank:
```{r get-wdi-data, eval=FALSE}
wdi_raw &amp;lt;- WDI(...)
write_csv(wdi_raw, &amp;quot;data/wdi_raw.csv&amp;quot;)
```
```{r load-wdi-data-real, include=FALSE}
wdi_raw &amp;lt;- read_csv(&amp;quot;data/wdi_raw.csv&amp;quot;)
```
&lt;/code>&lt;/pre>
&lt;p>Then we clean up the data a little, filtering out rows that aren&amp;rsquo;t actually countries and renaming the ugly World Bank code columns to actual words:&lt;/p>
&lt;pre>&lt;code class="language-r">wdi_clean &amp;lt;- wdi_raw %&amp;gt;%
filter(region != &amp;quot;Aggregates&amp;quot;) %&amp;gt;%
select(iso2c, country, year,
life_expectancy = SP.DYN.LE00.IN,
access_to_electricity = EG.ELC.ACCS.ZS,
co2_emissions = EN.ATM.CO2E.PC,
gdp_per_cap = NY.GDP.PCAP.KD,
region, income)
head(wdi_clean)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 9
## iso2c country year life_expectancy access_to_electricity co2_emissions gdp_per_cap region income
## &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt;
## 1 AD Andorra 2015 NA 100 NA 41768. Europe &amp;amp; Central Asia High income
## 2 AD Andorra 2004 NA 100 7.36 47033. Europe &amp;amp; Central Asia High income
## 3 AD Andorra 2001 NA 100 7.79 41421. Europe &amp;amp; Central Asia High income
## 4 AD Andorra 2002 NA 100 7.59 42396. Europe &amp;amp; Central Asia High income
## 5 AD Andorra 2014 NA 100 5.83 40790. Europe &amp;amp; Central Asia High income
## 6 AD Andorra 1995 NA 100 6.66 32918. Europe &amp;amp; Central Asia High income
&lt;/code>&lt;/pre>
&lt;h3 id="small-multiples">Small multiples&lt;/h3>
&lt;p>First we can make some small multiples plots and show life expectancy over time for a handful of countries. We&amp;rsquo;ll make a list of some countries chosen at random while I scrolled through the data, and then filter our data to include only those rows. We then plot life expectancy, faceting by country.&lt;/p>
&lt;pre>&lt;code class="language-r">life_expectancy_small &amp;lt;- wdi_clean %&amp;gt;%
filter(country %in% c(&amp;quot;Argentina&amp;quot;, &amp;quot;Bolivia&amp;quot;, &amp;quot;Brazil&amp;quot;,
&amp;quot;Belize&amp;quot;, &amp;quot;Canada&amp;quot;, &amp;quot;Chile&amp;quot;))
ggplot(data = life_expectancy_small,
mapping = aes(x = year, y = life_expectancy)) +
geom_line(size = 1) +
facet_wrap(vars(country))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/life-expectancy-small-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Small multiples! That&amp;rsquo;s all we need to do.&lt;/p>
&lt;p>We can do some fancier things, though. We can make this plot hyper minimalist:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(data = life_expectancy_small,
mapping = aes(x = year, y = life_expectancy)) +
geom_line(size = 1) +
facet_wrap(vars(country), scales = &amp;quot;free_y&amp;quot;) +
theme_void() +
theme(strip.text = element_text(face = &amp;quot;bold&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/life-expectancy-small-minimalist-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can do a whole part of a continent (poor Iraq and Syria ðŸ˜ž)&lt;/p>
&lt;pre>&lt;code class="language-r">life_expectancy_mena &amp;lt;- wdi_clean %&amp;gt;%
filter(region == &amp;quot;Middle East &amp;amp; North Africa&amp;quot;)
ggplot(data = life_expectancy_mena,
mapping = aes(x = year, y = life_expectancy)) +
geom_line(size = 1) +
facet_wrap(vars(country), scales = &amp;quot;free_y&amp;quot;, nrow = 3) +
theme_void() +
theme(strip.text = element_text(face = &amp;quot;bold&amp;quot;))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/life-expectancy-mena-1.png" width="960" style="display: block; margin: auto;" />
&lt;p>We can use the &lt;a href="https://hafen.github.io/geofacet/" target="_blank" rel="noopener">&lt;strong>geofacet&lt;/strong> package&lt;/a> to arrange these facets by geography:&lt;/p>
&lt;pre>&lt;code class="language-r">life_expectancy_eu &amp;lt;- wdi_clean %&amp;gt;%
filter(region == &amp;quot;Europe &amp;amp; Central Asia&amp;quot;)
ggplot(life_expectancy_eu, aes(x = year, y = life_expectancy)) +
geom_line(size = 1) +
facet_geo(vars(country), grid = &amp;quot;eu_grid1&amp;quot;, scales = &amp;quot;free_y&amp;quot;) +
labs(x = NULL, y = NULL, title = &amp;quot;Life expectancy from 1995â€“2015&amp;quot;,
caption = &amp;quot;Source: The World Bank (SP.DYN.LE00.IN)&amp;quot;) +
theme_minimal() +
theme(strip.text = element_text(face = &amp;quot;bold&amp;quot;),
plot.title = element_text(face = &amp;quot;bold&amp;quot;),
axis.text.x = element_text(angle = 45, hjust = 1))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/life-expectancy-eu-1.png" width="960" style="display: block; margin: auto;" />
&lt;p>Neat!&lt;/p>
&lt;h3 id="sparklines">Sparklines&lt;/h3>
&lt;p>Sparklines are just line charts (or bar charts) that are really really small.&lt;/p>
&lt;pre>&lt;code class="language-r">india_co2 &amp;lt;- wdi_clean %&amp;gt;%
filter(country == &amp;quot;India&amp;quot;)
plot_india &amp;lt;- ggplot(india_co2, aes(x = year, y = co2_emissions)) +
geom_line() +
theme_void()
plot_india
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/india-spark-1.png" width="96" style="display: block; margin: auto;" />
&lt;pre>&lt;code class="language-r">ggsave(&amp;quot;india_co2.pdf&amp;quot;, plot_india, width = 1, height = 0.15, units = &amp;quot;in&amp;quot;)
ggsave(&amp;quot;india_co2.png&amp;quot;, plot_india, width = 1, height = 0.15, units = &amp;quot;in&amp;quot;)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-r">china_co2 &amp;lt;- wdi_clean %&amp;gt;%
filter(country == &amp;quot;China&amp;quot;)
plot_china &amp;lt;- ggplot(china_co2, aes(x = year, y = co2_emissions)) +
geom_line() +
theme_void()
plot_china
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/china-spark-1.png" width="96" style="display: block; margin: auto;" />
&lt;pre>&lt;code class="language-r">ggsave(&amp;quot;china_co2.pdf&amp;quot;, plot_china, width = 1, heighlt = 0.15, units = &amp;quot;in&amp;quot;)
ggsave(&amp;quot;china_co2.png&amp;quot;, plot_china, width = 1, height = 0.15, units = &amp;quot;in&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>You can then use those saved tiny plots in your text.&lt;/p>
&lt;blockquote>
&lt;p>Both India &lt;img class="img-inline" src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/india-spark-1.png" width = "100"/> and China &lt;img class="img-inline" src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/china-spark-1.png" width = "100"/> have seen increased CO~2~ emissions over the past 20 years.&lt;/p>
&lt;/blockquote>
&lt;h3 id="slopegraphs">Slopegraphs&lt;/h3>
&lt;p>We can make a slopegraph to show changes in GDP per capita between two time periods. We need to first filter our WDI to include only the start and end years (here 1995 and 2015). Then, to make sure that we&amp;rsquo;re using complete data, we&amp;rsquo;ll get rid of any country that has missing data for either 1995 or 2015. The &lt;code>group_by(...) %&amp;gt;% filter(...) %&amp;gt;% ungroup()&lt;/code> pipeline does this, with the &lt;code>!any(is.na(gdp_per_cap))&lt;/code> test keeping any rows where any of the &lt;code>gdp_per_cap&lt;/code> values are not missing for the whole country.&lt;/p>
&lt;p>We then add a couple special columns for labels. The &lt;code>paste0()&lt;/code> function concatenates strings and variables together, so that &lt;code>paste0(&amp;quot;2 + 2 = &amp;quot;, 2 + 2)&lt;/code> would show &amp;ldquo;2 + 2 = 4&amp;rdquo;. Here we make labels that say either &amp;ldquo;Country name: $GDP&amp;rdquo; or &amp;ldquo;$GDP&amp;rdquo; depending on the year.&lt;/p>
&lt;pre>&lt;code class="language-r">gdp_south_asia &amp;lt;- wdi_clean %&amp;gt;%
filter(region == &amp;quot;South Asia&amp;quot;) %&amp;gt;%
filter(year %in% c(1995, 2015)) %&amp;gt;%
# Look at each country individually
group_by(country) %&amp;gt;%
# Remove the country if any of its gdp_per_cap values are missing
filter(!any(is.na(gdp_per_cap))) %&amp;gt;%
ungroup() %&amp;gt;%
# Make year a factor
mutate(year = factor(year)) %&amp;gt;%
# Make some nice label columns
# If the year is 1995, format it like &amp;quot;Country name: $GDP&amp;quot;. If the year is
# 2015, format it like &amp;quot;$GDP&amp;quot;
mutate(label_first = ifelse(year == 1995, paste0(country, &amp;quot;: &amp;quot;, dollar(round(gdp_per_cap))), NA),
label_last = ifelse(year == 2015, dollar(round(gdp_per_cap, 0)), NA))
&lt;/code>&lt;/pre>
&lt;p>With the data filtered like this, we can plot it by mapping year to the x-axis, GDP per capita to the y-axis, and coloring by country. To make the lines go across the two categorical labels in the x-axis (since we made year a factor/category), we need to also specify the &lt;code>group&lt;/code> aesthetic.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +
geom_line(size = 1.5)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/slopegraph-sa-simple-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Cool! We&amp;rsquo;re getting closer. We can definitely see different slopes, but with 7 different colors, it&amp;rsquo;s hard to see exactly which country is which. Instead, we can directly label each of these lines with &lt;code>geom_text()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +
geom_line(size = 1.5) +
geom_text(aes(label = country)) +
guides(color = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/slopegraph-sa-simple-text-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>That gets us a &lt;em>little&lt;/em> closer, but the country labels are hard to see, and we could include more information, like the actual values. Remember those &lt;code>label_first&lt;/code> and &lt;code>label_last&lt;/code> columns we made? Let&amp;rsquo;s use those instead:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +
geom_line(size = 1.5) +
geom_text(aes(label = label_first)) +
geom_text(aes(label = label_last)) +
guides(color = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/slopegraph-sa-simple-text-fancier-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Now we have dollar amounts and country names, but the labels are still overlapping and really hard to read. To fix this, we can make the labels repel away from each other and randomly position in a way that makes them not overlap. The &lt;a href="https://cran.r-project.org/web/packages/ggrepel/vignettes/ggrepel.html" target="_blank" rel="noopener">&lt;strong>ggrepel&lt;/strong> package&lt;/a> lets us do this with &lt;code>geom_text_repel()&lt;/code>&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +
geom_line(size = 1.5) +
geom_text_repel(aes(label = label_first)) +
geom_text_repel(aes(label = label_last)) +
guides(color = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/slopegraph-sa-getting-warmer-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Now none of the labels are on top of each other, but the labels are still on top of the lines. Also, some of the labels moved inward and outward along the x-axis, but they don&amp;rsquo;t need to do thatâ€”they just need to shift up and down. We can force the labels to only move up and down by setting the &lt;code>direction = &amp;quot;y&amp;quot;&lt;/code> argument, and we can move all the labels to the left or right with the &lt;code>nudge_x&lt;/code> argument. The &lt;code>seed&lt;/code> argument makes sure that the random label placement is the same every time we run this. It can be whatever number you wantâ€”it just has to be a number.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +
geom_line(size = 1.5) +
geom_text_repel(aes(label = label_first), direction = &amp;quot;y&amp;quot;, nudge_x = -1, seed = 1234) +
geom_text_repel(aes(label = label_last), direction = &amp;quot;y&amp;quot;, nudge_x = 1, seed = 1234) +
guides(color = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/slopegraph-sa-fancier-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>That&amp;rsquo;s it! Let&amp;rsquo;s take the theme off completely, change the colors a little, and it should be perfect.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(gdp_south_asia, aes(x = year, y = gdp_per_cap, group = country, color = country)) +
geom_line(size = 1.5) +
geom_text_repel(aes(label = label_first), direction = &amp;quot;y&amp;quot;, nudge_x = -1, seed = 1234) +
geom_text_repel(aes(label = label_last), direction = &amp;quot;y&amp;quot;, nudge_x = 1, seed = 1234) +
guides(color = &amp;quot;none&amp;quot;) +
scale_color_viridis_d(option = &amp;quot;magma&amp;quot;, end = 0.9) +
theme_void()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/slopegraph-sa-done-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="bump-charts">Bump charts&lt;/h3>
&lt;p>Finally, we can make a bump chart that shows changes in rankings over time. We&amp;rsquo;ll look at CO~2~ emissions in South Asia. First we need to calculate a new variable that shows the rank of each country within each year. We can do this if we group by year and then use the &lt;code>rank()&lt;/code> function to rank countries by the &lt;code>co2_emissions&lt;/code> column.&lt;/p>
&lt;pre>&lt;code class="language-r">sa_co2 &amp;lt;- wdi_clean %&amp;gt;%
filter(region == &amp;quot;South Asia&amp;quot;) %&amp;gt;%
filter(year &amp;gt;= 2004, year &amp;lt; 2015) %&amp;gt;%
group_by(year) %&amp;gt;%
mutate(rank = rank(co2_emissions))
&lt;/code>&lt;/pre>
&lt;p>We then plot this with points and lines, reversing the y-axis so 1 is at the top:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(sa_co2, aes(x = year, y = rank, color = country)) +
geom_line() +
geom_point() +
scale_y_reverse(breaks = 1:8)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/make-bump-plot-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Afghanistan and Nepal switched around for the number 1 spot, while India dropped from 4 to 6, switching places with Pakistan.&lt;/p>
&lt;p>As with the slopegraph, there are 8 different colors in the legend and it&amp;rsquo;s hard to line them all up with the different lines, so we can plot the text directly instead. We&amp;rsquo;ll use &lt;code>geom_text()&lt;/code> again. We don&amp;rsquo;t need to repel anything, since the text should fit in each row just fine. We need to change the &lt;code>data&lt;/code> argument in &lt;code>geom_text()&lt;/code> though and filter the data to only include one year, otherwise we&amp;rsquo;ll get labels on every point, which is excessive. We can also adjust the theme and colors to make it cleaner.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(sa_co2, aes(x = year, y = rank, color = country)) +
geom_line(size = 2) +
geom_point(size = 4) +
geom_text(data = filter(sa_co2, year == 2004),
aes(label = iso2c, x = 2003.25),
fontface = &amp;quot;bold&amp;quot;) +
geom_text(data = filter(sa_co2, year == 2014),
aes(label = iso2c, x = 2014.75),
fontface = &amp;quot;bold&amp;quot;) +
guides(color = &amp;quot;none&amp;quot;) +
scale_y_reverse(breaks = 1:8) +
scale_x_continuous(breaks = 2004:2014) +
scale_color_viridis_d(option = &amp;quot;magma&amp;quot;, begin = 0.2, end = 0.9) +
labs(x = NULL, y = &amp;quot;Rank&amp;quot;) +
theme_minimal() +
theme(panel.grid.major.y = element_blank(),
panel.grid.minor.y = element_blank(),
panel.grid.minor.x = element_blank())
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/08-example_files/figure-html/bump-plot-fancier-1.png" width="672" style="display: block; margin: auto;" />
&lt;p>If you want to be &lt;em>super&lt;/em> fancy, you can use flags instead of country codes, but that&amp;rsquo;s a little more complicated (you need to install the &lt;a href="https://github.com/rensa/ggflags" target="_blank" rel="noopener">&lt;strong>ggflags&lt;/strong> package&lt;/a>. &lt;a href="https://dominikkoch.github.io/Bump-Chart/" target="_blank" rel="noopener">See here for an example&lt;/a>.&lt;/p></description></item><item><title>Themes</title><link>https://aem2850.toddgerarden.com/example/05-example/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/05-example/</guid><description>&lt;p>The &lt;a href="https://aem2850.toddgerarden.com/lesson/05-lesson/">lesson for today&amp;rsquo;s session&lt;/a> is a fairly comprehensive introduction to using the &lt;code>theme()&lt;/code> function in ggplot, and &lt;a href="https://henrywang.nl/ggplot2-theme-elements-demonstration/" target="_blank" rel="noopener">this page by Henry Wang&lt;/a> is a good cheat sheet for remembering which theme elements are which on a plot.&lt;/p>
&lt;p>For &lt;a href="https://aem2850.toddgerarden.com/assignment/05-exercise/">your exercise&lt;/a>, you&amp;rsquo;re going to create the world&amp;rsquo;s ugliest plot. For this example, we&amp;rsquo;ll use the principles of CRAP to make a great theme.&lt;/p>
&lt;p>I&amp;rsquo;m going to build the theme semi-incrementally here. Instead of showing how the plot updates with each change in setting, I do most of the updates all at once, with tons of comments explaining what each line does. &lt;strong>Importantly&lt;/strong>, I did &lt;em>not&lt;/em> write this all at once. When you&amp;rsquo;re tinkering with themes, you generally start with something like &lt;code>theme_minimal()&lt;/code> or &lt;code>theme_bw()&lt;/code> and then gradually add new things to &lt;code>theme()&lt;/code>, like modifying &lt;code>plot.title&lt;/code>, then &lt;code>plot.subtitle&lt;/code>, etc. It&amp;rsquo;s a very iterative process with lots of tinkering. Because of this, &lt;strong>there is no live-coding video for this example&lt;/strong>â€”it would be incredibly long and boring. Instead, look through each of the lines and see what they&amp;rsquo;re doing.&lt;/p>
&lt;p>For this example, I&amp;rsquo;m going to use the &lt;code>gapminder&lt;/code> dataset that we&amp;rsquo;ve been using throughout this week. You can get it if you install the &lt;strong>gapminder&lt;/strong> package in R, or you can download this CSV file (you may need to right click on it and select &amp;ldquo;Save Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/gapminder.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>gapminder.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>I&amp;rsquo;m also going to use the &lt;a href="https://fonts.google.com/specimen/Roboto&amp;#43;Condensed" target="_blank" rel="noopener">Roboto Condensed font&lt;/a> in the theme. Download and install it on your computer if you don&amp;rsquo;t have it.&lt;/p>
&lt;h2 id="basic-plot">Basic plot&lt;/h2>
&lt;p>When I&amp;rsquo;m creating a theme, I like to use a basic plot with everything that might show up, complete with a title, subtitle, caption, legend, facets, and other elements.&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse) # For ggplot, dplyr, and friends
library(gapminder) # For gapminder data
library(scales) # For nice axis labels
gapminder_filtered &amp;lt;- gapminder %&amp;gt;%
filter(year &amp;gt; 2000)
base_plot &amp;lt;- ggplot(data = gapminder_filtered,
mapping = aes(x = gdpPercap, y = lifeExp,
color = continent, size = pop)) +
geom_point() +
# Use dollars, and get rid of the cents part (i.e. $300 instead of $300.00)
scale_x_log10(labels = dollar_format(accuracy = 1)) +
# Format with commas
scale_size_continuous(labels = comma) +
# Use viridis
scale_color_viridis_d(option = &amp;quot;plasma&amp;quot;, end = 0.9) +
labs(x = &amp;quot;GDP per capita&amp;quot;, y = &amp;quot;Life expectancy&amp;quot;,
color = &amp;quot;Continent&amp;quot;, size = &amp;quot;Population&amp;quot;,
title = &amp;quot;Here's a cool title&amp;quot;,
subtitle = &amp;quot;And here's a neat subtitle&amp;quot;,
caption = &amp;quot;Source: The Gapminder Project&amp;quot;) +
facet_wrap(vars(year))
base_plot
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/05-example_files/figure-html/basic-plot-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>Now we have &lt;code>base_plot&lt;/code> to work with. Here&amp;rsquo;s what it looks like with &lt;code>theme_minimal()&lt;/code> applied to it:&lt;/p>
&lt;pre>&lt;code class="language-r">base_plot +
theme_minimal()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/05-example_files/figure-html/base-minimal-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>That gets rid of the grey background and is a good start, but we can make lots of improvements. First let&amp;rsquo;s deal with the gridlines. There are too many. We can get rid of the minor gridlines with by setting them to &lt;code>element_blank()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">base_plot +
theme_minimal() +
theme(panel.grid.minor = element_blank())
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/05-example_files/figure-html/theme1-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>Next let&amp;rsquo;s add some typographic contrast. We&amp;rsquo;ll use Roboto Condensed Regular as the base font. Before trying this, make sure you do the following:&lt;/p>
&lt;p>&lt;strong>On macOS&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Run &lt;code>capabilities()&lt;/code> in your console and verify that &lt;code>TRUE&lt;/code> shows up under &lt;code>cairo&lt;/code>&lt;/li>
&lt;li>If not, download and install &lt;a href="https://www.xquartz.org/" target="_blank" rel="noopener">XQuartz&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>On Windows&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Run &lt;code>windowsFonts()&lt;/code> in your console and you&amp;rsquo;ll see a list of all the fonts you can use with R. It&amp;rsquo;s not a very big list.&lt;/p>
&lt;pre>&lt;code class="language-text">#&amp;gt; $serif
#&amp;gt; [1] &amp;quot;TT Times New Roman&amp;quot;
#&amp;gt;
#&amp;gt; $sans
#&amp;gt; [1] &amp;quot;TT Arial&amp;quot;
#&amp;gt;
#&amp;gt; $mono
#&amp;gt; [1] &amp;quot;TT Courier New&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>You can add Roboto Condensed to your current R session by running this in your console:&lt;/p>
&lt;pre>&lt;code class="language-r">windowsFonts(`Roboto Condensed` = windowsFont(&amp;quot;Roboto Condensed&amp;quot;))
&lt;/code>&lt;/pre>
&lt;p>Now if you run &lt;code>windowsFonts()&lt;/code>, you&amp;rsquo;ll see it in the list:&lt;/p>
&lt;pre>&lt;code class="language-text">#&amp;gt; $serif
#&amp;gt; [1] &amp;quot;TT Times New Roman&amp;quot;
#&amp;gt;
#&amp;gt; $sans
#&amp;gt; [1] &amp;quot;TT Arial&amp;quot;
#&amp;gt;
#&amp;gt; $mono
#&amp;gt; [1] &amp;quot;TT Courier New&amp;quot;
#&amp;gt;
#&amp;gt; $`Roboto Condensed`
#&amp;gt; [1] &amp;quot;Roboto Condensed&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>This only takes effect for your current R session, so if you are knitting a document or if you ever plan on closing RStudio, you&amp;rsquo;ll need to incorporate this font creation code into your script.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>We&amp;rsquo;ll use the font as the &lt;code>base_family&lt;/code> argument. Note how I make it bold with &lt;code>face&lt;/code> and change the size with &lt;code>rel()&lt;/code>. Instead of manually setting some arbitrary size, I use &lt;code>rel()&lt;/code> to resize the text in relation to the &lt;code>base_size&lt;/code> argument. Using &lt;code>rel(1.7)&lt;/code> means 1.7 Ã— &lt;code>base_size&lt;/code>, or 20.4 That will rescale according to whatever &lt;code>base_size&lt;/code> isâ€”if I shrink it to &lt;code>base_size = 8&lt;/code>, the title will scale down accordingly.&lt;/p>
&lt;pre>&lt;code class="language-r">plot_with_good_typography &amp;lt;- base_plot +
theme_minimal(base_family = &amp;quot;Roboto Condensed&amp;quot;, base_size = 12) +
theme(panel.grid.minor = element_blank(),
# Bold, bigger title
plot.title = element_text(face = &amp;quot;bold&amp;quot;, size = rel(1.7)),
# Plain, slightly bigger subtitle that is grey
plot.subtitle = element_text(face = &amp;quot;plain&amp;quot;, size = rel(1.3), color = &amp;quot;grey70&amp;quot;),
# Italic, smaller, grey caption that is left-aligned
plot.caption = element_text(face = &amp;quot;italic&amp;quot;, size = rel(0.7),
color = &amp;quot;grey70&amp;quot;, hjust = 0),
# Bold legend titles
legend.title = element_text(face = &amp;quot;bold&amp;quot;),
# Bold, slightly larger facet titles that are left-aligned for the sake of repetition
strip.text = element_text(face = &amp;quot;bold&amp;quot;, size = rel(1.1), hjust = 0),
# Bold axis titles
axis.title = element_text(face = &amp;quot;bold&amp;quot;),
# Add some space above the x-axis title and make it left-aligned
axis.title.x = element_text(margin = margin(t = 10), hjust = 0),
# Add some space to the right of the y-axis title and make it top-aligned
axis.title.y = element_text(margin = margin(r = 10), hjust = 1))
plot_with_good_typography
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/05-example_files/figure-html/theme2-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>Whoa. That gets us most of the way there! We have good contrast with the typography, with the strong bold and the lighter regular font (&lt;strong>âœ“ contrast&lt;/strong>). Everything is aligned left (&lt;strong>âœ“ alignment&lt;/strong> and &lt;strong>âœ“ repetition&lt;/strong>). By moving the axis titles a little bit away from the labels, we&amp;rsquo;ve enhanced proximity, since they were too close together (&lt;strong>âœ“ proximity&lt;/strong>). We repeat grey in both the caption and the subtitle (&lt;strong>âœ“ repetition&lt;/strong>).&lt;/p>
&lt;p>The only thing I don&amp;rsquo;t like is that the 2002 isn&amp;rsquo;t quite aligned with the title and subtitle. This is because the facet labels are in boxes along the top of each plot, and in some themes (like &lt;code>theme_grey()&lt;/code> and &lt;code>theme_bw()&lt;/code>) those facet labels have grey backgrounds. We can turn off the margin in those boxes, or we can add a background, which will then be perfectly aligned with the title and subtitle.&lt;/p>
&lt;pre>&lt;code class="language-r">plot_with_good_typography +
# Add a light grey background to the facet titles, with no borders
theme(strip.background = element_rect(fill = &amp;quot;grey90&amp;quot;, color = NA),
# Add a thin grey border around all the plots to tie in the facet titles
panel.border = element_rect(color = &amp;quot;grey90&amp;quot;, fill = NA))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/05-example_files/figure-html/theme3-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>ðŸ‘©â€ðŸ³ ðŸ’‹! That looks great!&lt;/p>
&lt;p>To save ourselves time in the future, we can store this whole thing as an object that we can then reuse on other plots:&lt;/p>
&lt;pre>&lt;code class="language-r">my_pretty_theme &amp;lt;- theme_minimal(base_family = &amp;quot;Roboto Condensed&amp;quot;, base_size = 12) +
theme(panel.grid.minor = element_blank(),
# Bold, bigger title
plot.title = element_text(face = &amp;quot;bold&amp;quot;, size = rel(1.7)),
# Plain, slightly bigger subtitle that is grey
plot.subtitle = element_text(face = &amp;quot;plain&amp;quot;, size = rel(1.3), color = &amp;quot;grey70&amp;quot;),
# Italic, smaller, grey caption that is left-aligned
plot.caption = element_text(face = &amp;quot;italic&amp;quot;, size = rel(0.7),
color = &amp;quot;grey70&amp;quot;, hjust = 0),
# Bold legend titles
legend.title = element_text(face = &amp;quot;bold&amp;quot;),
# Bold, slightly larger facet titles that are left-aligned for the sake of repetition
strip.text = element_text(face = &amp;quot;bold&amp;quot;, size = rel(1.1), hjust = 0),
# Bold axis titles
axis.title = element_text(face = &amp;quot;bold&amp;quot;),
# Add some space above the x-axis title and make it left-aligned
axis.title.x = element_text(margin = margin(t = 10), hjust = 0),
# Add some space to the right of the y-axis title and make it top-aligned
axis.title.y = element_text(margin = margin(r = 10), hjust = 1),
# Add a light grey background to the facet titles, with no borders
strip.background = element_rect(fill = &amp;quot;grey90&amp;quot;, color = NA),
# Add a thin grey border around all the plots to tie in the facet titles
panel.border = element_rect(color = &amp;quot;grey90&amp;quot;, fill = NA))
&lt;/code>&lt;/pre>
&lt;p>Now we can use it on any plot. Remember that first plot you made in your exercise from session 1 with the &lt;code>cars&lt;/code> dataset? Let&amp;rsquo;s throw this theme on it! (only here the dataset is named &lt;code>mpg&lt;/code> instead of &lt;code>cars&lt;/code>; the &lt;code>mpg&lt;/code> dataset is loaded invisibly whenever you load ggplot)&lt;/p>
&lt;pre>&lt;code class="language-r">mpg_example &amp;lt;- ggplot(data = mpg,
mapping = aes(x = displ, y = hwy, color = class)) +
geom_point(size = 3) +
scale_color_viridis_d() +
facet_wrap(vars(drv)) +
labs(x = &amp;quot;Displacement&amp;quot;, y = &amp;quot;Highway MPG&amp;quot;, color = &amp;quot;Car class&amp;quot;,
title = &amp;quot;Heavier cars get worse mileage&amp;quot;,
subtitle = &amp;quot;Except two-seaters?&amp;quot;,
caption = &amp;quot;Here's a caption&amp;quot;) +
my_pretty_theme
mpg_example
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/05-example_files/figure-html/mpg-example-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>Super neat!&lt;/p>
&lt;h2 id="nice-pre-built-themes">Nice pre-built themes&lt;/h2>
&lt;p>This custom theme we just made is just one iteration of a theme. There are countless ways to tinker with a theme and have it meet the different CRAP principles. People have even published their own themes in different R packages. Check these out to see lots of different examples:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://github.com/hrbrmstr/hrbrthemes" target="_blank" rel="noopener">&lt;strong>hrbrthemes&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://yutannihilation.github.io/allYourFigureAreBelongToUs/ggthemes/" target="_blank" rel="noopener">&lt;strong>ggthemes&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/cttobin/ggthemr" target="_blank" rel="noopener">&lt;strong>ggthemr&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://github.com/ricardo-bion/ggtech" target="_blank" rel="noopener">&lt;strong>ggtech&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://ryo-n7.github.io/2019-05-16-introducing-tvthemes-package/" target="_blank" rel="noopener">&lt;strong>tvthemes&lt;/strong>&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://www.garrickadenbuie.com/project/ggpomological/" target="_blank" rel="noopener">&lt;strong>ggpomological&lt;/strong>&lt;/a> (this one is incredible!)&lt;/li>
&lt;/ul>
&lt;p>Check &lt;a href="https://rfortherestofus.com/2019/08/themes-to-improve-your-ggplot-figures/" target="_blank" rel="noopener">this blog post&lt;/a> for examples of a bunch of others&lt;/p>
&lt;h2 id="bonus-ggthemeassist">Bonus: &lt;strong>ggthemeassist&lt;/strong>&lt;/h2>
&lt;p>If you&amp;rsquo;re intimidated by constantly referring to the documentation and figuring out what little line of code affects which part of the graph, install and check out the &lt;strong>ggthemeassist&lt;/strong> package. It provides an interactive menu for manipulating different theme elements, and then generates all the corresponding code, which is really magical.&lt;/p>
&lt;p>Here&amp;rsquo;s a brief example of how to use it.&lt;/p>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/9ldrTCUSReM" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="saving-plots">Saving plots&lt;/h2>
&lt;p>If we want to save these plots, we can use &lt;code>ggsave()&lt;/code>. For that to work, we need to store the plot as an object, which I already did in the examples above:&lt;/p>
&lt;pre>&lt;code class="language-r">name_of_plot_object &amp;lt;- ggplot(...)
&lt;/code>&lt;/pre>
&lt;p>We then feed our saved plot object to &lt;code>ggsave()&lt;/code> and specify the filename and dimensions we want to use. If we&amp;rsquo;re using PNG, we don&amp;rsquo;t need to worry about any extra options. If we&amp;rsquo;re using PDF, &lt;a href="https://www.andrewheiss.com/blog/2017/09/27/working-with-r-cairo-graphics-custom-fonts-and-ggplot/" target="_blank" rel="noopener">we need to tell R to use the Cairo PDF writing engine&lt;/a> instead of R&amp;rsquo;s normal one, since R&amp;rsquo;s normal one can&amp;rsquo;t deal with custom fonts.&lt;/p>
&lt;pre>&lt;code class="language-r"># Add my_pretty_theme to the gapminder base_plot and save as an object
final_gampinder_plot &amp;lt;- base_plot +
my_pretty_theme
# Save as PNG and PDF
ggsave(&amp;quot;fancy_gapminder.png&amp;quot;, final_gampinder_plot,
width = 8, height = 5, units = &amp;quot;in&amp;quot;)
ggsave(&amp;quot;fancy_gapminder.pdf&amp;quot;, final_gampinder_plot,
width = 8, height = 5, units = &amp;quot;in&amp;quot;, device = cairo_pdf)
# Save the mpg plot as PNG and PDF
ggsave(&amp;quot;fancy_mpg.png&amp;quot;, mpg_example,
width = 8, height = 5, units = &amp;quot;in&amp;quot;)
ggsave(&amp;quot;fancy_mpg.pdf&amp;quot;, mpg_example,
width = 8, height = 5, units = &amp;quot;in&amp;quot;, device = cairo_pdf)
&lt;/code>&lt;/pre></description></item><item><title>Uncertainty</title><link>https://aem2850.toddgerarden.com/example/06-example/</link><pubDate>Mon, 21 Jun 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/06-example/</guid><description>&lt;p>For this example, we&amp;rsquo;re going to use historical weather data from &lt;a href="https://darksky.net/forecast/33.7546,-84.39/us12/en" target="_blank" rel="noopener">Dark Sky&lt;/a> about wind speed and temperature trends for downtown Atlanta (&lt;a href="https://www.google.com/maps/place/33%c2%b045%2716.4%22N&amp;#43;84%c2%b023%2724.0%22W/@33.754557,-84.3921977,17z/" target="_blank" rel="noopener">specifically &lt;code>33.754557, -84.390009&lt;/code>&lt;/a>) in 2019. I downloaded this data using Dark Sky&amp;rsquo;s (about-to-be-retired-because-they-were-bought-by-Apple) API using the &lt;a href="https://github.com/hrbrmstr/darksky" target="_blank" rel="noopener"> &lt;strong>darksky&lt;/strong> package&lt;/a>.&lt;/p>
&lt;p>If you want to follow along with this example, you can download the data below (you&amp;rsquo;ll likely need to right click and choose &amp;ldquo;Save Link Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/atl-weather-2019.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>atl-weather-2019.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/40dW63jTbsk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a slightly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="load-and-clean-data">Load and clean data&lt;/h3>
&lt;p>First, we load the libraries we&amp;rsquo;ll be using:&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse)
library(lubridate)
library(ggridges)
library(gghalves)
&lt;/code>&lt;/pre>
&lt;p>Then we load the data with &lt;code>read_csv()&lt;/code>. Here I assume that the CSV file lives in a subfolder in my project named &lt;code>data&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">weather_atl_raw &amp;lt;- read_csv(&amp;quot;data/atl-weather-2019.csv&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>We&amp;rsquo;ll add a couple columns that we can use for faceting and filling using the &lt;code>month()&lt;/code> and &lt;code>wday()&lt;/code> functions from &lt;strong>lubridate&lt;/strong> for extracting parts of the date:&lt;/p>
&lt;pre>&lt;code class="language-r">weather_atl &amp;lt;- weather_atl_raw %&amp;gt;%
mutate(Month = month(time, label = TRUE, abbr = FALSE),
Day = wday(time, label = TRUE, abbr = FALSE))
&lt;/code>&lt;/pre>
&lt;p>Now we&amp;rsquo;re ready to go!&lt;/p>
&lt;h3 id="histograms">Histograms&lt;/h3>
&lt;p>We can first make a histogram of wind speed. We&amp;rsquo;ll use a bin width of 1 and color the edges of the bars white:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed)) +
geom_histogram(binwidth = 1, color = &amp;quot;white&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/basic-histogram-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>This is fine enough, but we can improve it by forcing the buckets/bins to start at whole numbers instead of containing ranges like 2.5â€“3.5. We&amp;rsquo;ll use the &lt;code>boundary&lt;/code> argument for that. We also add &lt;code>scale_x_continuous()&lt;/code> to add our own x-axis breaks instead of having things like 2.5, 5, and 7.5:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed)) +
geom_histogram(binwidth = 1, color = &amp;quot;white&amp;quot;, boundary = 1) +
scale_x_continuous(breaks = seq(0, 12, by = 1))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/basic-histogram-better-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can show the distribution of wind speed by month if we map the &lt;code>Month&lt;/code> column we made onto the fill aesthetic:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed, fill = Month)) +
geom_histogram(binwidth = 1, color = &amp;quot;white&amp;quot;, boundary = 1) +
scale_x_continuous(breaks = seq(0, 12, by = 1))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/histogram-by-month-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>This is colorful, but it&amp;rsquo;s impossible to actually interpret. Instead of only filling, we&amp;rsquo;ll also facet by month to see separate graphs for each month. We can turn off the fill legend because it&amp;rsquo;s now redundant.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed, fill = Month)) +
geom_histogram(binwidth = 1, color = &amp;quot;white&amp;quot;, boundary = 1) +
scale_x_continuous(breaks = seq(0, 12, by = 1)) +
guides(fill = &amp;quot;none&amp;quot;) +
facet_wrap(vars(Month))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/histogram-by-month-facet-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>Neat! January, March, and April appear to have the most variation in windy days, with a few wind-less days and a few very-windy days, while August was very wind-less.&lt;/p>
&lt;h3 id="density-plots">Density plots&lt;/h3>
&lt;p>The code to create a density plot is nearly identical to what we used for the histogramâ€”the only thing we change is the &lt;code>geom&lt;/code> layer:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed)) +
geom_density(color = &amp;quot;grey20&amp;quot;, fill = &amp;quot;grey50&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/basic-density-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>If we want, we can mess with some of the calculus options like the kernel and bandwidth:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed)) +
geom_density(color = &amp;quot;grey20&amp;quot;, fill = &amp;quot;grey50&amp;quot;,
bw = 0.1, kernel = &amp;quot;epanechnikov&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/density-kernel-bw-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can also fill by month. We&amp;rsquo;ll make the different layers 50% transparent so we can kind of see through the whole stack:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed, fill = Month)) +
geom_density(alpha = 0.5)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/density-fill-by-month-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Even with the transparency, this is really hard to interpret. We can fix this by faceting, like we did with the histograms:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed, fill = Month)) +
geom_density(alpha = 0.5) +
guides(fill = &amp;quot;none&amp;quot;) +
facet_wrap(vars(Month))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/density-facet-by-month-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>Or we can stack the density plots behind each other with &lt;a href="https://cran.r-project.org/web/packages/ggridges/vignettes/introduction.html" target="_blank" rel="noopener">&lt;strong>ggridges&lt;/strong>&lt;/a>. For that to work, we also need to map &lt;code>Month&lt;/code> to the y-axis. We can reverse the y-axis so that January is at the top if we use the &lt;code>fct_rev()&lt;/code> function:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed, y = fct_rev(Month), fill = Month)) +
geom_density_ridges() +
guides(fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/ggridges-basic-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can add some extra information to &lt;code>geom_density_ridges()&lt;/code> with some other arguments like &lt;code>quantile_lines&lt;/code>. We can use the &lt;code>quantiles&lt;/code> argument to tell the plow how many parts to be cut into. Since we just want to show the median, we&amp;rsquo;ll set that to 2 so each density plot is divided in half:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = windSpeed, y = fct_rev(Month), fill = Month)) +
geom_density_ridges(quantile_lines = TRUE, quantiles = 2) +
guides(fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/ggridges-quantile-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Now that we have good working code, we can easily substitute in other variables by changing the x mapping:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = temperatureHigh, y = fct_rev(Month), fill = Month)) +
geom_density_ridges(quantile_lines = TRUE, quantiles = 2) +
guides(fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/ggridges-quantile-temp-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can get extra fancy if we fill by temperature instead of filling by month. To get this to work, we need to use &lt;code>geom_density_ridges_gradient()&lt;/code>, and we need to change the &lt;code>fill&lt;/code> mapping to the strange looking &lt;code>..x..&lt;/code>, which is a weird ggplot trick that tells it to use the variable we mapped to the x-axis. For whatever reason, &lt;code>fill = temperatureHigh&lt;/code> doesn&amp;rsquo;t work ðŸ¤·:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl, aes(x = temperatureHigh, y = fct_rev(Month), fill = ..x..)) +
geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = 2) +
scale_fill_viridis_c(option = &amp;quot;plasma&amp;quot;) +
labs(x = &amp;quot;High temperature&amp;quot;, y = NULL, color = &amp;quot;Temp&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/ggridges-gradient-temp-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>And finally, we can get &lt;em>extra&lt;/em> fancy and show the distributions for both the high and low temperatures each month. To make this work, we need to manipulate the data a little. Right now there are two columns for high and low temperature: &lt;code>temperatureLow&lt;/code> and &lt;code>temperatureHigh&lt;/code>. To be able to map temperature to the x-axis and high vs. low to another aesthetic (like &lt;code>linetype&lt;/code>), we need a column with the temperature and a column with an indicator variable for whether it is high or low. This data needs to be tidied (since right now we have a variable (high/low) encoded in the column name). We can tidy this data using &lt;code>pivot_longer()&lt;/code> from &lt;strong>tidyr&lt;/strong>, which was already loaded with &lt;code>library(tidyverse)&lt;/code>. In the RStudio primers, you did this same thing with &lt;code>gather()&lt;/code>â€”&lt;code>pivot_longer()&lt;/code> is the newer version of &lt;code>gather()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">weather_atl_long &amp;lt;- weather_atl %&amp;gt;%
pivot_longer(cols = c(temperatureLow, temperatureHigh),
names_to = &amp;quot;temp_type&amp;quot;,
values_to = &amp;quot;temp&amp;quot;) %&amp;gt;%
# Clean up the new temp_type column so that &amp;quot;temperatureHigh&amp;quot; becomes &amp;quot;High&amp;quot;, etc.
mutate(temp_type = recode(temp_type,
temperatureHigh = &amp;quot;High&amp;quot;,
temperatureLow = &amp;quot;Low&amp;quot;)) %&amp;gt;%
# This is optionalâ€”just select a handful of columns
select(time, temp_type, temp, Month)
# Show the first few rows
head(weather_atl_long)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 4
## time temp_type temp Month
## &amp;lt;dttm&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;ord&amp;gt;
## 1 2019-01-01 05:00:00 Low 50.6 January
## 2 2019-01-01 05:00:00 High 63.9 January
## 3 2019-01-02 05:00:00 Low 49.0 January
## 4 2019-01-02 05:00:00 High 57.4 January
## 5 2019-01-03 05:00:00 Low 53.1 January
## 6 2019-01-03 05:00:00 High 55.3 January
&lt;/code>&lt;/pre>
&lt;p>Now we have a column for the temperature (&lt;code>temp&lt;/code>) and a column indicating if it is high or low (&lt;code>temp_type&lt;/code>). The dataset is also twice as long (730 rows) because each day has two rows (high and low). Let&amp;rsquo;s plot it and map high/low to the &lt;code>linetype&lt;/code> aesthetic to show high/low in the border of the plots:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl_long, aes(x = temp, y = fct_rev(Month),
fill = ..x.., linetype = temp_type)) +
geom_density_ridges_gradient(quantile_lines = TRUE, quantiles = 2) +
scale_fill_viridis_c(option = &amp;quot;plasma&amp;quot;) +
labs(x = &amp;quot;High temperature&amp;quot;, y = NULL, color = &amp;quot;Temp&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/ggridges-gradient-temp-high-low-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Super neat! We can see much wider temperature disparities during the summer, with large gaps between high and low, and relatively equal high/low temperatures during the winter.&lt;/p>
&lt;h3 id="box-violin-and-rain-cloud-plots">Box, violin, and rain cloud plots&lt;/h3>
&lt;p>Finally, we can look at the distribution of variables with box plots, violin plots, and other similar graphs. First, we&amp;rsquo;ll make a box plot of windspeed, filled by the &lt;code>Day&lt;/code> variable we made indicating weekday:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl,
aes(y = windSpeed, fill = Day)) +
geom_boxplot()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/basic-boxplot-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can switch this to a violin plot by just changing the &lt;code>geom&lt;/code> layer and mapping &lt;code>Day&lt;/code> to the x-axis:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl,
aes(y = windSpeed, x = Day, fill = Day)) +
geom_violin()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/basic-violin-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>With violin plots it&amp;rsquo;s typically good to overlay other geoms. We can add some jittered points for a strip plot:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl,
aes(y = windSpeed, x = Day, fill = Day)) +
geom_violin() +
geom_point(size = 0.5, position = position_jitter(width = 0.1)) +
guides(fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/violin-strip-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can also add larger points for the daily averages. We&amp;rsquo;ll use a special layer for this: &lt;code>stat_summary()&lt;/code>. It has a slightly different syntax, since we&amp;rsquo;re not actually mapping a column from the dataset. Instead, we&amp;rsquo;re feeding a column from a dataset into a function (here &lt;code>&amp;quot;mean&amp;quot;&lt;/code>) and then plotting that result:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl,
aes(y = windSpeed, x = Day, fill = Day)) +
geom_violin() +
stat_summary(geom = &amp;quot;point&amp;quot;, fun = &amp;quot;mean&amp;quot;, size = 5, color = &amp;quot;white&amp;quot;) +
geom_point(size = 0.5, position = position_jitter(width = 0.1)) +
guides(fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/violin-strip-mean-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>We can also show the mean and confidence interval at the same time by changing the summary function:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl,
aes(y = windSpeed, x = Day, fill = Day)) +
geom_violin() +
stat_summary(geom = &amp;quot;pointrange&amp;quot;, fun.data = &amp;quot;mean_se&amp;quot;, size = 1, color = &amp;quot;white&amp;quot;) +
geom_point(size = 0.5, position = position_jitter(width = 0.1)) +
guides(fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/violin-strip-mean-ci-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Overlaying the points directly on top of the violins shows extra information, but it&amp;rsquo;s also really crowded and hard to read. If we use &lt;a href="https://github.com/erocoar/gghalves" target="_blank" rel="noopener">the &lt;strong>gghalves&lt;/strong> package&lt;/a>, we can use special halved versions of some of these geoms like so:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl,
aes(x = fct_rev(Day), y = temperatureHigh)) +
geom_half_point(aes(color = Day), side = &amp;quot;l&amp;quot;, size = 0.5) +
geom_half_boxplot(aes(fill = Day), side = &amp;quot;r&amp;quot;) +
guides(color = &amp;quot;none&amp;quot;, fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/gghalves-point-boxplot-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Note the &lt;code>side&lt;/code> argument for specifying which half of the column the geom goes. We can also use &lt;code>geom_half_violin()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl,
aes(x = fct_rev(Day), y = temperatureHigh)) +
geom_half_point(aes(color = Day), side = &amp;quot;l&amp;quot;, size = 0.5) +
geom_half_violin(aes(fill = Day), side = &amp;quot;r&amp;quot;) +
guides(color = &amp;quot;none&amp;quot;, fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/gghalves-point-violon-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>If we flip the plot, we can make a &lt;a href="https://micahallen.org/2018/03/15/introducing-raincloud-plots/" target="_blank" rel="noopener">rain cloud plot&lt;/a>:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(weather_atl,
aes(x = fct_rev(Day), y = temperatureHigh)) +
geom_half_boxplot(aes(fill = Day), side = &amp;quot;l&amp;quot;, width = 0.5, nudge = 0.1) +
geom_half_point(aes(color = Day), side = &amp;quot;l&amp;quot;, size = 0.5) +
geom_half_violin(aes(fill = Day), side = &amp;quot;r&amp;quot;) +
guides(color = &amp;quot;none&amp;quot;, fill = &amp;quot;none&amp;quot;) +
coord_flip()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/06-example_files/figure-html/gghalves-rain-cloud-1.png" width="768" style="display: block; margin: auto;" />
&lt;p>Neat!&lt;/p></description></item><item><title>Mapping data to graphics</title><link>https://aem2850.toddgerarden.com/example/03-example/</link><pubDate>Mon, 14 Jun 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/03-example/</guid><description>&lt;p>For this example, I&amp;rsquo;m going to use real world data to demonstrate the typical process for loading data, cleaning it up a bit, and mapping specific columns of the data onto the parts of a graph using the grammar of graphics and &lt;code>ggplot()&lt;/code>.&lt;/p>
&lt;p>The data I&amp;rsquo;ll use comes from the BBC&amp;rsquo;s corporate charity, &lt;a href="https://www.bbcchildreninneed.co.uk/" target="_blank" rel="noopener">BBC Children in Need&lt;/a>, which makes grants to smaller UK nonprofit organizations that work on issues related to childhood poverty. An organization in the UK named &lt;a href="https://www.threesixtygiving.org/" target="_blank" rel="noopener">360Giving&lt;/a> helps nonprofits and foundations publish data about their grant giving activities in an open and standardized way, and (as of May 2020) &lt;a href="http://data.threesixtygiving.org/" target="_blank" rel="noopener">they list data from 126 different charities&lt;/a>, including BBC Children in Need.&lt;/p>
&lt;p>If you want to follow along with this example (highly recommended!), you can download the data directly from &lt;a href="http://data.threesixtygiving.org/" target="_blank" rel="noopener">360Giving&lt;/a> or by using this link:&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/360-giving-data.xlsx">&lt;i class="fas fa-file-excel">&lt;/i> &lt;code>360-giving-data.xlsx&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;p>&lt;strong>Warning&lt;/strong>: I got carried away with this because I wanted to make it as comprehensive and detailed as possible, so it starts off with nothing and walks through the process of downloading data, creating a new project, and getting everything started. As such, it is ridiculously long (1 hour ðŸ˜± ðŸ˜±). Remember that there&amp;rsquo;s no requirement that you watch these thingsâ€”they&amp;rsquo;re simply for your reference so you can see what doing this R stuff looks like in real time. The content all below the video is roughly the same (more polished even).&lt;/p>
&lt;p>That said, it &lt;em>is&lt;/em> a useful demonstration of how to get everything started and what it looks like to do an entire analysis, so there is value in it. Watch just the first part, or watch it on 2x or something.&lt;/p>
&lt;p>And I &lt;em>promise&lt;/em> future examples will not be this long!&lt;/p>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/2N04T-3kZfw" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a slightly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="load-and-clean-data">Load and clean data&lt;/h3>
&lt;p>First, we need to load a few libraries: &lt;strong>tidyverse&lt;/strong> (as always), along with &lt;strong>readxl&lt;/strong> for reading Excel files and &lt;strong>lubridate&lt;/strong> for working with dates:&lt;/p>
&lt;pre>&lt;code class="language-r"># Load libraries
library(tidyverse) # For ggplot, dplyr, and friends
library(readxl) # For reading Excel files
library(lubridate) # For working with dates
&lt;/code>&lt;/pre>
&lt;p>We&amp;rsquo;ll then load the original Excel file. I placed this file in a folder named &lt;code>data&lt;/code> in my RStudio Project folder for this example. I like to read original data into an object named &lt;code>whatever_raw&lt;/code> just in case it takes a long time to load (that way I don&amp;rsquo;t have to keep reloading it every time I add a new column or do anything else with it). It&amp;rsquo;s also good practice to keep a pristine, untouched copy of your data.&lt;/p>
&lt;pre>&lt;code class="language-r"># Load the original Excel file
bbc_raw &amp;lt;- read_excel(&amp;quot;data/360-giving-data.xlsx&amp;quot;)
&lt;/code>&lt;/pre>
&lt;p>There may be some errors reading the fileâ€”you can ignore those in this case.&lt;/p>
&lt;p>Next we&amp;rsquo;ll add a couple columns and clean up the data a little. In the video I did this non-linearlyâ€”I came back to the top of the document to add columns when I needed them and then reran the chunk to create the data.&lt;/p>
&lt;p>We&amp;rsquo;ll extract the year from the Award Date column, rename some of the longer-named columns, and make a new column that shows the duration of grants. We&amp;rsquo;ll also get rid of 2015 since there are so few observations then.&lt;/p>
&lt;p>Note the strange use of &lt;code>`&lt;/code>s around column names like &lt;code>`Award Date`&lt;/code>. This is because R technically doesn&amp;rsquo;t allow special characters like spaces in column names. If there are spaces, you have to wrap the column names in backticks. Because typing backticks all the time gets tedious, we&amp;rsquo;ll use &lt;code>rename()&lt;/code> to rename some of the columns:&lt;/p>
&lt;pre>&lt;code class="language-r">bbc &amp;lt;- bbc_raw %&amp;gt;%
# Extract the year from the award date
mutate(grant_year = year(`Award Date`)) %&amp;gt;%
# Rename some columns
rename(grant_amount = `Amount Awarded`,
grant_program = `Grant Programme:Title`,
grant_duration = `Planned Dates:Duration (months)`) %&amp;gt;%
# Make a new text-based version of the duration column, recoding months
# between 12-23, 23-35, and 36+. The case_when() function here lets us use
# multiple if/else conditions at the same time.
mutate(grant_duration_text = case_when(
grant_duration &amp;gt;= 12 &amp;amp; grant_duration &amp;lt; 24 ~ &amp;quot;1 year&amp;quot;,
grant_duration &amp;gt;= 24 &amp;amp; grant_duration &amp;lt; 36 ~ &amp;quot;2 years&amp;quot;,
grant_duration &amp;gt;= 36 ~ &amp;quot;3 years&amp;quot;
)) %&amp;gt;%
# Get rid of anything before 2016
filter(grant_year &amp;gt; 2015) %&amp;gt;%
# Make a categorical version of the year column
mutate(grant_year_category = factor(grant_year))
&lt;/code>&lt;/pre>
&lt;h3 id="histograms">Histograms&lt;/h3>
&lt;p>First let&amp;rsquo;s look at the distribution of grant amounts with a histogram. Map &lt;code>grant_amount&lt;/code> to the x-axis and don&amp;rsquo;t map anything to the y-axis, since &lt;code>geom_histogram()&lt;/code> will calculate the y-axis values for us:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(data = bbc, mapping = aes(x = grant_amount)) +
geom_histogram()
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/hist-basic-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>Notice that ggplot warns you about bin widths. By default it will divide the data into 30 equally spaced bins, which will most likely not be the best for your data. You should &lt;em>always&lt;/em> set your own bin width to something more appropriate. There are no rules for correct bin widths. Just don&amp;rsquo;t have them be too wide:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(data = bbc, mapping = aes(x = grant_amount)) +
geom_histogram(binwidth = 100000)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/hist-wide-bin-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>Or too small:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(data = bbc, mapping = aes(x = grant_amount)) +
geom_histogram(binwidth = 500)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/hist-tiny-bins-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>Â£10,000 seems to fit well. It&amp;rsquo;s often helpful to add a white border to the histogram bars, too:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(data = bbc, mapping = aes(x = grant_amount)) +
geom_histogram(binwidth = 10000, color = &amp;quot;white&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/hist-good-bins-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>We can map other variables onto the plot, like mapping &lt;code>grant_year_category&lt;/code> to the fill aesthetic:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc, aes(x = grant_amount, fill = grant_year_category)) +
geom_histogram(binwidth = 10000, color = &amp;quot;white&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/hist-bad-fill-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>That gets really hard to interpret though, so we can facet by year with &lt;code>facet_wrap()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc, aes(x = grant_amount, fill = grant_year_category)) +
geom_histogram(binwidth = 10000, color = &amp;quot;white&amp;quot;) +
facet_wrap(vars(grant_year))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/hist-facet-fill-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>Neat!&lt;/p>
&lt;h3 id="points">Points&lt;/h3>
&lt;p>Next let&amp;rsquo;s look at the data using points, mapping year to the x-axis and grant amount to the y-axis:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc, aes(x = grant_year_category, y = grant_amount)) +
geom_point()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/points-initial-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>We have some serious overplotting here, with dots so thick that it looks like lines. We can fix this a couple different ways. First, we can make the points semi-transparent using &lt;code>alpha&lt;/code>, which ranges from 0 (completely invisible) to 1 (completely solid).&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc, aes(x = grant_year_category, y = grant_amount)) +
geom_point(alpha = 0.1)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/points-alpha-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>We can also randomly space the points to spread them out using &lt;code>position_jitter()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc, aes(x = grant_year_category, y = grant_amount)) +
geom_point(position = position_jitter())
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/points-jitter-default-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>One issue with this, though, is that the points are jittered along the x-axis (which is fine, since they&amp;rsquo;re all within the same year) &lt;em>and&lt;/em> the y-axis (which is bad, since the amounts are actual numbers). We can tell ggplot to only jitter in one direction by specifying the &lt;code>height&lt;/code> argumentâ€”we don&amp;rsquo;t want any up-and-down jittering:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc, aes(x = grant_year_category, y = grant_amount)) +
geom_point(position = position_jitter(height = 0))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/points-jitter-horizontal-only-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>There are some weird clusters around Â£30,000 and below. Let&amp;rsquo;s map &lt;code>grant_program&lt;/code> to the color aesthetic, which has two categoriesâ€”regular grants and small grantsâ€”and see if that helps explain why:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc, aes(x = grant_year_category, y = grant_amount, color = grant_program)) +
geom_point(position = position_jitter(height = 0))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/points-jitter-color-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>It does! We appear to have two different distributions of grants: small grants have a limit of Â£30,000, while regular grants have a much higher average amount.&lt;/p>
&lt;h3 id="boxplots">Boxplots&lt;/h3>
&lt;p>We can add summary information to the plot by only changing the &lt;code>geom&lt;/code> we&amp;rsquo;re using. Switch from &lt;code>geom_point()&lt;/code> to &lt;code>geom_boxplot()&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc, aes(x = grant_year_category, y = grant_amount, color = grant_program)) +
geom_boxplot()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/boxplot-1.png" width="480" style="display: block; margin: auto;" />
&lt;h3 id="summaries">Summaries&lt;/h3>
&lt;p>We can also make smaller summarized datasets with &lt;strong>dplyr&lt;/strong> functions like &lt;code>group_by()&lt;/code> and &lt;code>summarize()&lt;/code> and plot those. First let&amp;rsquo;s look at grant totals, averages, and counts over time:&lt;/p>
&lt;pre>&lt;code class="language-r">bbc_by_year &amp;lt;- bbc %&amp;gt;%
group_by(grant_year) %&amp;gt;% # Make invisible subgroups for each year
summarize(total = sum(grant_amount), # Find the total awarded in each group
avg = mean(grant_amount), # Find the average awarded in each group
number = n()) # n() is a special function that shows the number of rows in each group
# Look at our summarized data
bbc_by_year
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 4 x 4
## grant_year total avg number
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1 2016 17290488 78238. 221
## 2 2017 62394278 59765. 1044
## 3 2018 61349392 60205. 1019
## 4 2019 41388816 61136. 677
&lt;/code>&lt;/pre>
&lt;p>Because we used &lt;code>summarize()&lt;/code>, R shrank our data down significantly. We now only have a row for each of the subgroups we made: one for each year. We can plot this smaller data. We&amp;rsquo;ll use &lt;code>geom_col()&lt;/code> for now (but in tomorrow&amp;rsquo;s session you&amp;rsquo;ll learn why this is actually bad for averages!)&lt;/p>
&lt;pre>&lt;code class="language-r"># Plot our summarized data
ggplot(bbc_by_year, aes(x = grant_year, y = avg)) +
geom_col()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/plot-year-summaries-1.png" width="480" style="display: block; margin: auto;" />
&lt;pre>&lt;code class="language-r">ggplot(bbc_by_year, aes(x = grant_year, y = total)) +
geom_col()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/plot-year-summaries-2.png" width="480" style="display: block; margin: auto;" />
&lt;pre>&lt;code class="language-r">ggplot(bbc_by_year, aes(x = grant_year, y = number)) +
geom_col()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/plot-year-summaries-3.png" width="480" style="display: block; margin: auto;" />
&lt;p>Based on these charts, it looks like 2016 saw the largest average grant amount. In all other years, grants averaged around Â£60,000, but in 2016 it jumped up to Â£80,000. If we look at total grants, though, we can see that there were far fewer grants awarded in 2016â€”only 221! 2017 and 2018 were much bigger years with far more money awarded.&lt;/p>
&lt;p>We can also use multiple aesthetics to reveal more information from the data. First we&amp;rsquo;ll make a new small summary dataset and group by both year and grant program. With those groups, we&amp;rsquo;ll again calculate the total, average, and number.&lt;/p>
&lt;pre>&lt;code class="language-r">bbc_year_size &amp;lt;- bbc %&amp;gt;%
group_by(grant_year, grant_program) %&amp;gt;%
summarize(total = sum(grant_amount),
avg = mean(grant_amount),
number = n())
bbc_year_size
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 8 x 5
## # Groups: grant_year [4]
## grant_year grant_program total avg number
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1 2016 Main Grants 16405586 86345. 190
## 2 2016 Small Grants 884902 28545. 31
## 3 2017 Main Grants 48502923 90154. 538
## 4 2017 Small Grants 13891355 27453. 506
## 5 2018 Main Grants 47347789 95652. 495
## 6 2018 Small Grants 14001603 26721. 524
## 7 2019 Main Grants 33019492 96267. 343
## 8 2019 Small Grants 8369324 25058. 334
&lt;/code>&lt;/pre>
&lt;p>Next we&amp;rsquo;ll plot the data, mapping the &lt;code>grant_program&lt;/code> column to the &lt;code>fill&lt;/code> aesthetic:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc_year_size, aes(x = grant_year, y = total, fill = grant_program)) +
geom_col()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/plot-year-size-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>By default, ggplot will stack the different fill colors within the same bar, but this makes it a little hard to make comparisons. While we can see that the average small grant amount was a little bigger in 2017 than in 2019, it&amp;rsquo;s harder to compare average main grant amount, since the bottoms of those sections don&amp;rsquo;t align.&lt;/p>
&lt;p>To fix this, we can use &lt;code>position_dodge()&lt;/code> to tell the columns to fit side-by-side:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc_year_size, aes(x = grant_year, y = total, fill = grant_program)) +
geom_col(position = position_dodge())
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/plot-year-size-dodge-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>Instead of dodging, we can also facet by &lt;code>grant_program&lt;/code> to separate the bars:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc_year_size, aes(x = grant_year, y = total, fill = grant_program)) +
geom_col() +
facet_wrap(vars(grant_program))
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/plot-year-size-facet-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>We can put these in one column if we want:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc_year_size, aes(x = grant_year, y = total, fill = grant_program)) +
geom_col() +
facet_wrap(vars(grant_program), ncol = 1)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/plot-year-size-col-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>Finally, we can include even more variables! We have a lot of aesthetics we can work with (&lt;code>size&lt;/code>, &lt;code>alpha&lt;/code>, &lt;code>color&lt;/code>, &lt;code>fill&lt;/code>, &lt;code>linetype&lt;/code>, etc.), as well as facets, so let&amp;rsquo;s add one more to show the duration of the awarded grant.&lt;/p>
&lt;p>First we&amp;rsquo;ll make another smaller summarized dataset, grouping by year, program, and duration and summarizing the total, average, and number of awards.&lt;/p>
&lt;pre>&lt;code class="language-r">bbc_year_size_duration &amp;lt;- bbc %&amp;gt;%
group_by(grant_year, grant_program, grant_duration_text) %&amp;gt;%
summarize(total = sum(grant_amount),
avg = mean(grant_amount),
number = n())
bbc_year_size_duration
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 21 x 6
## # Groups: grant_year, grant_program [8]
## grant_year grant_program grant_duration_text total avg number
## &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;int&amp;gt;
## 1 2016 Main Grants 2 years 97355 48678. 2
## 2 2016 Main Grants 3 years 16308231 86746. 188
## 3 2016 Small Grants 3 years 884902 28545. 31
## 4 2017 Main Grants 1 year 59586 29793 2
## 5 2017 Main Grants 2 years 825732 82573. 10
## 6 2017 Main Grants 3 years 47617605 90528. 526
## 7 2017 Small Grants 1 year 10000 10000 1
## 8 2017 Small Grants 2 years 245227 18864. 13
## 9 2017 Small Grants 3 years 13636128 27716. 492
## 10 2018 Main Grants 1 year 118134 59067 2
## # â€¦ with 11 more rows
&lt;/code>&lt;/pre>
&lt;p>Next, we&amp;rsquo;ll fill by grant program and facet by duration and show the total number of grants awarded&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(bbc_year_size_duration, aes(x = grant_year, y = number, fill = grant_program)) +
geom_col(position = position_dodge(preserve = &amp;quot;single&amp;quot;)) +
facet_wrap(vars(grant_duration_text), ncol = 1)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/03-example_files/figure-html/plot-year-size-duration-1.png" width="480" style="display: block; margin: auto;" />
&lt;p>The vast majority of BBC Children in Need&amp;rsquo;s grants last for 3 years. Super neat.&lt;/p></description></item><item><title>Amounts and proportions</title><link>https://aem2850.toddgerarden.com/example/04-example/</link><pubDate>Mon, 14 Jun 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/04-example/</guid><description>&lt;p>For this example, we&amp;rsquo;re going to use real world data to demonstrate some different ways to visualize amounts and proportions. We&amp;rsquo;ll use data from the CDC and the Social Security Administration about the number of daily births in the United States from 1994â€“2014. &lt;a href="https://fivethirtyeight.com/features/some-people-are-too-superstitious-to-have-a-baby-on-friday-the-13th/" target="_blank" rel="noopener">FiveThirtyEight reported a story using this data in 2016&lt;/a> and they posted relatively CSV files &lt;a href="https://github.com/fivethirtyeight/data/tree/master/births" target="_blank" rel="noopener">on GitHub&lt;/a>, so we can download and use those.&lt;/p>
&lt;p>If you want to follow along with this example, you can download the data directly from &lt;a href="https://github.com/fivethirtyeight/data/tree/master/births" target="_blank" rel="noopener">GitHub&lt;/a> or by using these links (you&amp;rsquo;ll likely need to right click on these and choose &amp;ldquo;Save Link Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_1994-2003_CDC_NCHS.csv" target="_blank" rel="noopener">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>US_births_1994-2003_CDC_NCHS.csv&lt;/code>&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://raw.githubusercontent.com/fivethirtyeight/data/master/births/US_births_2000-2014_SSA.csv" target="_blank" rel="noopener">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>US_births_2000-2014_SSA.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="live-coding-example">Live coding example&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/zrT-ThV6U6M" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="complete-code">Complete code&lt;/h2>
&lt;p>&lt;em>(This is a slightly cleaned up version of the code from the video.)&lt;/em>&lt;/p>
&lt;h3 id="load-data">Load data&lt;/h3>
&lt;p>There are two CSV files:&lt;/p>
&lt;ul>
&lt;li>&lt;code>US_births_1994-2003_CDC_NCHS.csv&lt;/code> contains U.S. births data for the years 1994 to 2003, as provided by the Centers for Disease Control and Preventionâ€™s National Center for Health Statistics.&lt;/li>
&lt;li>&lt;code>US_births_2000-2014_SSA.csv&lt;/code> contains U.S. births data for the years 2000 to 2014, as provided by the Social Security Administration.&lt;/li>
&lt;/ul>
&lt;p>Since the two datasets overlap in 2000â€“2003, we use Social Security Administration data for those years.&lt;/p>
&lt;p>We downloaded the data from GitHub and placed the CSV files in a folder named &lt;code>data&lt;/code>. We&amp;rsquo;ll then load them with &lt;code>read_csv()&lt;/code> and combine them into one data frame.&lt;/p>
&lt;pre>&lt;code class="language-r">library(tidyverse)
library(scales) # For nice labels in charts
births_1994_1999 &amp;lt;- read_csv(&amp;quot;data/US_births_1994-2003_CDC_NCHS.csv&amp;quot;) %&amp;gt;%
# Ignore anything after 2000
filter(year &amp;lt; 2000)
births_2000_2014 &amp;lt;- read_csv(&amp;quot;data/US_births_2000-2014_SSA.csv&amp;quot;)
births_combined &amp;lt;- bind_rows(births_1994_1999, births_2000_2014)
&lt;/code>&lt;/pre>
&lt;h3 id="wrangle-data">Wrangle data&lt;/h3>
&lt;p>Let&amp;rsquo;s look at the first few rows of the data to see what we&amp;rsquo;re working with:&lt;/p>
&lt;pre>&lt;code class="language-r">head(births_combined)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 5
## year month date_of_month day_of_week births
## &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt;
## 1 1994 1 1 6 8096
## 2 1994 1 2 7 7772
## 3 1994 1 3 1 10142
## 4 1994 1 4 2 11248
## 5 1994 1 5 3 11053
## 6 1994 1 6 4 11406
&lt;/code>&lt;/pre>
&lt;p>The columns for year and births seem straightforward and ready to use. The columns for month and day of the week could be improved if we changed them to text (i.e. January instead of 1; Tuesday instead of 3). To fix this, we can convert these columns to categorical variables, or factors in R. We can also specify that these categories (or factors) are ordered, meaning that Feburary comes after January, etc. Without ordering, R will plot them alphabetically, which isn&amp;rsquo;t very helpful.&lt;/p>
&lt;p>We&amp;rsquo;ll make a new dataset named &lt;code>births&lt;/code> that&amp;rsquo;s based on the combined births data, but with some new columns added:&lt;/p>
&lt;pre>&lt;code class="language-r"># The c() function lets us make a list of values
month_names &amp;lt;- c(&amp;quot;January&amp;quot;, &amp;quot;February&amp;quot;, &amp;quot;March&amp;quot;, &amp;quot;April&amp;quot;, &amp;quot;May&amp;quot;, &amp;quot;June&amp;quot;, &amp;quot;July&amp;quot;,
&amp;quot;August&amp;quot;, &amp;quot;September&amp;quot;, &amp;quot;October&amp;quot;, &amp;quot;November&amp;quot;, &amp;quot;December&amp;quot;)
day_names &amp;lt;- c(&amp;quot;Monday&amp;quot;, &amp;quot;Tuesday&amp;quot;, &amp;quot;Wednesday&amp;quot;,
&amp;quot;Thursday&amp;quot;, &amp;quot;Friday&amp;quot;, &amp;quot;Saturday&amp;quot;, &amp;quot;Sunday&amp;quot;)
births &amp;lt;- births_combined %&amp;gt;%
# Make month an ordered factor, using the month_name list as labels
mutate(month = factor(month, labels = month_names, ordered = TRUE)) %&amp;gt;%
mutate(day_of_week = factor(day_of_week, labels = day_names, ordered = TRUE),
date_of_month_categorical = factor(date_of_month)) %&amp;gt;%
# Add a column indicating if the day is on a weekend
mutate(weekend = ifelse(day_of_week %in% c(&amp;quot;Saturday&amp;quot;, &amp;quot;Sunday&amp;quot;), TRUE, FALSE))
head(births)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 6 x 7
## year month date_of_month day_of_week births date_of_month_categoriâ€¦ weekend
## &amp;lt;dbl&amp;gt; &amp;lt;ord&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;ord&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;lgl&amp;gt;
## 1 1994 January 1 Saturday 8096 1 TRUE
## 2 1994 January 2 Sunday 7772 2 TRUE
## 3 1994 January 3 Monday 10142 3 FALSE
## 4 1994 January 4 Tuesday 11248 4 FALSE
## 5 1994 January 5 Wednesday 11053 5 FALSE
## 6 1994 January 6 Thursday 11406 6 FALSE
&lt;/code>&lt;/pre>
&lt;p>If you look at the data now, you can see the columns are changed and have different types. &lt;code>year&lt;/code> and &lt;code>date_of_month&lt;/code> are still numbers, but &lt;code>month&lt;/code>, and &lt;code>day_of_week&lt;/code> are ordered factors (&lt;code>ord&lt;/code>) and &lt;code>date_of_month_categorical&lt;/code> is a regular factor (&lt;code>fct&lt;/code>). Technically it&amp;rsquo;s also ordered, but because it&amp;rsquo;s already alphabetical (i.e. 2 naturally comes after 1), we don&amp;rsquo;t need to force it to be in the right order.&lt;/p>
&lt;p>Our &lt;code>births&lt;/code> data is now clean and ready to go!&lt;/p>
&lt;h3 id="bar-plot">Bar plot&lt;/h3>
&lt;p>First we can look at a bar chart showing the total number of births each day. We need to make a smaller summarized dataset and then we&amp;rsquo;ll plot it:&lt;/p>
&lt;pre>&lt;code class="language-r">total_births_weekday &amp;lt;- births %&amp;gt;%
group_by(day_of_week) %&amp;gt;%
summarize(total = sum(births))
ggplot(data = total_births_weekday,
mapping = aes(x = day_of_week, y = total, fill = day_of_week)) +
geom_col() +
# Turn off the fill legend because it's redundant
guides(fill = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/04-example_files/figure-html/plot-bar-chart-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>If we fill by day of the week, we get 7 different colors, which is fine (I guess), but doesn&amp;rsquo;t really help tell a story. The main story here is that there are far fewer births during weekends. If we create a new column that flags if a row is Saturday or Sunday, we can fill by that column instead:&lt;/p>
&lt;pre>&lt;code class="language-r">total_births_weekday &amp;lt;- births %&amp;gt;%
group_by(day_of_week) %&amp;gt;%
summarize(total = sum(births)) %&amp;gt;%
mutate(weekend = ifelse(day_of_week %in% c(&amp;quot;Saturday&amp;quot;, &amp;quot;Sunday&amp;quot;), TRUE, FALSE))
ggplot(data = total_births_weekday,
mapping = aes(x = day_of_week, y = total, fill = weekend)) +
geom_col()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/04-example_files/figure-html/plot-bar-chart-weekend-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>Neat! Those default colors are kinda ugly, though, so let&amp;rsquo;s use the principles of preattentive processing and contrast to highlight the weekend bars:&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(data = total_births_weekday,
mapping = aes(x = day_of_week, y = total, fill = weekend)) +
geom_col() +
# Use grey and orange
scale_fill_manual(values = c(&amp;quot;grey70&amp;quot;, &amp;quot;#f2ad22&amp;quot;)) +
# Use commas instead of scientific notation
scale_y_continuous(labels = comma) +
# Turn off the legend since the title shows what the orange is
guides(fill = &amp;quot;none&amp;quot;) +
labs(title = &amp;quot;Weekends are unpopular times for giving birth&amp;quot;,
x = NULL, y = &amp;quot;Total births&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/04-example_files/figure-html/plot-bar-chart-weekend-better-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="lollipop-chart">Lollipop chart&lt;/h3>
&lt;p>Since the ends of the bars are often the most important part of the graph, we can use a lollipop chart to emphasize them. We&amp;rsquo;ll keep all the same code from our bar chart and make a few changes:&lt;/p>
&lt;ul>
&lt;li>Color by weekend instead of fill by weekend, since points and lines are colored in ggplot, not filled&lt;/li>
&lt;li>Switch &lt;code>scale_fill_manual()&lt;/code> to &lt;code>scale_color_manual()&lt;/code> and turn off the &lt;code>color&lt;/code> legend in the &lt;code>guides()&lt;/code> layer&lt;/li>
&lt;li>Switch &lt;code>geom_col()&lt;/code> to &lt;code>geom_pointrange()&lt;/code>. The &lt;code>geom_pointrange()&lt;/code> layer requires two additional aesthetics: &lt;code>ymin&lt;/code> and &lt;code>ymax&lt;/code> for the ends of the lines that come out of the point. Here we&amp;rsquo;ll set &lt;code>ymin&lt;/code> to 0 so it starts at the x-axis, and we&amp;rsquo;ll set &lt;code>ymax&lt;/code> to &lt;code>total&lt;/code> so it ends at the point.&lt;/li>
&lt;/ul>
&lt;pre>&lt;code class="language-r">ggplot(data = total_births_weekday,
mapping = aes(x = day_of_week, y = total, color = weekend)) +
geom_pointrange(aes(ymin = 0, ymax = total),
# Make the lines a little thicker and the dots a little bigger
fatten = 5, size = 1.5) +
# Use grey and orange
scale_color_manual(values = c(&amp;quot;grey70&amp;quot;, &amp;quot;#f2ad22&amp;quot;)) +
# Use commas instead of scientific notation
scale_y_continuous(labels = comma) +
# Turn off the legend since the title shows what the orange is
guides(color = &amp;quot;none&amp;quot;) +
labs(title = &amp;quot;Weekends are unpopular times for giving birth&amp;quot;,
x = NULL, y = &amp;quot;Total births&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/04-example_files/figure-html/plot-lollipop-chart-weekend-better-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="strip-plot">Strip plot&lt;/h3>
&lt;p>However, we want to #barbarplots! (Though they&amp;rsquo;re arguably okay here, since they show totals and not averages). Let&amp;rsquo;s show all the data with points. We&amp;rsquo;ll use the full dataset now, map x to weekday, y to births, and change &lt;code>geom_col()&lt;/code> to &lt;code>geom_point()&lt;/code>. We&amp;rsquo;ll tell &lt;code>geom_point()&lt;/code> to jitter the points randomly.&lt;/p>
&lt;pre>&lt;code class="language-r">ggplot(data = births,
mapping = aes(x = day_of_week, y = births, color = weekend)) +
scale_color_manual(values = c(&amp;quot;grey70&amp;quot;, &amp;quot;#f2ad22&amp;quot;)) +
geom_point(size = 0.5, position = position_jitter(height = 0)) +
guides(color = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/04-example_files/figure-html/strip-plot-1.png" width="576" style="display: block; margin: auto;" />
&lt;p>There are some interesting points in the low ends, likely because of holidays like Labor Day and Memorial Day (for the Mondays) and Thanksgiving (for the Thursday). If we had a column that indicated whether a day was a holiday, we could color by that and it would probably explain most of those low numbers. Unfortunately we don&amp;rsquo;t have that column, and it&amp;rsquo;d be hard to make. Some holidays are constant (Halloween is always October 31), but some aren&amp;rsquo;t (Thanksgiving is the fourth Thursday in November, so we&amp;rsquo;d need to find out which November 20-somethingth each year is the fourth Thursday, and good luck doing that at scale).&lt;/p>
&lt;h3 id="beeswarm-plot">Beeswarm plot&lt;/h3>
&lt;p>We can add some structure to these points if we use the &lt;a href="https://github.com/eclarke/ggbeeswarm" target="_blank" rel="noopener">&lt;strong>ggbeeswarm&lt;/strong> package&lt;/a>, with either &lt;code>geom_beeswarm()&lt;/code> or &lt;code>geom_quasirandom()&lt;/code>. &lt;code>geom_quasirandom()&lt;/code> actually works better here since there are so many pointsâ€”&lt;code>geom_beeswarm()&lt;/code> makes the clusters of points way too wide.&lt;/p>
&lt;pre>&lt;code class="language-r">library(ggbeeswarm)
ggplot(data = births,
mapping = aes(x = day_of_week, y = births, color = weekend)) +
scale_color_manual(values = c(&amp;quot;grey70&amp;quot;, &amp;quot;#f2ad22&amp;quot;)) +
# Make these points suuuper tiny
geom_quasirandom(size = 0.0001) +
guides(color = &amp;quot;none&amp;quot;)
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/04-example_files/figure-html/beeswarm-plot-1.png" width="576" style="display: block; margin: auto;" />
&lt;h3 id="heatmap">Heatmap&lt;/h3>
&lt;p>Finally, let&amp;rsquo;s use something non-traditional to show the average births by day in a somewhat proportional way. We can calculate the average number of births every day and then make a heatmap that fills each square by that average, thus showing the relative differences in births per day.&lt;/p>
&lt;p>To do this, we need to make a summarized data frame with &lt;code>group_by() %&amp;gt;% summarize()&lt;/code> to calculate the average number of births by month and day of the month (i.e. average for January 1, January 2, etc.).&lt;/p>
&lt;p>We&amp;rsquo;ll then make a sort of calendar with date of the month on the x axis, month on the y axis, with heat map squares filled by the daily average. We&amp;rsquo;ll use &lt;code>geom_tile()&lt;/code> to add squares for each day, and then add some extra scale, coordinates, and theme layers to clean up the plot:&lt;/p>
&lt;pre>&lt;code class="language-r">avg_births_month_day &amp;lt;- births %&amp;gt;%
group_by(month, date_of_month_categorical) %&amp;gt;%
summarize(avg_births = mean(births))
ggplot(data = avg_births_month_day,
# By default, the y-axis will have December at the top, so use fct_rev() to reverse it
mapping = aes(x = date_of_month_categorical, y = fct_rev(month), fill = avg_births)) +
geom_tile() +
# Add viridis colors
scale_fill_viridis_c(option = &amp;quot;inferno&amp;quot;, labels = comma) +
# Add nice labels
labs(x = &amp;quot;Day of the month&amp;quot;, y = NULL,
title = &amp;quot;Average births per day&amp;quot;,
subtitle = &amp;quot;1994-2014&amp;quot;,
fill = &amp;quot;Average births&amp;quot;) +
# Force all the tiles to have equal widths and heights
coord_equal() +
# Use a cleaner theme
theme_minimal()
&lt;/code>&lt;/pre>
&lt;img src="https://aem2850.toddgerarden.com/example/04-example_files/figure-html/plot-heatmap-1.png" width="960" style="display: block; margin: auto;" />
&lt;p>Neat! There are some really interesting trends here. Most obvious, probably, is that very few people are born on New Year&amp;rsquo;s Day, July 4th, Halloween, Thanksgiving, and Christmas.&lt;/p>
&lt;pre>&lt;code class="language-r">avg_births_month_day %&amp;gt;%
arrange(avg_births)
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 366 x 3
## # Groups: month [12]
## month date_of_month_categorical avg_births
## &amp;lt;ord&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt;
## 1 December 25 6601.
## 2 January 1 7827.
## 3 December 24 8103.
## 4 July 4 8825.
## 5 January 2 9356.
## 6 December 26 9599.
## 7 November 27 9770.
## 8 November 23 9919.
## 9 November 25 10001
## 10 October 31 10030.
## # â€¦ with 356 more rows
&lt;/code>&lt;/pre>
&lt;p>The days with the highest average are in mid-September (lol my birthday is #2), likely because that&amp;rsquo;s about 9 months after the first week of January. July 7th at #7 is odd and I have no idea why it might be so popular ðŸ¤·.&lt;/p>
&lt;pre>&lt;code class="language-r">avg_births_month_day %&amp;gt;%
arrange(desc(avg_births))
&lt;/code>&lt;/pre>
&lt;pre>&lt;code>## # A tibble: 366 x 3
## # Groups: month [12]
## month date_of_month_categorical avg_births
## &amp;lt;ord&amp;gt; &amp;lt;fct&amp;gt; &amp;lt;dbl&amp;gt;
## 1 September 9 12344.
## 2 September 19 12285.
## 3 September 12 12282.
## 4 September 17 12201.
## 5 September 10 12190.
## 6 September 20 12162.
## 7 July 7 12147.
## 8 September 15 12126.
## 9 September 16 12114.
## 10 September 18 12112.
## # â€¦ with 356 more rows
&lt;/code>&lt;/pre>
&lt;p>The funniest trend is the very visible dark column for the 13th of every month. People &lt;em>really&lt;/em> don&amp;rsquo;t want to give birth on the 13th.&lt;/p></description></item><item><title>Introduction to R and the tidyverse</title><link>https://aem2850.toddgerarden.com/example/01-example/</link><pubDate>Mon, 07 Jun 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/01-example/</guid><description>&lt;h2 id="basic-process-for-working-with-rstudio">Basic process for working with RStudio&lt;/h2>
&lt;p>For this example, I&amp;rsquo;m going to create a new RStudio project, download some data, put the data in the project, and make a graph of it using R Markdown. You&amp;rsquo;ll follow this same process any time you start a new project or exercise.&lt;/p>
&lt;p>To follow along, download this CSV file here (you may need to right click on it and select &amp;ldquo;Save Asâ€¦&amp;quot;):&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/data/gapminder.csv">&lt;i class="fas fa-file-csv">&lt;/i> &lt;code>gapminder.csv&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>Here&amp;rsquo;s a video walkthrough of how to get started:&lt;/p>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/kXlZbDZpfR0" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div></description></item><item><title>Graphic design</title><link>https://aem2850.toddgerarden.com/example/02-example/</link><pubDate>Mon, 07 Jun 2021 00:00:00 +0000</pubDate><guid>https://aem2850.toddgerarden.com/example/02-example/</guid><description>&lt;p>For this example, I&amp;rsquo;m going to critique and improve this random flyer I found posted in the BYU library in September 2018:&lt;/p>
&lt;img src="https://aem2850.toddgerarden.com/projects/02-example/original-from-hbll.jpg" width="50%" />
&lt;p>It&amp;rsquo;s not the best designed poster, but it&amp;rsquo;s incredibly typical of what you see in the real world. By applying the principles of CRAP, we can improve the poster significantly.&lt;/p>
&lt;p>If you download and unzip this file, you can follow along too (but you don&amp;rsquo;t have toâ€”you can just sit back and enjoy the ride).&lt;/p>
&lt;ul>
&lt;li>&lt;a href="https://aem2850.toddgerarden.com/projects/02-example.zip">&lt;i class="fas fa-file-archive">&lt;/i> &lt;code>02-example.zip&lt;/code>&lt;/a>&lt;/li>
&lt;/ul>
&lt;h2 id="critique">Critique&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/K0sd-j6eMiI" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="redesign-in-canva">Redesign in Canva&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/G1857weuvIc" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="redesign-in-illustrator">Redesign in Illustrator&lt;/h2>
&lt;div class="embed-responsive embed-responsive-16by9">
&lt;iframe class="embed-responsive-item" src="https://www.youtube.com/embed/5Z8FQtDVlYQ" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>&lt;/iframe>
&lt;/div>
&lt;h2 id="final-versions">Final versions&lt;/h2>
&lt;img src="https://aem2850.toddgerarden.com/img/examples/combined-output@2x.png" width="100%" /></description></item></channel></rss>